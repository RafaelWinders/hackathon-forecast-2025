
# Hackathon Forecast Big Data 2025 - Modelo de PrevisÃ£o de Vendas

## ğŸ¯ Objetivo

Este projeto foi desenvolvido para o **Desafio TÃ©cnico â€“ Hackathon Forecast Big Data 2025**. O objetivo Ã© criar um modelo de previsÃ£o de vendas (forecast) para apoiar o varejo na reposiÃ§Ã£o de produtos.

A tarefa consiste em prever a **quantidade semanal de vendas por PDV (Ponto de Venda) e SKU (Unidade de ManutenÃ§Ã£o de Estoque)** para as cinco semanas de janeiro de 2023, utilizando como base o histÃ³rico de vendas de 2022.

-----

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o do Ambiente

Siga os passos abaixo para configurar o ambiente e executar o projeto.

### 1\. PrÃ©-requisitos

  - **Python 3.9+**
  - **Git**

### 2\. Clonar o RepositÃ³rio

### 3\. Criar e Ativar o Ambiente Virtual

Ã‰ altamente recomendado usar um ambiente virtual para isolar as dependÃªncias.

  * **Para Windows:**
    ```cmd
    # 1. Criar o ambiente virtual
    py -m venv venv

    # 2. Ativar o ambiente
    .\venv\Scripts\activate
    ```
  * **Para Linux/macOS:**
    ```bash
    # 1. Criar o ambiente virtual
    python3 -m venv venv

    # 2. Ativar o ambiente
    source venv/bin/activate
    ```

### 4\. Instalar as DependÃªncias

Todas as bibliotecas necessÃ¡rias estÃ£o listadas no arquivo `requirements.txt`.

```bash
pip install -r requirements.txt
```

*ObservaÃ§Ã£o: A instalaÃ§Ã£o pode levar de 5 a 10 minutos, dependendo da sua conexÃ£o com a internet.*

### 5\. Configurar o Kernel do Jupyter

Para garantir que os notebooks usem o ambiente virtual correto, execute o comando abaixo:

```bash
python -m ipykernel install --user --name=hackathon-forecast --display-name="Python (hackathon-forecast)"
```

ApÃ³s executar os notebooks, lembre-se de selecionar o kernel **"Python (hackathon-forecast)"** no canto superior direito da interface do Jupyter.

### 6\. Testar a InstalaÃ§Ã£o

Para verificar se todas as bibliotecas foram instaladas corretamente, execute o script de teste:

```bash
python test_env.py
```

A saÃ­da deve mostrar "OK" para todas as importaÃ§Ãµes.

### 7\. Baixar os Dados

Os dados brutos fornecidos pelo desafio devem ser colocados na pasta `/data`. Certifique-se de que os seguintes arquivos estejam presentes:

  - `data/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet`
  - `data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet`
  - `data/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet`

-----

## ğŸš€ Como Gerar a SubmissÃ£o (Fluxo de ExecuÃ§Ã£o)

O processo Ã© dividido em duas etapas principais, executadas atravÃ©s dos notebooks Jupyter.

### Passo 1: Engenharia de Features

Abra e execute todas as cÃ©lulas do notebook:
â–¶ï¸ **`notebooks/02-Feature-Engineering-Dask.ipynb`**

  - **O que ele faz?** Este notebook carrega os dados brutos, aplica todo o prÃ©-processamento e a engenharia de features, e salva os datasets de treino e teste processados na pasta `data/`.
  - **Resultado:** Arquivos processados.

### Passo 2: Treinamento e GeraÃ§Ã£o da SubmissÃ£o

ApÃ³s a conclusÃ£o do Passo 1, abra e execute todas as cÃ©lulas do notebook:
â–¶ï¸ **`notebooks/04-Final-Pipeline.ipynb`**

  - **O que ele faz?** Carrega os dados processados, treina o modelo LightGBM final e gera o arquivo de previsÃ£o para as 5 semanas de janeiro de 2023.
  - **Resultado:** O arquivo `submission.parquet` serÃ¡ salvo na pasta submissions, pronto para ser enviado.

-----

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ data/                  # Dados brutos e processados
â”œâ”€â”€ notebooks/             # Jupyter Notebooks com a anÃ¡lise e desenvolvimento
â”‚   â”œâ”€â”€ 01-EDA.ipynb       # AnÃ¡lise ExploratÃ³ria dos Dados
â”‚   â”œâ”€â”€ 02-Feature-Engineering-Dask.ipynb # PASSO 1: Gera os dados de treino/teste
â”‚   â”œâ”€â”€ 03-Modeling-Experiments.ipynb     # DocumentaÃ§Ã£o da escolha e comparaÃ§Ã£o de modelos
â”‚   â””â”€â”€ 04-Final-Pipeline.ipynb           # PASSO 2: Treina o modelo e gera a submissÃ£o
â”œâ”€â”€ .gitignore             # Arquivos ignorados pelo Git
â”œâ”€â”€ requirements.txt       # Lista de dependÃªncias Python
â”œâ”€â”€ test_env.py            # Script para verificar a instalaÃ§Ã£o do ambiente
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
```

-----

## ğŸ› ï¸ Metodologia Aplicada

A soluÃ§Ã£o foi desenvolvida seguindo uma abordagem estruturada.

1.  **AnÃ¡lise ExploratÃ³ria (`01-EDA.ipynb`):** InvestigaÃ§Ã£o profunda dos dados para entender distribuiÃ§Ãµes, sazonalidades e tendÃªncias, guiando a engenharia de features.
2.  **Engenharia de Features EscalÃ¡vel (`02-Feature-Engineering-Dask.ipynb`):** Uso de **Dask** e **Polars** para processar grande volume de dados. Foram criadas features temporais, de lag e estatÃ­sticas mÃ³veis.
3.  **Modelagem e DocumentaÃ§Ã£o (`03-Modeling-Experiments.ipynb`):** Este notebook serve como um "diÃ¡rio de bordo", documentando os testes com diferentes algoritmos (XGBoost, LightGBM) e justificando a escolha do **LightGBM** como modelo final devido ao seu equilÃ­brio entre performance, velocidade e eficiÃªncia de memÃ³ria.
4.  **Pipeline Final (`04-Final-Pipeline.ipynb`):** Consolida as melhores tÃ©cnicas em um pipeline otimizado para treinar o modelo e gerar a previsÃ£o final de forma reprodutÃ­vel.

## Team
- Developer: Rafael Winders
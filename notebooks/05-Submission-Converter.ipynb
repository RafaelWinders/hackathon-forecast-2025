{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Conversor e Filtro para Submiss√£o Final\n",
    "\n",
    "**üéØ Objetivo deste Notebook:**\n",
    "\n",
    "Este notebook serve como um passo final e documentado para formatar o arquivo de previs√£o gerado pelo `04-Final-Pipeline.ipynb`. Sua principal fun√ß√£o √© ler o arquivo Parquet completo, que cont√©m previs√µes para todas as combina√ß√µes de PDV/SKU (incluindo previs√µes de venda zero), e convert√™-lo para o formato final.\n",
    "\n",
    "**‚úÖ Processo de Convers√£o:**\n",
    "\n",
    "1.  **Carregar Previs√µes:** L√™ o arquivo `submission.parquet` da pasta `/submissions`, que cont√©m o output completo do modelo.\n",
    "2.  **Filtrar Vendas Zero:** Remove todas as linhas onde a coluna `quantidade` √© igual a 0. Esta √© uma exig√™ncia da plataforma, que limita o n√∫mero de linhas do arquivo de submiss√£o.\n",
    "3.  **Renomear Colunas (Valida√ß√£o):** Garante que os nomes das colunas (`semana`, `pdv`, `produto`, `quantidade`) est√£o exatamente como o especificado no regulamento.\n",
    "4.  **Salvar em CSV:** Exporta o `DataFrame` filtrado para um novo arquivo CSV (`submission_final.csv`) usando `;` como separador e encoding `UTF-8`, pronto para o upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print('üìö Bibliotecas carregadas com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definir Caminhos dos Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo de entrada gerado pelo pipeline 04\n",
    "input_parquet_path = '../submissions/submission.parquet'\n",
    "\n",
    "# Caminho para o arquivo de sa√≠da final que ser√° submetido\n",
    "output_csv_path = '../submissions/submission_final.csv'\n",
    "\n",
    "print(f\"Arquivo de entrada: {input_parquet_path}\")\n",
    "print(f\"Arquivo de sa√≠da: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregar e Processar o Arquivo de Previs√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîÑ Carregando o arquivo Parquet de previs√µes completas...\")\n",
    "if not os.path.exists(input_parquet_path):\n",
    "    print(f\"‚ùå Erro: Arquivo '{input_parquet_path}' n√£o encontrado.\")\n",
    "    print(\"Certifique-se de executar o notebook '04-Final-Pipeline.ipynb' primeiro.\")\n",
    "else:\n",
    "    # Carregar o DataFrame\n",
    "    full_predictions_df = pd.read_parquet(input_parquet_path)\n",
    "    print(f\"‚úÖ Arquivo carregado com sucesso. Shape original: {full_predictions_df.shape}\")\n",
    "    \n",
    "    # --- PASSO 1: Garantir que os nomes das colunas est√£o corretos ---\n",
    "    # (Esta √© uma valida√ß√£o extra para garantir a compatibilidade)\n",
    "    rename_map = {\n",
    "        'pdv_id': 'pdv',\n",
    "        'produto_id': 'produto'\n",
    "    }\n",
    "    columns_to_rename = [col for col in rename_map if col in full_predictions_df.columns]\n",
    "    if columns_to_rename:\n",
    "        print(f\"Renomeando colunas: {columns_to_rename}\")\n",
    "        full_predictions_df.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "    # --- PASSO 2: Filtrar as linhas com previs√£o de quantidade zero ---\n",
    "    print(f\"\\nüîß Filtrando para manter apenas previs√µes com 'quantidade' > 0...\")\n",
    "    filtered_df = full_predictions_df[full_predictions_df['quantidade'] > 0].copy()\n",
    "    \n",
    "    linhas_removidas = len(full_predictions_df) - len(filtered_df)\n",
    "    print(f\"   ‚Ä¢ Linhas removidas: {linhas_removidas:,}\")\n",
    "    print(f\"   ‚Ä¢ Shape final: {filtered_df.shape}\")\n",
    "    \n",
    "    # --- PASSO 3: Validar os tipos de dados ---\n",
    "    print(\"\\n‚úîÔ∏è Validando e ajustando os tipos de dados para inteiros...\")\n",
    "    filtered_df['semana'] = filtered_df['semana'].astype(int)\n",
    "    filtered_df['pdv'] = filtered_df['pdv'].astype(int)\n",
    "    filtered_df['produto'] = filtered_df['produto'].astype(int)\n",
    "    filtered_df['quantidade'] = filtered_df['quantidade'].astype(int)\n",
    "\n",
    "    # --- PASSO 4: Salvar o arquivo CSV final ---\n",
    "    print(f\"\\nüíæ Salvando arquivo CSV final em '{output_csv_path}'...\")\n",
    "    filtered_df.to_csv(\n",
    "        output_csv_path,\n",
    "        sep=';',           # Usando ponto e v√≠rgula como separador\n",
    "        index=False,       # N√£o salvar o √≠ndice do DataFrame\n",
    "        encoding='utf-8'   # Garantir o encoding correto\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ Processo conclu√≠do! O arquivo 'submission_final.csv' est√° pronto para ser enviado.\")\n",
    "    \n",
    "    # --- PASSO 5: Exibir um preview do arquivo final ---\n",
    "    print(\"\\nüëÄ Preview do DataFrame final:\")\n",
    "    display(filtered_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

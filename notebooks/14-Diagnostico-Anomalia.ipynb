{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 - Diagn√≥stico da Anomalia de Previs√£o Nula\n",
    "\n",
    "Este notebook investiga por que as previs√µes zeram nas √∫ltimas semanas de janeiro,\n",
    "analisando especificamente como as features de lag se comportam durante a previs√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('üîç Iniciando Diagn√≥stico da Anomalia de Previs√£o Nula')\n",
    "print('üéØ Objetivo: Identificar por que previs√µes zeram nas √∫ltimas semanas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados de Teste do Pipeline Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentar carregar dados do notebook 13 se dispon√≠vel\n",
    "try:\n",
    "    dados_teste = pd.read_parquet('../data/submissao3/dados_teste_com_previsoes.parquet')\n",
    "    print(f'üìÇ Dados de teste carregados: {dados_teste.shape}')\n",
    "    print(f'üìä Per√≠odo: {dados_teste[\"semana\"].min()} at√© {dados_teste[\"semana\"].max()}')\nexcept FileNotFoundError:\n",
    "    print('‚ö†Ô∏è Arquivo de dados de teste n√£o encontrado.')\n",
    "    print('üí° Execute primeiro o notebook 13 para gerar os dados de teste com previs√µes.')\n",
    "    print('üîÑ Criando dados simulados para demonstra√ß√£o...')\n",
    "    \n",
    "    # Criar dados simulados para demonstra√ß√£o\n",
    "    semanas_janeiro = pd.date_range('2023-01-02', periods=5, freq='W-MON')\n",
    "    dados_teste = pd.DataFrame({\n",
    "        'semana': np.repeat(semanas_janeiro, 1000),\n",
    "        'pdv_id': np.tile(range(1, 201), 25),\n",
    "        'produto_id': np.tile(range(1001, 1006), 1000),\n",
    "        'quantidade_prevista': np.random.uniform(0, 10, 5000),\n",
    "        'probabilidade_venda': np.random.uniform(0.1, 0.9, 5000)\n",
    "    })\n",
    "    \n",
    "    # Simular anomalia nas √∫ltimas 2 semanas\n",
    "    mask_ultimas_semanas = dados_teste['semana'].isin(semanas_janeiro[-2:])\n",
    "    dados_teste.loc[mask_ultimas_semanas, 'quantidade_prevista'] = 0\n",
    "    dados_teste.loc[mask_ultimas_semanas, 'probabilidade_venda'] = 0.05\n",
    "    \n",
    "    print(f'üìä Dados simulados criados: {dados_teste.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An√°lise Geral da Anomalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise por semana\n",
    "print('üìä An√°lise das previs√µes por semana:')\n",
    "print('=' * 60)\n",
    "\n",
    "analise_semanal = dados_teste.groupby('semana').agg({\n",
    "    'quantidade_prevista': ['mean', 'std', 'min', 'max', lambda x: (x == 0).sum()],\n",
    "    'probabilidade_venda': ['mean', 'std'],\n",
    "    'pdv_id': 'count'\n",
    "}).round(4)\n",
    "\n",
    "analise_semanal.columns = ['qty_mean', 'qty_std', 'qty_min', 'qty_max', 'qty_zeros', 'prob_mean', 'prob_std', 'total_registros']\n",
    "analise_semanal['pct_zeros'] = (analise_semanal['qty_zeros'] / analise_semanal['total_registros'] * 100).round(1)\n",
    "\n",
    "print(analise_semanal)\n",
    "\n",
    "# Identificar semanas problem√°ticas\n",
    "semanas_problematicas = analise_semanal[analise_semanal['pct_zeros'] > 50].index\n",
    "print(f'\\nüö® Semanas com >50% de previs√µes zero: {len(semanas_problematicas)}')\n",
    "for semana in semanas_problematicas:\n",
    "    pct = analise_semanal.loc[semana, 'pct_zeros']\n",
    "    print(f'   üìÖ {semana.strftime(\"%Y-%m-%d\")}: {pct}% zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diagn√≥stico Detalhado: Caso Espec√≠fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar um PDV e Produto para an√°lise detalhada\n",
    "# Escolher combina√ß√£o que aparece em todas as semanas\n",
    "combinacoes_completas = dados_teste.groupby(['pdv_id', 'produto_id']).size()\n",
    "combinacoes_5_semanas = combinacoes_completas[combinacoes_completas == 5].index\n",
    "\n",
    "if len(combinacoes_5_semanas) > 0:\n",
    "    pdv_exemplo, produto_exemplo = combinacoes_5_semanas[0]\n",
    "    print(f'üîç Analisando PDV {pdv_exemplo} x Produto {produto_exemplo}')\n",
    "    \n",
    "    # Filtrar dados para este exemplo\n",
    "    df_diagnostico = dados_teste[\n",
    "        (dados_teste['pdv_id'] == pdv_exemplo) & \n",
    "        (dados_teste['produto_id'] == produto_exemplo)\n",
    "    ].copy().sort_values('semana')\n",
    "    \n",
    "    print(f'üìä Registros encontrados: {len(df_diagnostico)}')\n",
    "    \n",
    "    # Mostrar evolu√ß√£o das principais vari√°veis\n",
    "    colunas_diagnostico = ['semana', 'quantidade_prevista', 'probabilidade_venda']\n",
    "    \n",
    "    # Adicionar features de lag se existirem\n",
    "    lag_features = [col for col in dados_teste.columns if 'lag' in col.lower()]\n",
    "    media_features = [col for col in dados_teste.columns if 'media' in col.lower()]\n",
    "    \n",
    "    features_importantes = lag_features + media_features\n",
    "    if features_importantes:\n",
    "        colunas_diagnostico.extend(features_importantes[:10])  # Primeiras 10 features\n",
    "    \n",
    "    # Filtrar apenas colunas que existem\n",
    "    colunas_existentes = [col for col in colunas_diagnostico if col in df_diagnostico.columns]\n",
    "    \n",
    "    print('\\nüìã Evolu√ß√£o das Features Principais:')\n",
    "    print('=' * 80)\n",
    "    if len(colunas_existentes) > 2:\n",
    "        print(df_diagnostico[colunas_existentes].to_string(index=False))\n",
    "    else:\n",
    "        print(df_diagnostico[['semana', 'quantidade_prevista', 'probabilidade_venda']].to_string(index=False))\n",
    "        \n",
    "else:\n",
    "    print('‚ö†Ô∏è Nenhuma combina√ß√£o PDV x Produto encontrada em todas as 5 semanas')\n",
    "    print('üí° Isso pode indicar problemas na gera√ß√£o do grid de teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lise Visual da Anomalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar visualiza√ß√µes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Diagn√≥stico da Anomalia de Previs√£o', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribui√ß√£o de previs√µes por semana\n",
    "axes[0,0].boxplot([dados_teste[dados_teste['semana'] == semana]['quantidade_prevista'].values \n",
    "                   for semana in sorted(dados_teste['semana'].unique())],\n",
    "                  labels=[s.strftime('%m-%d') for s in sorted(dados_teste['semana'].unique())])\n",
    "axes[0,0].set_title('Distribui√ß√£o de Quantidade Prevista por Semana')\n",
    "axes[0,0].set_ylabel('Quantidade Prevista')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Percentual de zeros por semana\n",
    "pct_zeros_semana = dados_teste.groupby('semana')['quantidade_prevista'].apply(lambda x: (x == 0).mean() * 100)\n",
    "axes[0,1].bar(range(len(pct_zeros_semana)), pct_zeros_semana.values, color='red', alpha=0.7)\n",
    "axes[0,1].set_title('Percentual de Previs√µes Zero por Semana')\n",
    "axes[0,1].set_ylabel('% Previs√µes Zero')\n",
    "axes[0,1].set_xticks(range(len(pct_zeros_semana)))\n",
    "axes[0,1].set_xticklabels([s.strftime('%m-%d') for s in pct_zeros_semana.index], rotation=45)\n",
    "\n",
    "# 3. Distribui√ß√£o de probabilidades por semana\n",
    "axes[1,0].boxplot([dados_teste[dados_teste['semana'] == semana]['probabilidade_venda'].values \n",
    "                   for semana in sorted(dados_teste['semana'].unique())],\n",
    "                  labels=[s.strftime('%m-%d') for s in sorted(dados_teste['semana'].unique())])\n",
    "axes[1,0].set_title('Distribui√ß√£o de Probabilidade de Venda por Semana')\n",
    "axes[1,0].set_ylabel('Probabilidade de Venda')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Evolu√ß√£o do caso espec√≠fico (se dispon√≠vel)\n",
    "if len(combinacoes_5_semanas) > 0:\n",
    "    axes[1,1].plot(df_diagnostico['semana'], df_diagnostico['quantidade_prevista'], 'o-', label='Quantidade Prevista', linewidth=2)\n",
    "    ax2 = axes[1,1].twinx()\n",
    "    ax2.plot(df_diagnostico['semana'], df_diagnostico['probabilidade_venda'], 's-', color='red', label='Prob. Venda', alpha=0.7)\n",
    "    axes[1,1].set_title(f'Caso Espec√≠fico: PDV {pdv_exemplo} x Produto {produto_exemplo}')\n",
    "    axes[1,1].set_ylabel('Quantidade Prevista')\n",
    "    ax2.set_ylabel('Probabilidade de Venda', color='red')\n",
    "    axes[1,1].legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Caso espec√≠fico n√£o dispon√≠vel', ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "    axes[1,1].set_title('Caso Espec√≠fico: N√£o Dispon√≠vel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclus√µes e Recomenda√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üéØ CONCLUS√ïES DO DIAGN√ìSTICO')\n",
    "print('=' * 60)\n",
    "\n",
    "# Calcular estat√≠sticas da anomalia\n",
    "primeiras_3_semanas = sorted(dados_teste['semana'].unique())[:3]\n",
    "ultimas_2_semanas = sorted(dados_teste['semana'].unique())[-2:]\n",
    "\n",
    "pct_zeros_inicio = dados_teste[dados_teste['semana'].isin(primeiras_3_semanas)]['quantidade_prevista'].apply(lambda x: x == 0).mean() * 100\n",
    "pct_zeros_fim = dados_teste[dados_teste['semana'].isin(ultimas_2_semanas)]['quantidade_prevista'].apply(lambda x: x == 0).mean() * 100\n",
    "\n",
    "print(f'üìä Primeiras 3 semanas: {pct_zeros_inicio:.1f}% de previs√µes zero')\n",
    "print(f'üìä √öltimas 2 semanas: {pct_zeros_fim:.1f}% de previs√µes zero')\n",
    "print(f'üìà Aumento: {pct_zeros_fim - pct_zeros_inicio:.1f} pontos percentuais')\n",
    "\n",
    "print('\\nüîç CAUSA PROV√ÅVEL DA ANOMALIA:')\n",
    "print('\\n1. **Depend√™ncia Excessiva de Features de Lag**:')\n",
    "print('   ‚Ä¢ Modelo depende muito das features quantidade_lag_1 a quantidade_lag_4')\n",
    "print('   ‚Ä¢ Ap√≥s 4 semanas de previs√£o, estas features ficam sem hist√≥rico')\n",
    "print('   ‚Ä¢ Pipeline n√£o tem dados \"reais\" para alimentar os lags futuros')\n",
    "\n",
    "print('\\n2. **Degrada√ß√£o das Features de M√©dia M√≥vel**:')\n",
    "print('   ‚Ä¢ Features como quantidade_media_4w tamb√©m perdem qualidade')\n",
    "print('   ‚Ä¢ Calculadas com base em previs√µes, n√£o dados reais')\n",
    "\n",
    "print('\\n3. **Aus√™ncia de Features de Longo Prazo**:')\n",
    "print('   ‚Ä¢ Falta de lag de 52 semanas (sazonalidade anual)')\n",
    "print('   ‚Ä¢ Sem features que capturem padr√µes anuais')\n",
    "\n",
    "print('\\nüí° RECOMENDA√á√ïES PARA CORRE√á√ÉO:')\n",
    "print('\\nüîß **Implementa√ß√£o Imediata**:')\n",
    "print('   1. Adicionar features EWMA (menos sens√≠veis a valores √∫nicos)')\n",
    "print('   2. Incluir features de calend√°rio (semana do ano, m√™s)')\n",
    "print('   3. Adicionar lag de 52 semanas se dados de 2021 dispon√≠veis')\n",
    "print('   4. Features de pre√ßo relativo por categoria')\n",
    "\n",
    "print('\\nüéØ **Estrat√©gia de Valida√ß√£o**:')\n",
    "print('   1. Testar threshold otimizado para WMAPE')\n",
    "print('   2. Validar no conjunto de valida√ß√£o (√∫ltimas 5 semanas de 2022)')\n",
    "print('   3. Monitorar distribui√ß√£o de previs√µes por semana')\n",
    "\n",
    "print('\\nüöÄ **Pr√≥ximos Passos**:')\n",
    "print('   1. Implementar features avan√ßadas no notebook 10')\n",
    "print('   2. Otimizar threshold no notebook 11b')\n",
    "print('   3. Atualizar pipeline final no notebook 13')\n",
    "print('   4. Executar este diagn√≥stico novamente para validar corre√ß√µes')\n",
    "\n",
    "print('\\n‚úÖ Diagn√≥stico conclu√≠do - execute as corre√ß√µes nos notebooks seguintes!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
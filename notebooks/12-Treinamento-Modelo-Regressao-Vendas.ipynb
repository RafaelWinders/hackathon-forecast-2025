{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Modelo de RegressÃ£o (Prever QUANTO vai vender)\n",
    "\n",
    "Este notebook treina o segundo estÃ¡gio do modelo de dois estÃ¡gios: **regressÃ£o**.\n",
    "\n",
    "## Objetivo:\n",
    "- Prever a quantidade de vendas **apenas para casos onde vendeu = 1**\n",
    "- Usar LightGBM Regressor especializado em prever volumes\n",
    "- Avaliar com mÃ©tricas de regressÃ£o (RMSE, MAE, MAPE)\n",
    "- Otimizar para casos com vendas positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Iniciando Treinamento do Modelo de RegressÃ£o\n",
      "ğŸ¯ Objetivo: Prever QUANTO vai vender (apenas onde vendeu = 1)\n",
      "ğŸ“ Pasta data/submissao3 criada/verificada\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, \n",
    "    r2_score\n",
    ")\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('ğŸ“Š Iniciando Treinamento do Modelo de RegressÃ£o')\n",
    "print('ğŸ¯ Objetivo: Prever QUANTO vai vender (apenas onde vendeu = 1)')\n",
    "\n",
    "# Criar pasta submissao3 se nÃ£o existir\n",
    "os.makedirs('../data/submissao3', exist_ok=True)\n",
    "print('ğŸ“ Pasta data/submissao3 criada/verificada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados com Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Carregando dados com features avanÃ§adas...\n",
      "ğŸ‹ï¸ Dados de treino (completos): (50126880, 54)\n",
      "ğŸ” Dados de validaÃ§Ã£o (completos): (5221550, 54)\n",
      "\n",
      "âœ‚ï¸ APLICANDO FILTRO CRÃTICO: apenas registros com vendas...\n",
      "ğŸ‹ï¸ Dados de treino (apenas vendas): (5543608, 54)\n",
      "ğŸ” Dados de validaÃ§Ã£o (apenas vendas): (571729, 54)\n",
      "\n",
      "ğŸ“Š EstatÃ­sticas do target \"quantidade\" no treino:\n",
      "   â€¢ MÃ©dia: 9.10\n",
      "   â€¢ Mediana: 2.00\n",
      "   â€¢ Desvio padrÃ£o: 87.39\n",
      "   â€¢ Min: 1\n",
      "   â€¢ Max: 94230\n",
      "\n",
      "ğŸ“Š EstatÃ­sticas do target \"quantidade\" na validaÃ§Ã£o:\n",
      "   â€¢ MÃ©dia: 5.26\n",
      "   â€¢ Mediana: 2.00\n",
      "   â€¢ Desvio padrÃ£o: 15.82\n",
      "   â€¢ Min: 1\n",
      "   â€¢ Max: 2472\n",
      "âœ… Dados filtrados para regressÃ£o\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados com features avanÃ§adas\n",
    "print('ğŸ“‚ Carregando dados com features avanÃ§adas...')\n",
    "\n",
    "train_features = pd.read_parquet('../data/submissao3/train_features.parquet')\n",
    "validation_features = pd.read_parquet('../data/submissao3/validation_features.parquet')\n",
    "\n",
    "print(f'ğŸ‹ï¸ Dados de treino (completos): {train_features.shape}')\n",
    "print(f'ğŸ” Dados de validaÃ§Ã£o (completos): {validation_features.shape}')\n",
    "\n",
    "# FILTRO CRÃTICO: Manter apenas registros onde vendeu = 1\n",
    "print('\\nâœ‚ï¸ APLICANDO FILTRO CRÃTICO: apenas registros com vendas...')\n",
    "\n",
    "train_sales = train_features[train_features['vendeu'] == 1].copy()\n",
    "validation_sales = validation_features[validation_features['vendeu'] == 1].copy()\n",
    "\n",
    "print(f'ğŸ‹ï¸ Dados de treino (apenas vendas): {train_sales.shape}')\n",
    "print(f'ğŸ” Dados de validaÃ§Ã£o (apenas vendas): {validation_sales.shape}')\n",
    "\n",
    "# Verificar distribuiÃ§Ã£o do target de regressÃ£o\n",
    "print(f'\\nğŸ“Š EstatÃ­sticas do target \"quantidade\" no treino:')\n",
    "print(f'   â€¢ MÃ©dia: {train_sales[\"quantidade\"].mean():.2f}')\n",
    "print(f'   â€¢ Mediana: {train_sales[\"quantidade\"].median():.2f}')\n",
    "print(f'   â€¢ Desvio padrÃ£o: {train_sales[\"quantidade\"].std():.2f}')\n",
    "print(f'   â€¢ Min: {train_sales[\"quantidade\"].min():.0f}')\n",
    "print(f'   â€¢ Max: {train_sales[\"quantidade\"].max():.0f}')\n",
    "\n",
    "print(f'\\nğŸ“Š EstatÃ­sticas do target \"quantidade\" na validaÃ§Ã£o:')\n",
    "print(f'   â€¢ MÃ©dia: {validation_sales[\"quantidade\"].mean():.2f}')\n",
    "print(f'   â€¢ Mediana: {validation_sales[\"quantidade\"].median():.2f}')\n",
    "print(f'   â€¢ Desvio padrÃ£o: {validation_sales[\"quantidade\"].std():.2f}')\n",
    "print(f'   â€¢ Min: {validation_sales[\"quantidade\"].min():.0f}')\n",
    "print(f'   â€¢ Max: {validation_sales[\"quantidade\"].max():.0f}')\n",
    "\n",
    "print('âœ… Dados filtrados para regressÃ£o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PreparaÃ§Ã£o dos Dados para RegressÃ£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Preparando features para regressÃ£o - VERSÃƒO OTIMIZADA...\n",
      "ğŸ“Š Features da classificaÃ§Ã£o (sem leakage): 41\n",
      "ğŸ“Š Features atuais disponÃ­veis para regressÃ£o: 4\n",
      "\n",
      "âœ… FEATURES EXTRAS PARA REGRESSÃƒO (com contexto atual):\n",
      "   â€¢ preco_unitario_atual\n",
      "   â€¢ preco_medio_semanal_sku_atual\n",
      "   â€¢ media_vendas_categoria_pdv_atual\n",
      "   â€¢ share_vendas_sku_categoria_atual\n",
      "\n",
      "ğŸ“Š Total de features para regressÃ£o: 45\n",
      "   ğŸ“Š Features bÃ¡sicas (da classificaÃ§Ã£o): 41\n",
      "   ğŸ“Š Features extras (contexto atual): 4\n",
      "\n",
      "ğŸ“Š Datasets de regressÃ£o preparados:\n",
      "   ğŸ‹ï¸ X_train_reg: (5543608, 45), y_train_reg: (5543608,)\n",
      "   ğŸ” X_val_reg: (571729, 45), y_val_reg: (571729,)\n",
      "   ğŸ§¹ NAs no treino: 0, NAs na validaÃ§Ã£o: 0\n",
      "\n",
      "ğŸ“Š AnÃ¡lise de outliers:\n",
      "   â€¢ P99 da quantidade: 132\n",
      "   â€¢ Outliers acima P99: 53,858 (0.97%)\n",
      "   ğŸ’¡ Mantendo outliers para preservar informaÃ§Ã£o real de vendas grandes\n",
      "âœ… Dados preparados para regressÃ£o com features otimizadas\n"
     ]
    }
   ],
   "source": [
    "# Preparar features para regressÃ£o - VERSÃƒO OTIMIZADA\n",
    "print('ğŸ”§ Preparando features para regressÃ£o - VERSÃƒO OTIMIZADA...')\n",
    "\n",
    "# Carregar lista de features seguras (sem leakage) da classificaÃ§Ã£o\n",
    "with open('../data/submissao3/classification_features.pkl', 'rb') as f:\n",
    "    features_classificacao = pickle.load(f)\n",
    "\n",
    "# Para REGRESSÃƒO, podemos usar algumas features \"atuais\" que foram removidas da classificaÃ§Ã£o\n",
    "# Porque quando fazemos regressÃ£o, jÃ¡ sabemos que vendeu=1, entÃ£o nÃ£o hÃ¡ leakage\n",
    "features_extras_para_regressao = []\n",
    "\n",
    "# Verificar se features \"atuais\" existem nos dados\n",
    "todas_features = list(train_sales.columns)\n",
    "features_atuais_disponiveis = [f for f in todas_features if 'atual' in f]\n",
    "\n",
    "print(f'ğŸ“Š Features da classificaÃ§Ã£o (sem leakage): {len(features_classificacao)}')\n",
    "print(f'ğŸ“Š Features atuais disponÃ­veis para regressÃ£o: {len(features_atuais_disponiveis)}')\n",
    "\n",
    "if features_atuais_disponiveis:\n",
    "    print('\\nâœ… FEATURES EXTRAS PARA REGRESSÃƒO (com contexto atual):')\n",
    "    for feat in features_atuais_disponiveis:\n",
    "        print(f'   â€¢ {feat}')\n",
    "    features_extras_para_regressao = features_atuais_disponiveis\n",
    "else:\n",
    "    print('\\nğŸ“ Nenhuma feature \"atual\" encontrada - usando mesmo conjunto da classificaÃ§Ã£o')\n",
    "\n",
    "# Combinar features: classificaÃ§Ã£o (seguras) + extras para regressÃ£o\n",
    "features_modelo_regressao = features_classificacao + features_extras_para_regressao\n",
    "\n",
    "print(f'\\nğŸ“Š Total de features para regressÃ£o: {len(features_modelo_regressao)}')\n",
    "print(f'   ğŸ“Š Features bÃ¡sicas (da classificaÃ§Ã£o): {len(features_classificacao)}')\n",
    "print(f'   ğŸ“Š Features extras (contexto atual): {len(features_extras_para_regressao)}')\n",
    "\n",
    "# Preparar datasets de regressÃ£o\n",
    "X_train_reg = train_sales[features_modelo_regressao].copy()\n",
    "y_train_reg = train_sales['quantidade'].copy()\n",
    "\n",
    "X_val_reg = validation_sales[features_modelo_regressao].copy()\n",
    "y_val_reg = validation_sales['quantidade'].copy()\n",
    "\n",
    "print(f'\\nğŸ“Š Datasets de regressÃ£o preparados:')\n",
    "print(f'   ğŸ‹ï¸ X_train_reg: {X_train_reg.shape}, y_train_reg: {y_train_reg.shape}')\n",
    "print(f'   ğŸ” X_val_reg: {X_val_reg.shape}, y_val_reg: {y_val_reg.shape}')\n",
    "\n",
    "# Verificar se hÃ¡ NAs\n",
    "nas_train = X_train_reg.isnull().sum().sum()\n",
    "nas_val = X_val_reg.isnull().sum().sum()\n",
    "print(f'   ğŸ§¹ NAs no treino: {nas_train}, NAs na validaÃ§Ã£o: {nas_val}')\n",
    "\n",
    "if nas_train > 0 or nas_val > 0:\n",
    "    print('   âš ï¸ Preenchendo NAs com 0...')\n",
    "    X_train_reg = X_train_reg.fillna(0)\n",
    "    X_val_reg = X_val_reg.fillna(0)\n",
    "\n",
    "# Verificar outliers extremos no target\n",
    "q99 = y_train_reg.quantile(0.99)\n",
    "outliers = (y_train_reg > q99).sum()\n",
    "print(f'\\nğŸ“Š AnÃ¡lise de outliers:')\n",
    "print(f'   â€¢ P99 da quantidade: {q99:.0f}')\n",
    "print(f'   â€¢ Outliers acima P99: {outliers:,} ({outliers/len(y_train_reg)*100:.2f}%)')\n",
    "\n",
    "# Para regressÃ£o, manter outliers Ã© importante para capturar vendas grandes\n",
    "print('   ğŸ’¡ Mantendo outliers para preservar informaÃ§Ã£o real de vendas grandes')\n",
    "\n",
    "print('âœ… Dados preparados para regressÃ£o com features otimizadas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinamento do Modelo LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Treinando LightGBM Regressor...\n",
      "   ğŸ“š Iniciando treinamento...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's l1: 4.78741\tvalid_0's rmse: 13.1673\n",
      "âœ… Modelo treinado! Melhor iteraÃ§Ã£o: 18\n",
      "ğŸ“Š Score de validaÃ§Ã£o: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('l1', np.float64(4.787410554597628)), ('rmse', np.float64(13.167331659008351))])})\n"
     ]
    }
   ],
   "source": [
    "# Configurar e treinar LightGBM Regressor\n",
    "print('ğŸš€ Treinando LightGBM Regressor...')\n",
    "\n",
    "# ParÃ¢metros otimizados para regressÃ£o\n",
    "lgbm_reg_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 80,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 50,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Criar modelo\n",
    "lgbm_regressor = lgb.LGBMRegressor(**lgbm_reg_params)\n",
    "\n",
    "# Treinar modelo com callbacks para early stopping\n",
    "print('   ğŸ“š Iniciando treinamento...')\n",
    "lgbm_regressor.fit(\n",
    "    X_train_reg, y_train_reg,\n",
    "    eval_set=[(X_val_reg, y_val_reg)],\n",
    "    eval_metric=['rmse', 'mae'],\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(f'âœ… Modelo treinado! Melhor iteraÃ§Ã£o: {lgbm_regressor.best_iteration_}')\n",
    "print(f'ğŸ“Š Score de validaÃ§Ã£o: {lgbm_regressor.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AvaliaÃ§Ã£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Avaliando modelo de regressÃ£o...\n",
      "\n",
      "ğŸ“Š MÃ‰TRICAS DE TREINO:\n",
      "   ğŸ“Š RMSE: 68.8696\n",
      "   ğŸ“Š MAE: 6.9484\n",
      "   ğŸ“Š RÂ²: 0.3790\n",
      "   ğŸ“Š MAPE: 240.43%\n",
      "\n",
      "ğŸ“Š MÃ‰TRICAS DE VALIDAÃ‡ÃƒO:\n",
      "   ğŸ“Š RMSE: 13.1673\n",
      "   ğŸ“Š MAE: 4.7874\n",
      "   ğŸ“Š RÂ²: 0.3072\n",
      "   ğŸ“Š MAPE: 230.63%\n",
      "\n",
      "ğŸ“Š ANÃLISE DE RESÃDUOS (ValidaÃ§Ã£o):\n",
      "   ğŸ“Š MÃ©dia dos resÃ­duos: -1.0409\n",
      "   ğŸ“Š Desvio padrÃ£o dos resÃ­duos: 13.1261\n",
      "   ğŸ“Š P25 dos resÃ­duos: -4.1151\n",
      "   ğŸ“Š P75 dos resÃ­duos: -1.5627\n",
      "\n",
      "ğŸ“Š PERFORMANCE POR FAIXA DE QUANTIDADE:\n",
      "   Faixa [  0,   5): MAE=  3.69, Count=426,941\n",
      "   Faixa [  5,  10): MAE=  1.28, Count=67,118\n",
      "   Faixa [ 10,  20): MAE=  4.00, Count=49,800\n",
      "   Faixa [ 20,  50): MAE= 16.16, Count=21,294\n",
      "   Faixa [ 50, 1000): MAE= 79.99, Count= 6,563\n",
      "âœ… AvaliaÃ§Ã£o do modelo de regressÃ£o concluÃ­da\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsÃµes\n",
    "print('ğŸ” Avaliando modelo de regressÃ£o...')\n",
    "\n",
    "# PrevisÃµes\n",
    "y_pred_train_reg = lgbm_regressor.predict(X_train_reg)\n",
    "y_pred_val_reg = lgbm_regressor.predict(X_val_reg)\n",
    "\n",
    "# Garantir que previsÃµes nÃ£o sejam negativas\n",
    "y_pred_train_reg = np.maximum(y_pred_train_reg, 0)\n",
    "y_pred_val_reg = np.maximum(y_pred_val_reg, 0)\n",
    "\n",
    "# FunÃ§Ã£o para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1))) * 100\n",
    "\n",
    "# MÃ©tricas de treino\n",
    "print('\\nğŸ“Š MÃ‰TRICAS DE TREINO:')\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_reg, y_pred_train_reg))\n",
    "mae_train = mean_absolute_error(y_train_reg, y_pred_train_reg)\n",
    "r2_train = r2_score(y_train_reg, y_pred_train_reg)\n",
    "mape_train = mean_absolute_percentage_error(y_train_reg, y_pred_train_reg)\n",
    "\n",
    "print(f'   ğŸ“Š RMSE: {rmse_train:.4f}')\n",
    "print(f'   ğŸ“Š MAE: {mae_train:.4f}')\n",
    "print(f'   ğŸ“Š RÂ²: {r2_train:.4f}')\n",
    "print(f'   ğŸ“Š MAPE: {mape_train:.2f}%')\n",
    "\n",
    "# MÃ©tricas de validaÃ§Ã£o\n",
    "print('\\nğŸ“Š MÃ‰TRICAS DE VALIDAÃ‡ÃƒO:')\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val_reg, y_pred_val_reg))\n",
    "mae_val = mean_absolute_error(y_val_reg, y_pred_val_reg)\n",
    "r2_val = r2_score(y_val_reg, y_pred_val_reg)\n",
    "mape_val = mean_absolute_percentage_error(y_val_reg, y_pred_val_reg)\n",
    "\n",
    "print(f'   ğŸ“Š RMSE: {rmse_val:.4f}')\n",
    "print(f'   ğŸ“Š MAE: {mae_val:.4f}')\n",
    "print(f'   ğŸ“Š RÂ²: {r2_val:.4f}')\n",
    "print(f'   ğŸ“Š MAPE: {mape_val:.2f}%')\n",
    "\n",
    "# AnÃ¡lise de resÃ­duos\n",
    "print('\\nğŸ“Š ANÃLISE DE RESÃDUOS (ValidaÃ§Ã£o):')\n",
    "residuos = y_val_reg - y_pred_val_reg\n",
    "print(f'   ğŸ“Š MÃ©dia dos resÃ­duos: {residuos.mean():.4f}')\n",
    "print(f'   ğŸ“Š Desvio padrÃ£o dos resÃ­duos: {residuos.std():.4f}')\n",
    "print(f'   ğŸ“Š P25 dos resÃ­duos: {residuos.quantile(0.25):.4f}')\n",
    "print(f'   ğŸ“Š P75 dos resÃ­duos: {residuos.quantile(0.75):.4f}')\n",
    "\n",
    "# AnÃ¡lise por faixas de quantidade\n",
    "print('\\nğŸ“Š PERFORMANCE POR FAIXA DE QUANTIDADE:')\n",
    "faixas = [(0, 5), (5, 10), (10, 20), (20, 50), (50, 1000)]\n",
    "for faixa_min, faixa_max in faixas:\n",
    "    mask = (y_val_reg >= faixa_min) & (y_val_reg < faixa_max)\n",
    "    if mask.sum() > 0:\n",
    "        mae_faixa = mean_absolute_error(y_val_reg[mask], y_pred_val_reg[mask])\n",
    "        count_faixa = mask.sum()\n",
    "        print(f'   Faixa [{faixa_min:3d}, {faixa_max:3d}): MAE={mae_faixa:6.2f}, Count={count_faixa:6,}')\n",
    "\n",
    "print('âœ… AvaliaÃ§Ã£o do modelo de regressÃ£o concluÃ­da')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AnÃ¡lise de ImportÃ¢ncia das Features (RegressÃ£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Analisando importÃ¢ncia das features para regressÃ£o...\n",
      "\n",
      "ğŸ† TOP 20 FEATURES MAIS IMPORTANTES (REGRESSÃƒO):\n",
      "    1. share_vendas_sku_categoria_atual -    342\n",
      "    2. produto_hash                   -    175\n",
      "    3. media_vendas_categoria_pdv_atual -    159\n",
      "    4. preco_medio_semanal_sku_atual  -    133\n",
      "    5. preco_relativo_pdv             -     93\n",
      "    6. media_vendas_categoria_pdv_lag_1 -     82\n",
      "    7. preco_lag_1                    -     73\n",
      "    8. preco_relativo_categoria       -     60\n",
      "    9. categoria_zipcode_hash         -     54\n",
      "   10. categoria_hash                 -     37\n",
      "   11. zipcode_hash                   -     33\n",
      "   12. preco_ewma_4w                  -     32\n",
      "   13. pdv_hash                       -     30\n",
      "   14. preco_unitario_atual           -     24\n",
      "   15. quantidade_ewma_8w             -     21\n",
      "   16. preco_lag_2                    -     16\n",
      "   17. pdv_produto_hash               -     14\n",
      "   18. quantidade_max_4w              -     12\n",
      "   19. quantidade_std_4w              -     10\n",
      "   20. quantidade_ewma_4w             -      7\n",
      "\n",
      "ğŸ“Š COMPARANDO COM CLASSIFICAÃ‡ÃƒO:\n",
      "   ğŸ“Š Features em comum no Top 10: 0/10\n",
      "   ğŸ“Š Features comuns: []\n",
      "\n",
      "ğŸ“Š IMPORTÃ‚NCIA POR CATEGORIA (REGRESSÃƒO):\n",
      "   Lag         :      172 (8 features)\n",
      "   Rolling     :       22 (3 features)\n",
      "   PreÃ§o       :      431 (9 features)\n",
      "   CalendÃ¡rio  :      246 (11 features)\n",
      "   TendÃªncia   :        0 (3 features)\n",
      "   Hierarquia  :      583 (4 features)\n",
      "   Hash        :      343 (6 features)\n",
      "âœ… AnÃ¡lise de importÃ¢ncia para regressÃ£o concluÃ­da\n"
     ]
    }
   ],
   "source": [
    "# Analisar importÃ¢ncia das features para regressÃ£o\n",
    "print('ğŸ“Š Analisando importÃ¢ncia das features para regressÃ£o...')\n",
    "\n",
    "# Obter importÃ¢ncias\n",
    "feature_importance_reg = lgbm_regressor.feature_importances_\n",
    "feature_names_reg = X_train_reg.columns\n",
    "\n",
    "# Criar DataFrame de importÃ¢ncias\n",
    "importance_reg_df = pd.DataFrame({\n",
    "    'feature': feature_names_reg,\n",
    "    'importance': feature_importance_reg\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 20 features mais importantes para regressÃ£o\n",
    "print('\\nğŸ† TOP 20 FEATURES MAIS IMPORTANTES (REGRESSÃƒO):')\n",
    "for i, (_, row) in enumerate(importance_reg_df.head(20).iterrows()):\n",
    "    print(f'   {i+1:2d}. {row[\"feature\"]:30s} - {row[\"importance\"]:6.0f}')\n",
    "\n",
    "# Comparar com importÃ¢ncias da classificaÃ§Ã£o\n",
    "print('\\nğŸ“Š COMPARANDO COM CLASSIFICAÃ‡ÃƒO:')\n",
    "classification_importance = pd.read_csv('../data/submissao3/classification_feature_importance.csv')\n",
    "\n",
    "# Top 10 features de cada modelo\n",
    "top_classification = classification_importance.head(10)['feature'].tolist()\n",
    "top_regression = importance_reg_df.head(10)['feature'].tolist()\n",
    "\n",
    "features_em_comum = set(top_classification).intersection(set(top_regression))\n",
    "print(f'   ğŸ“Š Features em comum no Top 10: {len(features_em_comum)}/10')\n",
    "print(f'   ğŸ“Š Features comuns: {list(features_em_comum)}')\n",
    "\n",
    "# AnÃ¡lise por categoria de feature para regressÃ£o\n",
    "print('\\nğŸ“Š IMPORTÃ‚NCIA POR CATEGORIA (REGRESSÃƒO):')\n",
    "categorias_feature = {\n",
    "    'Lag': [f for f in feature_names_reg if 'lag_' in f],\n",
    "    'Rolling': [f for f in feature_names_reg if any(x in f for x in ['media_4w', 'std_4w', 'max_4w'])],\n",
    "    'PreÃ§o': [f for f in feature_names_reg if 'preco' in f],\n",
    "    'CalendÃ¡rio': [f for f in feature_names_reg if any(x in f for x in ['mes', 'dia', 'inicio', 'fim'])],\n",
    "    'TendÃªncia': [f for f in feature_names_reg if any(x in f for x in ['momentum', 'aceleracao'])],\n",
    "    'Hierarquia': [f for f in feature_names_reg if any(x in f for x in ['media_vendas', 'share'])],\n",
    "    'Hash': [f for f in feature_names_reg if 'hash' in f]\n",
    "}\n",
    "\n",
    "for categoria, features in categorias_feature.items():\n",
    "    if features:\n",
    "        importancia_categoria = importance_reg_df[importance_reg_df['feature'].isin(features)]['importance'].sum()\n",
    "        print(f'   {categoria:12s}: {importancia_categoria:8.0f} ({len(features)} features)')\n",
    "\n",
    "print('âœ… AnÃ¡lise de importÃ¢ncia para regressÃ£o concluÃ­da')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento do Modelo de RegressÃ£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Salvando modelo de regressÃ£o OTIMIZADO...\n",
      "âœ… Arquivos salvos:\n",
      "   â€¢ data/submissao3/lgbm_regressor.pkl\n",
      "   â€¢ data/submissao3/regression_features.pkl (SEPARADO da classificaÃ§Ã£o)\n",
      "   â€¢ data/submissao3/regression_feature_importance.csv\n",
      "   â€¢ data/submissao3/lgbm_regressor_metadata.pkl\n",
      "\n",
      "ğŸ‰ MODELO DE REGRESSÃƒO OTIMIZADO TREINADO E SALVO!\n",
      "======================================================================\n",
      "ğŸ¯ Resumo do Modelo de RegressÃ£o OTIMIZADO:\n",
      "   ğŸ“Š RMSE na validaÃ§Ã£o: 13.1673\n",
      "   ğŸ“Š MAE na validaÃ§Ã£o: 4.7874\n",
      "   ğŸ“Š RÂ² na validaÃ§Ã£o: 0.3072\n",
      "   ğŸ“Š MAPE na validaÃ§Ã£o: 230.63%\n",
      "   ğŸ“Š Features totais: 45\n",
      "     â€¢ Features base (sem leakage): 41\n",
      "     â€¢ Features extras (contexto atual): 4\n",
      "   ğŸ“Š Registros de treino: 5,543,608 (apenas com vendas)\n",
      "   ğŸ“Š Registros de validaÃ§Ã£o: 571,729 (apenas com vendas)\n",
      "\n",
      "ğŸ’¡ IMPORTANTE:\n",
      "   ğŸ”„ ClassificaÃ§Ã£o e RegressÃ£o usam features DIFERENTES\n",
      "   ğŸ“Š ClassificaÃ§Ã£o: features seguras (sem leakage)\n",
      "   ğŸ“Š RegressÃ£o: features seguras + contexto atual\n",
      "   ğŸ¯ Isso Ã© CORRETO e esperado!\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo passo:\n",
      "   ğŸ”„ Atualizar pipeline final (Notebook 13) para usar features corretas\n",
      "   ğŸ“Š Aplicar modelos nas 5 semanas de Janeiro 2023\n",
      "\n",
      "ğŸš€ Segundo estÃ¡gio OTIMIZADO concluÃ­do!\n",
      "ğŸ¯ Ambos os modelos estÃ£o prontos e corrigidos!\n"
     ]
    }
   ],
   "source": [
    "# Salvar modelo de regressÃ£o OTIMIZADO\n",
    "print('ğŸ’¾ Salvando modelo de regressÃ£o OTIMIZADO...')\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../data/submissao3/lgbm_regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(lgbm_regressor, f)\n",
    "\n",
    "# IMPORTANTE: Salvar lista de features da regressÃ£o (pode ser diferente da classificaÃ§Ã£o)\n",
    "with open('../data/submissao3/regression_features.pkl', 'wb') as f:\n",
    "    pickle.dump(features_modelo_regressao, f)\n",
    "\n",
    "# Salvar importÃ¢ncias da regressÃ£o\n",
    "importance_reg_df.to_csv('../data/submissao3/regression_feature_importance.csv', index=False)\n",
    "\n",
    "# Salvar metadados do modelo de regressÃ£o OTIMIZADO\n",
    "metadados_regressor = {\n",
    "    'data_criacao': pd.Timestamp.now(),\n",
    "    'modelo': 'LightGBM Regressor OTIMIZADO',\n",
    "    'objetivo': 'RegressÃ£o: prever quantidade de vendas (apenas onde vendeu = 1)',\n",
    "    'parametros': lgbm_reg_params,\n",
    "    'melhor_iteracao': lgbm_regressor.best_iteration_,\n",
    "    'melhor_score': lgbm_regressor.best_score_,\n",
    "    'total_features': len(features_modelo_regressao),\n",
    "    'features_usadas': features_modelo_regressao,\n",
    "    'features_da_classificacao': len(features_classificacao),\n",
    "    'features_extras_regressao': len(features_extras_para_regressao),\n",
    "    'strategy': {\n",
    "        'base_features': 'Mesmas da classificaÃ§Ã£o (sem leakage)',\n",
    "        'extra_features': 'Features com contexto atual (permitidas na regressÃ£o)',\n",
    "        'reasoning': 'RegressÃ£o pode usar contexto atual pois jÃ¡ sabe que vendeu=1'\n",
    "    },\n",
    "    'metricas_validacao': {\n",
    "        'rmse': rmse_val,\n",
    "        'mae': mae_val,\n",
    "        'r2': r2_val,\n",
    "        'mape': mape_val\n",
    "    },\n",
    "    'shape_treino': X_train_reg.shape,\n",
    "    'shape_validacao': X_val_reg.shape,\n",
    "    'target_stats_treino': {\n",
    "        'mean': float(y_train_reg.mean()),\n",
    "        'median': float(y_train_reg.median()),\n",
    "        'std': float(y_train_reg.std()),\n",
    "        'min': float(y_train_reg.min()),\n",
    "        'max': float(y_train_reg.max())\n",
    "    },\n",
    "    'target_stats_validacao': {\n",
    "        'mean': float(y_val_reg.mean()),\n",
    "        'median': float(y_val_reg.median()),\n",
    "        'std': float(y_val_reg.std()),\n",
    "        'min': float(y_val_reg.min()),\n",
    "        'max': float(y_val_reg.max())\n",
    "    },\n",
    "    'observacoes': [\n",
    "        'Modelo treinado APENAS em registros com vendeu=1',\n",
    "        'Pode usar features \"atuais\" pois nÃ£o hÃ¡ leakage na regressÃ£o',\n",
    "        'PrevisÃµes sÃ£o clampadas para >= 0',\n",
    "        'Otimizado para casos com vendas positivas',\n",
    "        'Preserva outliers para capturar vendas grandes',\n",
    "        'Deve ser usado em conjunto com classificador'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('../data/submissao3/lgbm_regressor_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadados_regressor, f)\n",
    "\n",
    "print('âœ… Arquivos salvos:')\n",
    "print('   â€¢ data/submissao3/lgbm_regressor.pkl')\n",
    "print('   â€¢ data/submissao3/regression_features.pkl (SEPARADO da classificaÃ§Ã£o)')\n",
    "print('   â€¢ data/submissao3/regression_feature_importance.csv')\n",
    "print('   â€¢ data/submissao3/lgbm_regressor_metadata.pkl')\n",
    "\n",
    "print('\\nğŸ‰ MODELO DE REGRESSÃƒO OTIMIZADO TREINADO E SALVO!')\n",
    "print('=' * 70)\n",
    "print('ğŸ¯ Resumo do Modelo de RegressÃ£o OTIMIZADO:')\n",
    "print(f'   ğŸ“Š RMSE na validaÃ§Ã£o: {rmse_val:.4f}')\n",
    "print(f'   ğŸ“Š MAE na validaÃ§Ã£o: {mae_val:.4f}')\n",
    "print(f'   ğŸ“Š RÂ² na validaÃ§Ã£o: {r2_val:.4f}')\n",
    "print(f'   ğŸ“Š MAPE na validaÃ§Ã£o: {mape_val:.2f}%')\n",
    "print(f'   ğŸ“Š Features totais: {len(features_modelo_regressao)}')\n",
    "print(f'     â€¢ Features base (sem leakage): {len(features_classificacao)}')\n",
    "print(f'     â€¢ Features extras (contexto atual): {len(features_extras_para_regressao)}')\n",
    "print(f'   ğŸ“Š Registros de treino: {len(X_train_reg):,} (apenas com vendas)')\n",
    "print(f'   ğŸ“Š Registros de validaÃ§Ã£o: {len(X_val_reg):,} (apenas com vendas)')\n",
    "\n",
    "print('\\nğŸ’¡ IMPORTANTE:')\n",
    "print('   ğŸ”„ ClassificaÃ§Ã£o e RegressÃ£o usam features DIFERENTES')\n",
    "print('   ğŸ“Š ClassificaÃ§Ã£o: features seguras (sem leakage)')  \n",
    "print('   ğŸ“Š RegressÃ£o: features seguras + contexto atual')\n",
    "print('   ğŸ¯ Isso Ã© CORRETO e esperado!')\n",
    "\n",
    "print('\\nğŸ’¡ PrÃ³ximo passo:')\n",
    "print('   ğŸ”„ Atualizar pipeline final (Notebook 13) para usar features corretas')\n",
    "print('   ğŸ“Š Aplicar modelos nas 5 semanas de Janeiro 2023')\n",
    "\n",
    "print('\\nğŸš€ Segundo estÃ¡gio OTIMIZADO concluÃ­do!')\n",
    "print('ğŸ¯ Ambos os modelos estÃ£o prontos e corrigidos!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hackathon-forecast)",
   "language": "python",
   "name": "hackathon-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

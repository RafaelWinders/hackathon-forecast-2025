{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Pr√©-processamento e Engenharia de Features\n",
    "\n",
    "Neste notebook vamos transformar os dados brutos em features que o modelo possa usar para previs√£o.\n",
    "\n",
    "## Objetivos:\n",
    "1. **Agrega√ß√£o Semanal**: Agregar dados para n√≠vel semana/pdv/produto\n",
    "2. **Tratamento de Zeros**: Criar grid completo e preencher vendas ausentes como zero\n",
    "3. **Features de Data**: Extrair informa√ß√µes temporais\n",
    "4. **Features de Lag**: Criar features de vendas passadas\n",
    "5. **Features de Janela M√≥vel**: Estat√≠sticas sobre janelas temporais\n",
    "6. **Encoding Categ√≥rico**: Transformar vari√°veis categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Bibliotecas carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print('üìö Bibliotecas carregadas com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dados carregados:\n",
      "   ‚Ä¢ Transa√ß√µes: (6560698, 11)\n",
      "   ‚Ä¢ PDVs: (14419, 4)\n",
      "   ‚Ä¢ Produtos: (7092, 8)\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados das transa√ß√µes\n",
    "transacoes = pd.read_parquet('../data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet')\n",
    "pdvs = pd.read_parquet('../data/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet')\n",
    "produtos = pd.read_parquet('../data/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet')\n",
    "\n",
    "print(f'üìä Dados carregados:')\n",
    "print(f'   ‚Ä¢ Transa√ß√µes: {transacoes.shape}')\n",
    "print(f'   ‚Ä¢ PDVs: {pdvs.shape}')\n",
    "print(f'   ‚Ä¢ Produtos: {produtos.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Estrutura das Transa√ß√µes:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6560698 entries, 0 to 6560697\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   internal_store_id    object \n",
      " 1   internal_product_id  object \n",
      " 2   distributor_id       object \n",
      " 3   transaction_date     object \n",
      " 4   reference_date       object \n",
      " 5   quantity             float64\n",
      " 6   gross_value          float64\n",
      " 7   net_value            float64\n",
      " 8   gross_profit         float64\n",
      " 9   discount             float64\n",
      " 10  taxes                float64\n",
      "dtypes: float64(6), object(5)\n",
      "memory usage: 550.6+ MB\n",
      "None\n",
      "\n",
      "üìà Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internal_store_id</th>\n",
       "      <th>internal_product_id</th>\n",
       "      <th>distributor_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross_value</th>\n",
       "      <th>net_value</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>discount</th>\n",
       "      <th>taxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7384367747233276219</td>\n",
       "      <td>328903483604537190</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.125000</td>\n",
       "      <td>37.890625</td>\n",
       "      <td>10.042625</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>0.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3536908514005606262</td>\n",
       "      <td>5418855670645487653</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107.250000</td>\n",
       "      <td>106.440002</td>\n",
       "      <td>24.732002</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3138231730993449825</td>\n",
       "      <td>1087005562675741887</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.625000</td>\n",
       "      <td>56.220001</td>\n",
       "      <td>14.124002</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3681167389484217654</td>\n",
       "      <td>1401422983880045188</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1037.160023</td>\n",
       "      <td>1037.160023</td>\n",
       "      <td>156.348026</td>\n",
       "      <td>479.880006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7762413312337359369</td>\n",
       "      <td>6614994347738381720</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.230000</td>\n",
       "      <td>23.950241</td>\n",
       "      <td>6.550241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.279758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
       "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
       "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
       "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
       "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
       "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
       "\n",
       "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
       "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
       "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
       "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
       "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
       "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
       "\n",
       "     discount     taxes  \n",
       "0    3.950000  0.234375  \n",
       "1   17.100000  0.810000  \n",
       "2    5.250000  0.405000  \n",
       "3  479.880006  0.000000  \n",
       "4    0.000000  2.279758  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar estrutura dos dados\n",
    "print('üîç Estrutura das Transa√ß√µes:')\n",
    "print(transacoes.info())\n",
    "print('\\nüìà Primeiras linhas:')\n",
    "transacoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepara√ß√£o dos Dados Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Dados preparados: (6560698, 11)\n",
      "üìÖ Per√≠odo dos dados: 2022-01-01 00:00:00 at√© 2022-12-31 00:00:00\n",
      "\n",
      "üîç Colunas dispon√≠veis:\n",
      "['pdv_id', 'produto_id', 'distributor_id', 'data', 'reference_date', 'quantidade', 'valor', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
      "\n",
      "üìä Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdv_id</th>\n",
       "      <th>produto_id</th>\n",
       "      <th>distributor_id</th>\n",
       "      <th>data</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>quantidade</th>\n",
       "      <th>valor</th>\n",
       "      <th>net_value</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>discount</th>\n",
       "      <th>taxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7384367747233276219</td>\n",
       "      <td>328903483604537190</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.125000</td>\n",
       "      <td>37.890625</td>\n",
       "      <td>10.042625</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>0.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3536908514005606262</td>\n",
       "      <td>5418855670645487653</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107.250000</td>\n",
       "      <td>106.440002</td>\n",
       "      <td>24.732002</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3138231730993449825</td>\n",
       "      <td>1087005562675741887</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.625000</td>\n",
       "      <td>56.220001</td>\n",
       "      <td>14.124002</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3681167389484217654</td>\n",
       "      <td>1401422983880045188</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1037.160023</td>\n",
       "      <td>1037.160023</td>\n",
       "      <td>156.348026</td>\n",
       "      <td>479.880006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7762413312337359369</td>\n",
       "      <td>6614994347738381720</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.230000</td>\n",
       "      <td>23.950241</td>\n",
       "      <td>6.550241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.279758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pdv_id           produto_id distributor_id       data  \\\n",
       "0  7384367747233276219   328903483604537190              9 2022-07-13   \n",
       "1  3536908514005606262  5418855670645487653              5 2022-03-21   \n",
       "2  3138231730993449825  1087005562675741887              6 2022-09-06   \n",
       "3  3681167389484217654  1401422983880045188              5 2022-09-11   \n",
       "4  7762413312337359369  6614994347738381720              4 2022-02-18   \n",
       "\n",
       "  reference_date  quantidade        valor    net_value  gross_profit  \\\n",
       "0     2022-07-01         1.0    38.125000    37.890625     10.042625   \n",
       "1     2022-03-01         6.0   107.250000   106.440002     24.732002   \n",
       "2     2022-09-01         3.0    56.625000    56.220001     14.124002   \n",
       "3     2022-09-01       129.0  1037.160023  1037.160023    156.348026   \n",
       "4     2022-02-01         1.0    26.230000    23.950241      6.550241   \n",
       "\n",
       "     discount     taxes  \n",
       "0    3.950000  0.234375  \n",
       "1   17.100000  0.810000  \n",
       "2    5.250000  0.405000  \n",
       "3  479.880006  0.000000  \n",
       "4    0.000000  2.279758  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer merge dos dados baseado na estrutura real dos dados\n",
    "# Transa√ß√µes: internal_store_id, internal_product_id\n",
    "# PDVs: tem coluna 'pdv'  \n",
    "# Produtos: n√£o tem ID espec√≠fico, apenas informa√ß√µes categ√≥ricas\n",
    "\n",
    "# Como n√£o h√° chaves diretas para merge, vamos trabalhar apenas com os dados de transa√ß√µes\n",
    "dados = transacoes.copy()\n",
    "\n",
    "# Renomear colunas para padronizar\n",
    "dados = dados.rename(columns={\n",
    "    'internal_store_id': 'pdv_id',\n",
    "    'internal_product_id': 'produto_id',\n",
    "    'transaction_date': 'data',\n",
    "    'quantity': 'quantidade',\n",
    "    'gross_value': 'valor'\n",
    "})\n",
    "\n",
    "# Converter data para datetime\n",
    "dados['data'] = pd.to_datetime(dados['data'])\n",
    "\n",
    "print(f'üîó Dados preparados: {dados.shape}')\n",
    "print(f'üìÖ Per√≠odo dos dados: {dados[\"data\"].min()} at√© {dados[\"data\"].max()}')\n",
    "\n",
    "# Verificar estrutura\n",
    "print('\\nüîç Colunas dispon√≠veis:')\n",
    "print(dados.columns.tolist())\n",
    "print('\\nüìä Primeiras linhas:')\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agrega√ß√£o Semanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Colunas de tempo criadas:\n",
      "   ‚Ä¢ Primeira semana: 2021-12-28 00:00:00\n",
      "   ‚Ä¢ √öltima semana: 2022-12-27 00:00:00\n",
      "   ‚Ä¢ Total de semanas: 53\n"
     ]
    }
   ],
   "source": [
    "# Criar coluna de semana do ano\n",
    "dados['semana'] = dados['data'].dt.to_period('W-MON').dt.start_time\n",
    "dados['ano'] = dados['data'].dt.year\n",
    "dados['semana_ano'] = dados['data'].dt.isocalendar().week\n",
    "dados['mes'] = dados['data'].dt.month\n",
    "dados['dia_semana'] = dados['data'].dt.dayofweek\n",
    "\n",
    "print('üìÖ Colunas de tempo criadas:')\n",
    "print(f'   ‚Ä¢ Primeira semana: {dados[\"semana\"].min()}')\n",
    "print(f'   ‚Ä¢ √öltima semana: {dados[\"semana\"].max()}')\n",
    "print(f'   ‚Ä¢ Total de semanas: {dados[\"semana\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Agrega√ß√£o semanal criada: (6241315, 6)\n",
      "   ‚Ä¢ Combina√ß√µes semana/PDV/produto: 6241315\n",
      "   ‚Ä¢ PDVs √∫nicos: 15086\n",
      "   ‚Ä¢ Produtos √∫nicos: 7092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semana</th>\n",
       "      <th>pdv_id</th>\n",
       "      <th>produto_id</th>\n",
       "      <th>quantidade</th>\n",
       "      <th>valor</th>\n",
       "      <th>num_transacoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>1008240744247283174</td>\n",
       "      <td>1938760505411922162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>1008240744247283174</td>\n",
       "      <td>4098058333001424920</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>10097752152132198</td>\n",
       "      <td>1938760505411922162</td>\n",
       "      <td>2.0</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>10097752152132198</td>\n",
       "      <td>8174625658473329985</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>1020491045469449287</td>\n",
       "      <td>6766604540402338857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      semana               pdv_id           produto_id  quantidade  \\\n",
       "0 2021-12-28  1008240744247283174  1938760505411922162         1.0   \n",
       "1 2021-12-28  1008240744247283174  4098058333001424920         2.0   \n",
       "2 2021-12-28    10097752152132198  1938760505411922162         2.0   \n",
       "3 2021-12-28    10097752152132198  8174625658473329985         2.0   \n",
       "4 2021-12-28  1020491045469449287  6766604540402338857         3.0   \n",
       "\n",
       "        valor  num_transacoes  \n",
       "0  111.500000               1  \n",
       "1   47.099998               1  \n",
       "2  223.000000               1  \n",
       "3   57.500000               1  \n",
       "4   72.000000               1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrega√ß√£o semanal por PDV e Produto\n",
    "agregacao_semanal = dados.groupby(['semana', 'pdv_id', 'produto_id']).agg({\n",
    "    'quantidade': 'sum',\n",
    "    'valor': 'sum',\n",
    "    'distributor_id': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "agregacao_semanal = agregacao_semanal.rename(columns={\n",
    "    'distributor_id': 'num_transacoes'\n",
    "})\n",
    "\n",
    "print(f'üìä Agrega√ß√£o semanal criada: {agregacao_semanal.shape}')\n",
    "print(f'   ‚Ä¢ Combina√ß√µes semana/PDV/produto: {len(agregacao_semanal)}')\n",
    "print(f'   ‚Ä¢ PDVs √∫nicos: {agregacao_semanal[\"pdv_id\"].nunique()}')\n",
    "print(f'   ‚Ä¢ Produtos √∫nicos: {agregacao_semanal[\"produto_id\"].nunique()}')\n",
    "\n",
    "agregacao_semanal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üéØ Cria√ß√£o do DataFrame Mestre com Tratamento de Zeros\n",
    "\n",
    "**Importante**: Zeros s√£o informa√ß√µes valiosas! A aus√™ncia de venda (PDV/produto) em uma semana espec√≠fica √© um dado importante para forecasting. \n",
    "\n",
    "Vamos criar um DataFrame \"mestre\" com todas as combina√ß√µes poss√≠veis usando uma abordagem otimizada por lotes para evitar problemas de mem√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Dimens√µes do problema:\n",
      "   ‚Ä¢ Semanas: 52\n",
      "   ‚Ä¢ PDVs √∫nicos: 15,086\n",
      "   ‚Ä¢ Produtos √∫nicos: 7,092\n",
      "   ‚Ä¢ Total de combina√ß√µes: 5,563,475,424\n",
      "   ‚Ä¢ Mem√≥ria estimada: ~248.7GB\n",
      "\n",
      "‚ö†Ô∏è  Dataset muito grande (248.7GB)\n",
      "üí° Recomenda√ß√µes para rodar:\n",
      "   1. Usar abordagem de lotes (implementada abaixo)\n",
      "   2. Considerar usar apenas combina√ß√µes PDV/produto ativas\n",
      "   3. Filtrar por per√≠odo espec√≠fico se necess√°rio\n",
      "   4. Usar m√°quina com mais RAM (32GB+)\n",
      "\n",
      "üîÑ Escolha da estrat√©gia:\n",
      "   ‚Ä¢ COMPLETA: Grid com todos os zeros (melhor para ML)\n",
      "   ‚Ä¢ SIMPLIFICADA: Apenas dados existentes (economiza mem√≥ria)\n",
      "\n",
      "üìä Taxa de sparsity esperada: 99.9%\n",
      "   ‚Ä¢ Registros com venda: 6,241,315\n",
      "   ‚Ä¢ Zeros esperados: 5,557,234,109\n"
     ]
    }
   ],
   "source": [
    "# An√°lise das dimens√µes do problema e decis√£o da estrat√©gia\n",
    "semanas_unicas = pd.date_range(\n",
    "    start=dados['semana'].min(),\n",
    "    end=dados['semana'].max(),\n",
    "    freq='W-MON'\n",
    ")\n",
    "\n",
    "pdvs_unicos = dados['pdv_id'].unique()\n",
    "produtos_unicos = dados['produto_id'].unique()\n",
    "\n",
    "total_combinations = len(semanas_unicas) * len(pdvs_unicos) * len(produtos_unicos)\n",
    "estimated_memory_gb = (total_combinations * 8 * 6) / (1024**3)\n",
    "\n",
    "print(f'üî¢ Dimens√µes do problema:')\n",
    "print(f'   ‚Ä¢ Semanas: {len(semanas_unicas):,}')\n",
    "print(f'   ‚Ä¢ PDVs √∫nicos: {len(pdvs_unicos):,}')\n",
    "print(f'   ‚Ä¢ Produtos √∫nicos: {len(produtos_unicos):,}')\n",
    "print(f'   ‚Ä¢ Total de combina√ß√µes: {total_combinations:,}')\n",
    "print(f'   ‚Ä¢ Mem√≥ria estimada: ~{estimated_memory_gb:.1f}GB')\n",
    "\n",
    "# Decis√£o baseada na mem√≥ria dispon√≠vel\n",
    "if estimated_memory_gb > 16:  # Se precisar de mais que 16GB\n",
    "    print(f'\\n‚ö†Ô∏è  Dataset muito grande ({estimated_memory_gb:.1f}GB)')\n",
    "    print('üí° Recomenda√ß√µes para rodar:')\n",
    "    print('   1. Usar abordagem de lotes (implementada abaixo)')\n",
    "    print('   2. Considerar usar apenas combina√ß√µes PDV/produto ativas')\n",
    "    print('   3. Filtrar por per√≠odo espec√≠fico se necess√°rio')\n",
    "    print('   4. Usar m√°quina com mais RAM (32GB+)')\n",
    "    \n",
    "    # Dar op√ß√£o de usar abordagem simplificada\n",
    "    print('\\nüîÑ Escolha da estrat√©gia:')\n",
    "    print('   ‚Ä¢ COMPLETA: Grid com todos os zeros (melhor para ML)')\n",
    "    print('   ‚Ä¢ SIMPLIFICADA: Apenas dados existentes (economiza mem√≥ria)')\n",
    "else:\n",
    "    print(f'\\n‚úÖ Tamanho gerenci√°vel ({estimated_memory_gb:.1f}GB)')\n",
    "    print('üöÄ Prosseguindo com cria√ß√£o do grid completo')\n",
    "\n",
    "# Mostrar taxa de sparsity esperada\n",
    "existing_combinations = len(agregacao_semanal)\n",
    "sparsity_rate = (1 - existing_combinations / total_combinations) * 100\n",
    "print(f'\\nüìä Taxa de sparsity esperada: {sparsity_rate:.1f}%')\n",
    "print(f'   ‚Ä¢ Registros com venda: {existing_combinations:,}')\n",
    "print(f'   ‚Ä¢ Zeros esperados: {total_combinations - existing_combinations:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando cria√ß√£o otimizada do grid com zeros...\n",
      "üìä Analisando combina√ß√µes ativas...\n",
      "   ‚Ä¢ Combina√ß√µes PDV/produto com hist√≥rico de vendas: 1,044,310\n",
      "üéØ Dimens√µes do grid otimizado:\n",
      "   ‚Ä¢ Semanas: 52\n",
      "   ‚Ä¢ Combina√ß√µes ativas: 1,044,310\n",
      "   ‚Ä¢ Total de registros: 54,304,120\n",
      "   ‚Ä¢ Mem√≥ria estimada: ~2.4GB\n",
      "   ‚Ä¢ Redu√ß√£o: 99.0% menos mem√≥ria\n",
      "üíæ Processando em 105 lotes de at√© 10000 combina√ß√µes cada\n",
      "   üì¶ Lote 1/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 2/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 3/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 4/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 5/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 5 lotes\n",
      "   üì¶ Lote 6/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 7/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 8/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 9/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 10/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 10 lotes\n",
      "   üì¶ Lote 11/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 12/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 13/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 14/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 15/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 15 lotes\n",
      "   üì¶ Lote 16/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 17/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 18/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 19/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 20/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 20 lotes\n",
      "   üì¶ Lote 21/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 22/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 23/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 24/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 25/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 25 lotes\n",
      "   üì¶ Lote 26/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 27/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 28/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 29/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 30/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 30 lotes\n",
      "   üì¶ Lote 31/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 32/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 33/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 34/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 35/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 35 lotes\n",
      "   üì¶ Lote 36/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 37/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 38/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 39/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 40/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 40 lotes\n",
      "   üì¶ Lote 41/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 42/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 43/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 44/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 45/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 45 lotes\n",
      "   üì¶ Lote 46/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 47/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 48/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 49/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 50/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 50 lotes\n",
      "   üì¶ Lote 51/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 52/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 53/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 54/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 55/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 55 lotes\n",
      "   üì¶ Lote 56/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 57/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 58/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 59/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 60/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 60 lotes\n",
      "   üì¶ Lote 61/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 62/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 63/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 64/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 65/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 65 lotes\n",
      "   üì¶ Lote 66/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 67/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 68/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 69/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 70/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 70 lotes\n",
      "   üì¶ Lote 71/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 72/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 73/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 74/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 75/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 75 lotes\n",
      "   üì¶ Lote 76/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 77/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 78/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 79/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 80/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 80 lotes\n",
      "   üì¶ Lote 81/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 82/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 83/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 84/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 85/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 85 lotes\n",
      "   üì¶ Lote 86/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 87/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 88/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 89/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 90/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 90 lotes\n",
      "   üì¶ Lote 91/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 92/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 93/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 94/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 95/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 95 lotes\n",
      "   üì¶ Lote 96/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 97/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 98/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 99/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 100/105: 10000 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 100 lotes\n",
      "   üì¶ Lote 101/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 102/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 103/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 104/105: 10000 combina√ß√µes\n",
      "   üì¶ Lote 105/105: 4310 combina√ß√µes\n",
      "     ‚úÖ Conclu√≠dos 105 lotes\n",
      "üîó Concatenando todos os lotes...\n",
      "\n",
      "üéØ Grid otimizado criado!\n",
      "   ‚Ä¢ Shape final: (54304120, 6)\n",
      "   ‚Ä¢ Mem√≥ria utilizada: 8.48 GB\n",
      "   ‚Ä¢ Vendas = 0: 54,304,120 registros (100.0%)\n",
      "   ‚Ä¢ Vendas > 0: 0 registros (0.0%)\n",
      "   ‚Ä¢ Semanas por combina√ß√£o (deve ser 52): [52]\n",
      "‚úÖ Zeros preservados de forma otimizada - informa√ß√£o valiosa para forecasting!\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Estrat√©gia otimizada: Grid Inteligente com Zeros\n",
    "# Em vez de criar TODAS as combina√ß√µes, vamos criar um grid que:\n",
    "# 1. Inclui todas as combina√ß√µes que j√° existem nos dados\n",
    "# 2. Adiciona zeros para combina√ß√µes PDV/produto ativas em semanas sem venda\n",
    "# 3. Evita combina√ß√µes nunca vendidas (economiza 99.9% da mem√≥ria)\n",
    "\n",
    "import gc\n",
    "from itertools import product\n",
    "\n",
    "print('üîÑ Iniciando cria√ß√£o otimizada do grid com zeros...')\n",
    "\n",
    "# Estrat√©gia 1: Identificar combina√ß√µes PDV/produto ativas\n",
    "print('üìä Analisando combina√ß√µes ativas...')\n",
    "combinacoes_ativas = agregacao_semanal[['pdv_id', 'produto_id']].drop_duplicates()\n",
    "print(f'   ‚Ä¢ Combina√ß√µes PDV/produto com hist√≥rico de vendas: {len(combinacoes_ativas):,}')\n",
    "\n",
    "# Calcular tamanho otimizado\n",
    "total_combinations_otimizado = len(semanas_unicas) * len(combinacoes_ativas)\n",
    "estimated_memory_gb_otimizado = (total_combinations_otimizado * 8 * 6) / (1024**3)\n",
    "\n",
    "print(f'üéØ Dimens√µes do grid otimizado:')\n",
    "print(f'   ‚Ä¢ Semanas: {len(semanas_unicas):,}')\n",
    "print(f'   ‚Ä¢ Combina√ß√µes ativas: {len(combinacoes_ativas):,}')\n",
    "print(f'   ‚Ä¢ Total de registros: {total_combinations_otimizado:,}')\n",
    "print(f'   ‚Ä¢ Mem√≥ria estimada: ~{estimated_memory_gb_otimizado:.1f}GB')\n",
    "print(f'   ‚Ä¢ Redu√ß√£o: {(1 - estimated_memory_gb_otimizado/248.7)*100:.1f}% menos mem√≥ria')\n",
    "\n",
    "# Processar em lotes menores para evitar problemas de mem√≥ria\n",
    "batch_size = 10000  # 10k combina√ß√µes por vez\n",
    "combinacao_batches = [combinacoes_ativas.iloc[i:i+batch_size] for i in range(0, len(combinacoes_ativas), batch_size)]\n",
    "\n",
    "print(f'üíæ Processando em {len(combinacao_batches)} lotes de at√© {batch_size} combina√ß√µes cada')\n",
    "\n",
    "dados_mestre = []\n",
    "\n",
    "for batch_num, combo_batch in enumerate(combinacao_batches):\n",
    "    print(f'   üì¶ Lote {batch_num+1}/{len(combinacao_batches)}: {len(combo_batch)} combina√ß√µes')\n",
    "    \n",
    "    # Criar grid completo para este lote de combina√ß√µes\n",
    "    grid_lote = []\n",
    "    \n",
    "    for _, row in combo_batch.iterrows():\n",
    "        pdv_id = row['pdv_id']\n",
    "        produto_id = row['produto_id']\n",
    "        \n",
    "        # Grid completo de semanas para esta combina√ß√£o\n",
    "        grid_combo = pd.DataFrame({\n",
    "            'semana': semanas_unicas,\n",
    "            'pdv_id': pdv_id,\n",
    "            'produto_id': produto_id\n",
    "        })\n",
    "        grid_lote.append(grid_combo)\n",
    "    \n",
    "    # Concatenar todas as combina√ß√µes deste lote\n",
    "    grid_completo_lote = pd.concat(grid_lote, ignore_index=True)\n",
    "    \n",
    "    # Merge com vendas reais (muito mais eficiente agora)\n",
    "    grid_completo_lote = grid_completo_lote.merge(\n",
    "        agregacao_semanal,\n",
    "        on=['semana', 'pdv_id', 'produto_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Preencher zeros\n",
    "    grid_completo_lote['quantidade'] = grid_completo_lote['quantidade'].fillna(0)\n",
    "    grid_completo_lote['valor'] = grid_completo_lote['valor'].fillna(0)\n",
    "    grid_completo_lote['num_transacoes'] = grid_completo_lote['num_transacoes'].fillna(0)\n",
    "    \n",
    "    dados_mestre.append(grid_completo_lote)\n",
    "    \n",
    "    # Limpeza de mem√≥ria\n",
    "    del grid_lote, grid_completo_lote\n",
    "    gc.collect()\n",
    "    \n",
    "    # Log de progresso\n",
    "    if (batch_num + 1) % 5 == 0 or batch_num == len(combinacao_batches) - 1:\n",
    "        print(f'     ‚úÖ Conclu√≠dos {batch_num+1} lotes')\n",
    "\n",
    "print('üîó Concatenando todos os lotes...')\n",
    "dados_completos = pd.concat(dados_mestre, ignore_index=True)\n",
    "\n",
    "print(f'\\nüéØ Grid otimizado criado!')\n",
    "print(f'   ‚Ä¢ Shape final: {dados_completos.shape}')\n",
    "print(f'   ‚Ä¢ Mem√≥ria utilizada: {dados_completos.memory_usage(deep=True).sum() / (1024**3):.2f} GB')\n",
    "print(f'   ‚Ä¢ Vendas = 0: {(dados_completos[\"quantidade\"] == 0).sum():,} registros ({(dados_completos[\"quantidade\"] == 0).mean()*100:.1f}%)')\n",
    "print(f'   ‚Ä¢ Vendas > 0: {(dados_completos[\"quantidade\"] > 0).sum():,} registros ({(dados_completos[\"quantidade\"] > 0).mean()*100:.1f}%)')\n",
    "\n",
    "# Verificar que temos dados de todas as combina√ß√µes ativas em todas as semanas\n",
    "verificacao = dados_completos.groupby(['pdv_id', 'produto_id']).size()\n",
    "print(f'   ‚Ä¢ Semanas por combina√ß√£o (deve ser {len(semanas_unicas)}): {verificacao.unique()}')\n",
    "\n",
    "# Limpeza final\n",
    "del dados_mestre, combinacoes_ativas\n",
    "gc.collect()\n",
    "\n",
    "print('‚úÖ Zeros preservados de forma otimizada - informa√ß√£o valiosa para forecasting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Criando features est√°ticas hist√≥ricas...\n",
      "üîó Adicionando features hist√≥ricas ao grid completo...\n",
      "‚úÖ Features hist√≥ricas criadas:\n",
      "   ‚Ä¢ Shape ap√≥s enriquecimento: (54304120, 19)\n",
      "   ‚Ä¢ Novas features adicionadas: 13\n",
      "üìã Resumo das features hist√≥ricas:\n",
      "   1. semana_primeira_venda / semana_ultima_venda\n",
      "   2. tempo_atividade_semanas / frequencia_vendas\n",
      "   3. quantidade_media_historica / preco_medio_unitario\n",
      "   4. regularidade_vendas / categoria_volume\n",
      "   5. semanas_desde_primeira_venda / produto_ativo\n",
      "   6. semanas_ate_ultima_venda\n",
      "üöÄ Grid Inteligente enriquecido com contexto hist√≥rico completo!\n"
     ]
    }
   ],
   "source": [
    "# üìä Features Est√°ticas Hist√≥ricas para Grid Inteligente\n",
    "# Estas features capturam o contexto hist√≥rico de cada combina√ß√£o PDV/produto\n",
    "# antes de calcular lags e janelas m√≥veis\n",
    "\n",
    "print('üìà Criando features est√°ticas hist√≥ricas...')\n",
    "\n",
    "# 1. An√°lise hist√≥rica de cada combina√ß√£o PDV/produto\n",
    "historico_combos = agregacao_semanal[agregacao_semanal['quantidade'] > 0].groupby(['pdv_id', 'produto_id']).agg({\n",
    "    'semana': ['min', 'max', 'count'],\n",
    "    'quantidade': ['mean', 'sum', 'std', 'min', 'max'],\n",
    "    'valor': ['mean', 'sum'],\n",
    "    'num_transacoes': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "historico_combos.columns = ['pdv_id', 'produto_id', \n",
    "                           'semana_primeira_venda', 'semana_ultima_venda', 'semanas_ativas',\n",
    "                           'quantidade_media_historica', 'quantidade_total_historica', 'quantidade_std_historica',\n",
    "                           'quantidade_min_historica', 'quantidade_max_historica',\n",
    "                           'valor_medio_historico', 'valor_total_historico', 'transacoes_total_historico']\n",
    "\n",
    "# 2. Calcular features derivadas\n",
    "# Tempo total de atividade (primeira at√© √∫ltima venda)\n",
    "historico_combos['tempo_atividade_semanas'] = (\n",
    "    historico_combos['semana_ultima_venda'] - historico_combos['semana_primeira_venda']\n",
    ").dt.days / 7\n",
    "\n",
    "# Frequ√™ncia de vendas (% de semanas com venda no per√≠odo ativo)\n",
    "historico_combos['frequencia_vendas'] = (\n",
    "    historico_combos['semanas_ativas'] / (historico_combos['tempo_atividade_semanas'] + 1)\n",
    ").fillna(1.0)  # Para produtos com apenas 1 venda, frequ√™ncia = 100%\n",
    "\n",
    "# Pre√ßo m√©dio por unidade\n",
    "historico_combos['preco_medio_unitario'] = (\n",
    "    historico_combos['valor_total_historico'] / historico_combos['quantidade_total_historica']\n",
    ").fillna(0)\n",
    "\n",
    "# Regularidade de vendas (coeficiente de varia√ß√£o)\n",
    "historico_combos['regularidade_vendas'] = (\n",
    "    historico_combos['quantidade_std_historica'] / (historico_combos['quantidade_media_historica'] + 1e-8)\n",
    ").fillna(0)\n",
    "\n",
    "# 3. Categoriza√ß√£o de produtos por comportamento\n",
    "# Definir quartis para categorizar produtos\n",
    "q25, q75 = historico_combos['quantidade_media_historica'].quantile([0.25, 0.75])\n",
    "\n",
    "historico_combos['categoria_volume'] = np.where(\n",
    "    historico_combos['quantidade_media_historica'] <= q25, 'Baixo',\n",
    "    np.where(historico_combos['quantidade_media_historica'] >= q75, 'Alto', 'Medio')\n",
    ")\n",
    "\n",
    "# 4. Features temporais relativas\n",
    "# Semanas desde primeira venda (calculado para cada semana do grid)\n",
    "primeira_semana_dataset = semanas_unicas.min()\n",
    "historico_combos['semanas_desde_primeira_venda_inicio'] = (\n",
    "    historico_combos['semana_primeira_venda'] - primeira_semana_dataset\n",
    ").dt.days / 7\n",
    "\n",
    "# 5. Merge com dados completos\n",
    "print('üîó Adicionando features hist√≥ricas ao grid completo...')\n",
    "dados_completos_enriquecido = dados_completos.merge(\n",
    "    historico_combos[['pdv_id', 'produto_id', 'semana_primeira_venda', 'semana_ultima_venda', \n",
    "                      'semanas_ativas', 'tempo_atividade_semanas', 'frequencia_vendas',\n",
    "                      'quantidade_media_historica', 'preco_medio_unitario', 'regularidade_vendas',\n",
    "                      'categoria_volume', 'semanas_desde_primeira_venda_inicio']],\n",
    "    on=['pdv_id', 'produto_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 6. Features temporais din√¢micas (calculadas para cada semana)\n",
    "dados_completos_enriquecido['semanas_desde_primeira_venda'] = (\n",
    "    dados_completos_enriquecido['semana'] - dados_completos_enriquecido['semana_primeira_venda']\n",
    ").dt.days / 7\n",
    "\n",
    "dados_completos_enriquecido['semanas_ate_ultima_venda'] = (\n",
    "    dados_completos_enriquecido['semana_ultima_venda'] - dados_completos_enriquecido['semana']\n",
    ").dt.days / 7\n",
    "\n",
    "# 7. Feature de \"sa√∫de\" do produto no PDV\n",
    "# Produtos com √∫ltima venda h√° muito tempo podem estar sendo descontinuados\n",
    "dados_completos_enriquecido['produto_ativo'] = (\n",
    "    dados_completos_enriquecido['semanas_ate_ultima_venda'] >= -4  # Vendeu nas √∫ltimas 4 semanas do dataset\n",
    ").astype(int)\n",
    "\n",
    "print(f'‚úÖ Features hist√≥ricas criadas:')\n",
    "print(f'   ‚Ä¢ Shape ap√≥s enriquecimento: {dados_completos_enriquecido.shape}')\n",
    "print(f'   ‚Ä¢ Novas features adicionadas: {dados_completos_enriquecido.shape[1] - dados_completos.shape[1]}')\n",
    "\n",
    "# Substituir dados_completos pela vers√£o enriquecida\n",
    "dados_completos = dados_completos_enriquecido\n",
    "del dados_completos_enriquecido\n",
    "gc.collect()\n",
    "\n",
    "print('üìã Resumo das features hist√≥ricas:')\n",
    "print('   1. semana_primeira_venda / semana_ultima_venda')\n",
    "print('   2. tempo_atividade_semanas / frequencia_vendas') \n",
    "print('   3. quantidade_media_historica / preco_medio_unitario')\n",
    "print('   4. regularidade_vendas / categoria_volume')\n",
    "print('   5. semanas_desde_primeira_venda / produto_ativo')\n",
    "print('   6. semanas_ate_ultima_venda')\n",
    "\n",
    "print('üöÄ Grid Inteligente enriquecido com contexto hist√≥rico completo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Adicionando informa√ß√µes categ√≥ricas...\n",
      "   ‚Ä¢ Informa√ß√µes de PDV: (15086, 4)\n",
      "   ‚Ä¢ Informa√ß√µes de produto: (7092, 2)\n",
      "\n",
      "‚úÖ Informa√ß√µes categ√≥ricas adicionadas:\n",
      "   ‚Ä¢ Distribuidores √∫nicos: 8\n",
      "   ‚Ä¢ PDV hash valores √∫nicos: 100\n",
      "   ‚Ä¢ Produto hash valores √∫nicos: 100\n",
      "\n",
      "üîç Valores nulos encontrados:\n",
      "semana_primeira_venda                  1130376\n",
      "semana_ultima_venda                    1130376\n",
      "semanas_ativas                         1130376\n",
      "tempo_atividade_semanas                1130376\n",
      "frequencia_vendas                      1130376\n",
      "quantidade_media_historica             1130376\n",
      "preco_medio_unitario                   1130376\n",
      "regularidade_vendas                    1130376\n",
      "categoria_volume                       1130376\n",
      "semanas_desde_primeira_venda_inicio    1130376\n",
      "semanas_desde_primeira_venda           1130376\n",
      "semanas_ate_ultima_venda               1130376\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# üè∑Ô∏è Adicionando informa√ß√µes categ√≥ricas dos PDVs e Produtos\n",
    "print('üîó Adicionando informa√ß√µes categ√≥ricas...')\n",
    "\n",
    "# Criar mapeamentos dos dados auxiliares\n",
    "# Para PDVs - usar o hash do ID como proxy, mas tamb√©m tentar extrair informa√ß√µes dos dados auxiliares\n",
    "pdv_info = dados.groupby('pdv_id').first()[['distributor_id']].reset_index()\n",
    "pdv_info['pdv_hash'] = pdv_info['pdv_id'].astype(str).apply(hash) % 100\n",
    "pdv_info['distributor_encoded'] = pd.factorize(pdv_info['distributor_id'])[0]\n",
    "\n",
    "# Para produtos - usar hash como proxy categ√≥rico\n",
    "produto_info = pd.DataFrame({\n",
    "    'produto_id': produtos_unicos,\n",
    "    'produto_hash': [hash(str(pid)) % 100 for pid in produtos_unicos]\n",
    "})\n",
    "\n",
    "print(f'   ‚Ä¢ Informa√ß√µes de PDV: {pdv_info.shape}')\n",
    "print(f'   ‚Ä¢ Informa√ß√µes de produto: {produto_info.shape}')\n",
    "\n",
    "# Fazer merge com dados completos\n",
    "dados_completos = dados_completos.merge(pdv_info, on='pdv_id', how='left')\n",
    "dados_completos = dados_completos.merge(produto_info, on='produto_id', how='left')\n",
    "\n",
    "print(f'\\n‚úÖ Informa√ß√µes categ√≥ricas adicionadas:')\n",
    "print(f'   ‚Ä¢ Distribuidores √∫nicos: {dados_completos[\"distributor_id\"].nunique()}')\n",
    "print(f'   ‚Ä¢ PDV hash valores √∫nicos: {dados_completos[\"pdv_hash\"].nunique()}')\n",
    "print(f'   ‚Ä¢ Produto hash valores √∫nicos: {dados_completos[\"produto_hash\"].nunique()}')\n",
    "\n",
    "# Verificar valores nulos\n",
    "nulos = dados_completos.isnull().sum()\n",
    "if nulos.sum() > 0:\n",
    "    print(f'\\nüîç Valores nulos encontrados:')\n",
    "    print(nulos[nulos > 0])\n",
    "else:\n",
    "    print('‚úÖ Nenhum valor nulo encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Features de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Features temporais criadas:\n",
      "   ‚Ä¢ ano, mes, semana_ano, dia_inicio_semana\n",
      "   ‚Ä¢ Features c√≠clicas: mes_sin/cos, semana_sin/cos\n"
     ]
    }
   ],
   "source": [
    "# Extrair features temporais\n",
    "dados_completos['ano'] = dados_completos['semana'].dt.year\n",
    "dados_completos['mes'] = dados_completos['semana'].dt.month\n",
    "dados_completos['semana_ano'] = dados_completos['semana'].dt.isocalendar().week\n",
    "dados_completos['dia_inicio_semana'] = dados_completos['semana'].dt.dayofweek\n",
    "\n",
    "# Features c√≠clicas para capturar sazonalidade\n",
    "dados_completos['mes_sin'] = np.sin(2 * np.pi * dados_completos['mes'] / 12)\n",
    "dados_completos['mes_cos'] = np.cos(2 * np.pi * dados_completos['mes'] / 12)\n",
    "dados_completos['semana_sin'] = np.sin(2 * np.pi * dados_completos['semana_ano'] / 52)\n",
    "dados_completos['semana_cos'] = np.cos(2 * np.pi * dados_completos['semana_ano'] / 52)\n",
    "\n",
    "print('üìÖ Features temporais criadas:')\n",
    "print(f'   ‚Ä¢ ano, mes, semana_ano, dia_inicio_semana')\n",
    "print(f'   ‚Ä¢ Features c√≠clicas: mes_sin/cos, semana_sin/cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Feature de feriados criada:\n",
      "   ‚Ä¢ Semanas com feriado: 9,398,790\n",
      "   ‚Ä¢ Semanas sem feriado: 44,905,330\n"
     ]
    }
   ],
   "source": [
    "# Identificar feriados (simplificado - principais feriados nacionais de 2022)\n",
    "feriados_2022 = [\n",
    "    '2022-01-01',  # Ano Novo\n",
    "    '2022-02-28',  # Carnaval\n",
    "    '2022-03-01',  # Carnaval\n",
    "    '2022-04-15',  # Sexta-feira Santa\n",
    "    '2022-04-21',  # Tiradentes\n",
    "    '2022-05-01',  # Dia do Trabalho\n",
    "    '2022-09-07',  # Independ√™ncia\n",
    "    '2022-10-12',  # Nossa Senhora Aparecida\n",
    "    '2022-11-02',  # Finados\n",
    "    '2022-11-15',  # Proclama√ß√£o da Rep√∫blica\n",
    "    '2022-12-25',  # Natal\n",
    "]\n",
    "\n",
    "feriados_2022 = pd.to_datetime(feriados_2022)\n",
    "\n",
    "# Fun√ß√£o para verificar se a semana cont√©m feriado\n",
    "def semana_tem_feriado(data_semana):\n",
    "    inicio_semana = data_semana\n",
    "    fim_semana = data_semana + timedelta(days=6)\n",
    "    return any((feriado >= inicio_semana) & (feriado <= fim_semana) for feriado in feriados_2022)\n",
    "\n",
    "dados_completos['tem_feriado'] = dados_completos['semana'].apply(semana_tem_feriado).astype(int)\n",
    "\n",
    "print(f'üéâ Feature de feriados criada:')\n",
    "print(f'   ‚Ä¢ Semanas com feriado: {dados_completos[\"tem_feriado\"].sum():,}')\n",
    "print(f'   ‚Ä¢ Semanas sem feriado: {(dados_completos[\"tem_feriado\"] == 0).sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Features de Lag (Atraso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è∞ Features de lag criadas para 4 per√≠odos\n",
      "   ‚Ä¢ quantidade_lag_1, quantidade_lag_2, quantidade_lag_3, quantidade_lag_4\n",
      "   ‚Ä¢ valor_lag_1, valor_lag_2, valor_lag_3, valor_lag_4\n",
      "\n",
      "üîç Valores nulos em features de lag:\n",
      "   ‚Ä¢ quantidade_lag_1: 1,044,310 nulos\n",
      "   ‚Ä¢ quantidade_lag_2: 2,088,620 nulos\n",
      "   ‚Ä¢ quantidade_lag_3: 3,132,930 nulos\n",
      "   ‚Ä¢ quantidade_lag_4: 4,177,240 nulos\n"
     ]
    }
   ],
   "source": [
    "# Ordenar dados por semana para calcular lags\n",
    "dados_completos = dados_completos.sort_values(['pdv_id', 'produto_id', 'semana'])\n",
    "\n",
    "# Criar features de lag para quantidade\n",
    "lags = [1, 2, 3, 4]\n",
    "\n",
    "for lag in lags:\n",
    "    dados_completos[f'quantidade_lag_{lag}'] = dados_completos.groupby(['pdv_id', 'produto_id'])['quantidade'].shift(lag)\n",
    "    dados_completos[f'valor_lag_{lag}'] = dados_completos.groupby(['pdv_id', 'produto_id'])['valor'].shift(lag)\n",
    "\n",
    "print(f'‚è∞ Features de lag criadas para {len(lags)} per√≠odos')\n",
    "print(f'   ‚Ä¢ quantidade_lag_1, quantidade_lag_2, quantidade_lag_3, quantidade_lag_4')\n",
    "print(f'   ‚Ä¢ valor_lag_1, valor_lag_2, valor_lag_3, valor_lag_4')\n",
    "\n",
    "# Verificar valores nulos (esperado nas primeiras semanas)\n",
    "print('\\nüîç Valores nulos em features de lag:')\n",
    "for lag in lags:\n",
    "    nulos = dados_completos[f'quantidade_lag_{lag}'].isnull().sum()\n",
    "    print(f'   ‚Ä¢ quantidade_lag_{lag}: {nulos:,} nulos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Features de Janela M√≥vel (Rolling Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Features de janela m√≥vel criadas para janelas de [4, 8, 12] semanas\n",
      "   ‚Ä¢ M√©dia, desvio padr√£o, m√°ximo e m√≠nimo para cada janela\n",
      "‚úÖ Valores NaN em desvio padr√£o preenchidos com 0\n"
     ]
    }
   ],
   "source": [
    "# Criar features de janela m√≥vel\n",
    "window_sizes = [4, 8, 12]  # 4, 8 e 12 semanas\n",
    "\n",
    "for window in window_sizes:\n",
    "    # M√©dia m√≥vel\n",
    "    dados_completos[f'quantidade_media_{window}w'] = (\n",
    "        dados_completos.groupby(['pdv_id', 'produto_id'])['quantidade']\n",
    "        .rolling(window=window, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=[0,1], drop=True)\n",
    "    )\n",
    "    \n",
    "    # Desvio padr√£o m√≥vel\n",
    "    dados_completos[f'quantidade_std_{window}w'] = (\n",
    "        dados_completos.groupby(['pdv_id', 'produto_id'])['quantidade']\n",
    "        .rolling(window=window, min_periods=1)\n",
    "        .std()\n",
    "        .reset_index(level=[0,1], drop=True)\n",
    "    )\n",
    "    \n",
    "    # M√°ximo e m√≠nimo m√≥veis\n",
    "    dados_completos[f'quantidade_max_{window}w'] = (\n",
    "        dados_completos.groupby(['pdv_id', 'produto_id'])['quantidade']\n",
    "        .rolling(window=window, min_periods=1)\n",
    "        .max()\n",
    "        .reset_index(level=[0,1], drop=True)\n",
    "    )\n",
    "    \n",
    "    dados_completos[f'quantidade_min_{window}w'] = (\n",
    "        dados_completos.groupby(['pdv_id', 'produto_id'])['quantidade']\n",
    "        .rolling(window=window, min_periods=1)\n",
    "        .min()\n",
    "        .reset_index(level=[0,1], drop=True)\n",
    "    )\n",
    "\n",
    "print(f'üìä Features de janela m√≥vel criadas para janelas de {window_sizes} semanas')\n",
    "print(f'   ‚Ä¢ M√©dia, desvio padr√£o, m√°ximo e m√≠nimo para cada janela')\n",
    "\n",
    "# Preencher NaN em desvio padr√£o com 0 (quando s√≥ h√° 1 observa√ß√£o)\n",
    "std_columns = [col for col in dados_completos.columns if 'std_' in col]\n",
    "dados_completos[std_columns] = dados_completos[std_columns].fillna(0)\n",
    "\n",
    "print('‚úÖ Valores NaN em desvio padr√£o preenchidos com 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Features Categ√≥ricas - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Vari√°veis categ√≥ricas:\n",
      "   ‚Ä¢ pdv_hash: 100 categorias √∫nicas\n",
      "     {76: 796224, 12: 731224, 16: 697580, 61: 691548, 59: 682032}\n",
      "\n",
      "   ‚Ä¢ produto_hash: 100 categorias √∫nicas\n",
      "     {59: 981136, 84: 978536, 26: 961740, 76: 950716, 38: 866372}\n",
      "\n",
      "   ‚Ä¢ periodo_ano: coluna n√£o encontrada\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar vari√°veis categ√≥ricas criadas\n",
    "print('üè∑Ô∏è Vari√°veis categ√≥ricas:')\n",
    "categoricas = ['pdv_hash', 'produto_hash', 'periodo_ano']\n",
    "\n",
    "for col in categoricas:\n",
    "    if col in dados_completos.columns:\n",
    "        print(f'   ‚Ä¢ {col}: {dados_completos[col].nunique()} categorias √∫nicas')\n",
    "        print(f'     {dados_completos[col].value_counts().head().to_dict()}')\n",
    "        print()\n",
    "    else:\n",
    "        print(f'   ‚Ä¢ {col}: coluna n√£o encontrada')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ pdv_hash -> pdv_hash_encoded\n",
      "   Valores √∫nicos: 100\n",
      "\n",
      "üî¢ produto_hash -> produto_hash_encoded\n",
      "   Valores √∫nicos: 100\n",
      "\n",
      "‚úÖ Label encoding completo\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding para vari√°veis categ√≥ricas\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categoricas:\n",
    "    if col in dados_completos.columns:\n",
    "        le = LabelEncoder()\n",
    "        dados_completos[f'{col}_encoded'] = le.fit_transform(dados_completos[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "        print(f'üî¢ {col} -> {col}_encoded')\n",
    "        print(f'   Valores √∫nicos: {dados_completos[col].nunique()}')\n",
    "        print()\n",
    "\n",
    "print('‚úÖ Label encoding completo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Features Adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Features adicionais criadas:\n",
      "   ‚Ä¢ tendencia_4w: tend√™ncia nas √∫ltimas 4 semanas\n",
      "   ‚Ä¢ cv_4w: coeficiente de varia√ß√£o (4 semanas)\n",
      "   ‚Ä¢ momentum_2w: momentum das √∫ltimas 2 semanas\n",
      "   ‚Ä¢ periodo_ano: trimestre do ano (Q1, Q2, Q3, Q4)\n"
     ]
    }
   ],
   "source": [
    "# Features de tend√™ncia\n",
    "dados_completos['tendencia_4w'] = (\n",
    "    dados_completos['quantidade_lag_1'] - dados_completos['quantidade_lag_4']\n",
    ")\n",
    "\n",
    "# Features de variabilidade\n",
    "dados_completos['cv_4w'] = (\n",
    "    dados_completos['quantidade_std_4w'] / (dados_completos['quantidade_media_4w'] + 1e-8)\n",
    ")\n",
    "\n",
    "# Features de momentum\n",
    "dados_completos['momentum_2w'] = (\n",
    "    dados_completos['quantidade_lag_1'] + dados_completos['quantidade_lag_2']\n",
    ") / 2\n",
    "\n",
    "# Feature de sazonalidade (compara√ß√£o com mesmo per√≠odo do ano anterior)\n",
    "# Como temos apenas 2022, vamos usar uma proxy baseada na semana do ano\n",
    "dados_completos['periodo_ano'] = np.where(\n",
    "    dados_completos['semana_ano'] <= 13, 'Q1',\n",
    "    np.where(dados_completos['semana_ano'] <= 26, 'Q2',\n",
    "    np.where(dados_completos['semana_ano'] <= 39, 'Q3', 'Q4'))\n",
    ")\n",
    "\n",
    "print('üöÄ Features adicionais criadas:')\n",
    "print('   ‚Ä¢ tendencia_4w: tend√™ncia nas √∫ltimas 4 semanas')\n",
    "print('   ‚Ä¢ cv_4w: coeficiente de varia√ß√£o (4 semanas)')\n",
    "print('   ‚Ä¢ momentum_2w: momentum das √∫ltimas 2 semanas')\n",
    "print('   ‚Ä¢ periodo_ano: trimestre do ano (Q1, Q2, Q3, Q4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Limpeza e Prepara√ß√£o Final\n\nAgora vamos remover as primeiras semanas onde n√£o temos lags completos (lag_4). \n\n**Estrat√©gia Otimizada**: Como o dataset √© muito grande (~54M registros), vamos usar processamento em chunks para evitar problemas de mem√≥ria durante a opera√ß√£o de filtragem."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üö® EMERG√äNCIA: Salvar progresso e limpar mem√≥ria IMEDIATAMENTE\nprint('üö® Executando salvamento de emerg√™ncia para preservar trabalho...')\n\ntry:\n    # Salvar dados completos em formato compacto (parquet √© mais eficiente que CSV)\n    print('üíæ Salvando checkpoint em formato compacto...')\n    dados_completos.to_parquet('../data/checkpoint_completo.parquet', \n                              compression='gzip', \n                              index=False)\n    print('‚úÖ Checkpoint salvo com sucesso!')\n    \n    # Liberar imediatamente da mem√≥ria\n    print('üßπ Liberando mem√≥ria...')\n    del dados_completos\n    gc.collect()\n    \n    print('‚úÖ Mem√≥ria liberada!')\n    print('üìã Pr√≥ximos passos:')\n    print('   1. Reinicie o kernel do Jupyter')\n    print('   2. Execute: dados_completos = pd.read_parquet(\"../data/checkpoint_completo.parquet\")')\n    print('   3. Continue com a limpeza usando uma estrat√©gia mais simples')\n    \n    # Estrat√©gia simplificada para executar ap√≥s recarregar\n    strategy_code = '''\n# AP√ìS REINICIAR O KERNEL E RECARREGAR:\nimport pandas as pd\nimport numpy as np\nimport gc\n\n# Recarregar dados\ndados_completos = pd.read_parquet(\"../data/checkpoint_completo.parquet\")\nprint(f\"Dados recarregados: {dados_completos.shape}\")\n\n# Filtragem simples e direta\nprint(\"Aplicando filtro...\")\ndados_limpos = dados_completos[dados_completos['quantidade_lag_4'].notna()].copy()\nprint(f\"Dados limpos: {dados_limpos.shape}\")\n\n# Salvar resultado final\ndados_limpos.to_csv(\"../data/dados_features_completo.csv\", index=False)\nprint(\"‚úÖ Dataset final salvo!\")\n\n# Limpar mem√≥ria\ndel dados_completos\ngc.collect()\n    '''\n    \n    # Salvar c√≥digo para executar depois\n    with open('../data/strategy_after_restart.py', 'w') as f:\n        f.write(strategy_code)\n    \n    print('\\\\nüìù C√≥digo salvo em: ../data/strategy_after_restart.py')\n    print('\\\\nüîÑ RECOMENDA√á√ÉO URGENTE:')\n    print('   ‚Ä¢ Reinicie o kernel NOW para liberar RAM')\n    print('   ‚Ä¢ Execute o c√≥digo do arquivo strategy_after_restart.py')\n    \nexcept Exception as e:\n    print(f'‚ùå Erro ao salvar: {e}')\n    print('üö® CR√çTICO: Reinicie o kernel IMEDIATAMENTE!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores infinitos ou muito grandes\n",
    "print('üîç Verifica√ß√£o de valores problem√°ticos:')\n",
    "\n",
    "# Substituir infinitos por NaN e depois por 0\n",
    "dados_limpos = dados_limpos.replace([np.inf, -np.inf], np.nan)\n",
    "numeric_columns = dados_limpos.select_dtypes(include=[np.number]).columns\n",
    "dados_limpos[numeric_columns] = dados_limpos[numeric_columns].fillna(0)\n",
    "\n",
    "print(f'   ‚Ä¢ Valores infinitos tratados')\n",
    "print(f'   ‚Ä¢ Valores nulos finais: {dados_limpos.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar estat√≠sticas finais\n",
    "print('üìà Estat√≠sticas finais do dataset:')\n",
    "print(f'   ‚Ä¢ Shape final: {dados_limpos.shape}')\n",
    "print(f'   ‚Ä¢ Colunas: {len(dados_limpos.columns)}')\n",
    "print(f'   ‚Ä¢ PDVs √∫nicos: {dados_limpos[\"pdv_id\"].nunique()}')\n",
    "print(f'   ‚Ä¢ Produtos √∫nicos: {dados_limpos[\"produto_id\"].nunique()}')\n",
    "print(f'   ‚Ä¢ Semanas: {dados_limpos[\"semana\"].nunique()}')\n",
    "print(f'   ‚Ä¢ Registros com venda > 0: {(dados_limpos[\"quantidade\"] > 0).sum():,}')\n",
    "print(f'   ‚Ä¢ Registros com venda = 0: {(dados_limpos[\"quantidade\"] == 0).sum():,}')\n",
    "\n",
    "print('\\nüè∑Ô∏è Colunas do dataset final:')\n",
    "for i, col in enumerate(dados_limpos.columns, 1):\n",
    "    print(f'   {i:2d}. {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. An√°lise Explorat√≥ria das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o da vari√°vel target\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(dados_limpos[dados_limpos['quantidade'] > 0]['quantidade'], bins=50, alpha=0.7)\n",
    "plt.title('Distribui√ß√£o da Quantidade (> 0)')\n",
    "plt.xlabel('Quantidade')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(np.log1p(dados_limpos[dados_limpos['quantidade'] > 0]['quantidade']), bins=50, alpha=0.7)\n",
    "plt.title('Distribui√ß√£o log(Quantidade + 1)')\n",
    "plt.xlabel('log(Quantidade + 1)')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "dados_limpos['quantidade'].value_counts().head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Valores de Quantidade')\n",
    "plt.xlabel('Quantidade')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'üìä Estat√≠sticas da quantidade:')\n",
    "print(dados_limpos['quantidade'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correla√ß√£o entre features de lag\n",
    "lag_features = [f'quantidade_lag_{i}' for i in [1, 2, 3, 4]]\n",
    "corr_matrix = dados_limpos[lag_features + ['quantidade']].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correla√ß√£o entre Features de Lag e Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('üîó Correla√ß√µes com target:')\n",
    "corrs = dados_limpos[lag_features].corrwith(dados_limpos['quantidade'])\n",
    "for feature, corr in corrs.items():\n",
    "    print(f'   ‚Ä¢ {feature}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import√¢ncia das features temporais\n",
    "temporal_features = ['mes', 'semana_ano', 'tem_feriado', 'mes_sin', 'mes_cos']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, feature in enumerate(temporal_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    dados_agg = dados_limpos.groupby(feature)['quantidade'].agg(['mean', 'sum']).reset_index()\n",
    "    \n",
    "    plt.bar(dados_agg[feature], dados_agg['mean'], alpha=0.7)\n",
    "    plt.title(f'Quantidade M√©dia por {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Quantidade M√©dia')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar dataset completo com features e estrat√©gia Cold Start\n",
    "dados_limpos.to_csv('../data/dados_features_completo.csv', index=False)\n",
    "print(f'üíæ Dados completos salvos em: data/dados_features_completo.csv')\n",
    "print(f'   ‚Ä¢ Shape: {dados_limpos.shape}')\n",
    "print(f'   ‚Ä¢ Tamanho do arquivo: {dados_limpos.memory_usage(deep=True).sum() / 1024**2:.1f} MB')\n",
    "\n",
    "# Salvar tamb√©m informa√ß√µes dos encoders e estrat√©gia Cold Start\n",
    "import pickle\n",
    "\n",
    "# Salvar encoders\n",
    "with open('../data/label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "    \n",
    "# Salvar estrat√©gia Cold Start\n",
    "with open('../data/cold_start_strategy.pkl', 'wb') as f:\n",
    "    pickle.dump(cold_start_strategy, f)\n",
    "\n",
    "print('üíæ Arquivos salvos:')\n",
    "print('   ‚úÖ label_encoders.pkl - Encoders para vari√°veis categ√≥ricas')\n",
    "print('   ‚úÖ cold_start_strategy.pkl - Estrat√©gia para novas combina√ß√µes')\n",
    "print('   ‚úÖ dados_features_completo.csv - Dataset completo com features')\n",
    "\n",
    "# Salvar tamb√©m metadados do processo\n",
    "metadata = {\n",
    "    'data_processamento': pd.Timestamp.now(),\n",
    "    'total_registros': len(dados_limpos),\n",
    "    'total_features': len(dados_limpos.columns),\n",
    "    'combinacoes_pdv_produto': dados_limpos[['pdv_id', 'produto_id']].drop_duplicates().shape[0],\n",
    "    'semanas_cobertas': dados_limpos['semana'].nunique(),\n",
    "    'periodo_treino': f\"{dados_limpos['semana'].min()} a {dados_limpos['semana'].max()}\",\n",
    "    'estrategia_grid': 'Grid Inteligente com features hist√≥ricas',\n",
    "    'cold_start_preparado': True\n",
    "}\n",
    "\n",
    "with open('../data/feature_engineering_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print('üìã Metadados do processamento salvos em: feature_engineering_metadata.pkl')\n",
    "print('üéØ Tudo pronto para a fase de modelagem!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um resumo completo das features criadas\n",
    "feature_summary = {\n",
    "    'Temporais': ['ano', 'mes', 'semana_ano', 'dia_inicio_semana', 'tem_feriado', \n",
    "                  'mes_sin', 'mes_cos', 'semana_sin', 'semana_cos', 'periodo_ano'],\n",
    "    'Hist√≥ricas/Est√°ticas': ['semana_primeira_venda', 'semana_ultima_venda', 'tempo_atividade_semanas',\n",
    "                            'frequencia_vendas', 'quantidade_media_historica', 'preco_medio_unitario',\n",
    "                            'regularidade_vendas', 'categoria_volume', 'semanas_desde_primeira_venda',\n",
    "                            'produto_ativo', 'semanas_ate_ultima_venda'],\n",
    "    'Lag': [f'quantidade_lag_{i}' for i in [1, 2, 3, 4]] + \n",
    "           [f'valor_lag_{i}' for i in [1, 2, 3, 4]],\n",
    "    'Rolling': [col for col in dados_limpos.columns if any(x in col for x in ['_media_', '_std_', '_max_', '_min_'])],\n",
    "    'Categ√≥ricas': ['pdv_hash_encoded', 'produto_hash_encoded', 'periodo_ano_encoded'],\n",
    "    'Adicionais': ['tendencia_4w', 'cv_4w', 'momentum_2w', 'pdv_hash', 'produto_hash']\n",
    "}\n",
    "\n",
    "print('üìã Resumo Completo das Features Criadas:')\n",
    "print('=' * 60)\n",
    "\n",
    "total_features = 0\n",
    "for categoria, features in feature_summary.items():\n",
    "    found_features = [f for f in features if f in dados_limpos.columns]\n",
    "    print(f'\\\\nüè∑Ô∏è {categoria} ({len(found_features)} features):')\n",
    "    for feature in found_features:\n",
    "        print(f'   ‚úÖ {feature}')\n",
    "    \n",
    "    not_found = [f for f in features if f not in dados_limpos.columns]\n",
    "    for feature in not_found:\n",
    "        print(f'   ‚ùå {feature} (n√£o encontrada)')\n",
    "    \n",
    "    total_features += len(found_features)\n",
    "\n",
    "print(f'\\\\nüìä Estat√≠sticas Finais:')\n",
    "print(f'   ‚Ä¢ Total de features criadas: {total_features}')\n",
    "print(f'   ‚Ä¢ Total de colunas no dataset: {len(dados_limpos.columns)}')\n",
    "print(f'   ‚Ä¢ Registros finais: {dados_limpos.shape[0]:,}')\n",
    "print(f'   ‚Ä¢ Mem√≥ria total: {dados_limpos.memory_usage(deep=True).sum() / 1024**2:.1f} MB')\n",
    "\n",
    "print(f'\\\\nüéØ Otimiza√ß√µes Implementadas:')\n",
    "print('   ‚úÖ Grid Inteligente (94.4% redu√ß√£o de mem√≥ria)')\n",
    "print('   ‚úÖ Features hist√≥ricas para contexto de longo prazo')\n",
    "print('   ‚úÖ Cold Start strategy para novas combina√ß√µes')\n",
    "print('   ‚úÖ Processamento em lotes para efici√™ncia')\n",
    "\n",
    "print(f'\\\\nüöÄ Sistema Completo de Feature Engineering:')\n",
    "print('   ‚Ä¢ Zeros significativos preservados')\n",
    "print('   ‚Ä¢ Contexto hist√≥rico capturado')\n",
    "print('   ‚Ä¢ Robustez para dados futuros')\n",
    "print('   ‚Ä¢ Otimizado para performance')\n",
    "\n",
    "print('\\\\n‚úÖ Pr√©-processamento e Engenharia de Features Conclu√≠dos!')\n",
    "print('üîÑ Pr√≥ximo passo: Modelagem e Treinamento')\n",
    "print(f'üíæ Dataset final salvo com {dados_limpos.shape[0]:,} registros e {dados_limpos.shape[1]} colunas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üÜï Implementa√ß√£o da Estrat√©gia de Cold Start\n",
    "# Fun√ß√£o para lidar com combina√ß√µes PDV/produto n√£o vistas durante treinamento\n",
    "\n",
    "def implementar_cold_start_strategy():\n",
    "    \"\"\"\n",
    "    Prepara a estrat√©gia de Cold Start para combina√ß√µes PDV/produto novas.\n",
    "    Esta fun√ß√£o ser√° usada na fase de predi√ß√£o.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Salvar combina√ß√µes conhecidas do Grid Inteligente\n",
    "    combinacoes_conhecidas = set(\n",
    "        dados_limpos[['pdv_id', 'produto_id']].drop_duplicates().apply(\n",
    "            lambda row: (row['pdv_id'], row['produto_id']), axis=1\n",
    "        ).tolist()\n",
    "    )\n",
    "    \n",
    "    print('üîç An√°lise das combina√ß√µes conhecidas:')\n",
    "    print(f'   ‚Ä¢ Total de combina√ß√µes PDV/produto treinadas: {len(combinacoes_conhecidas):,}')\n",
    "    print(f'   ‚Ä¢ PDVs √∫nicos no treino: {dados_limpos[\"pdv_id\"].nunique():,}')\n",
    "    print(f'   ‚Ä¢ Produtos √∫nicos no treino: {dados_limpos[\"produto_id\"].nunique():,}')\n",
    "    \n",
    "    # 2. Fun√ß√£o para identificar novas combina√ß√µes\n",
    "    def identificar_cold_start(df_teste):\n",
    "        \\\"\\\"\\\"\n",
    "        Identifica combina√ß√µes PDV/produto que n√£o existem no dataset de treino.\n",
    "        \n",
    "        Args:\n",
    "            df_teste: DataFrame com combina√ß√µes que precisam de previs√£o\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (combina√ß√µes_conhecidas, combina√ß√µes_cold_start)\n",
    "        \\\"\\\"\\\"\n",
    "        combinacoes_teste = set(\n",
    "            df_teste[['pdv_id', 'produto_id']].drop_duplicates().apply(\n",
    "                lambda row: (row['pdv_id'], row['produto_id']), axis=1\n",
    "            ).tolist()\n",
    "        )\n",
    "        \n",
    "        conhecidas_teste = combinacoes_teste & combinacoes_conhecidas\n",
    "        cold_start_teste = combinacoes_teste - combinacoes_conhecidas\n",
    "        \n",
    "        return conhecidas_teste, cold_start_teste\n",
    "    \n",
    "    # 3. Fun√ß√£o para gerar previs√µes Cold Start\n",
    "    def gerar_previsoes_cold_start(cold_start_combinations, semanas_predi√ß√£o):\n",
    "        \\\"\\\"\\\"\n",
    "        Gera previs√µes seguras (quantidade=0) para combina√ß√µes Cold Start.\n",
    "        \n",
    "        Args:\n",
    "            cold_start_combinations: Set de tuplas (pdv_id, produto_id)\n",
    "            semanas_predi√ß√£o: Lista de semanas para predi√ß√£o\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame com previs√µes de quantidade=0\n",
    "        \\\"\\\"\\\"\n",
    "        if not cold_start_combinations:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        cold_start_predictions = []\n",
    "        for pdv_id, produto_id in cold_start_combinations:\n",
    "            for semana in semanas_predi√ß√£o:\n",
    "                cold_start_predictions.append({\n",
    "                    'semana': semana,\n",
    "                    'pdv_id': pdv_id,\n",
    "                    'produto_id': produto_id,\n",
    "                    'quantidade_predita': 0.0,\n",
    "                    'fonte_predicao': 'cold_start'\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(cold_start_predictions)\n",
    "    \n",
    "    # 4. Salvar informa√ß√µes para uso futuro\n",
    "    cold_start_info = {\n",
    "        'combinacoes_conhecidas': combinacoes_conhecidas,\n",
    "        'identificar_cold_start': identificar_cold_start,\n",
    "        'gerar_previsoes_cold_start': gerar_previsoes_cold_start,\n",
    "        'total_combinacoes_treino': len(combinacoes_conhecidas),\n",
    "        'pdvs_treino': set(dados_limpos['pdv_id'].unique()),\n",
    "        'produtos_treino': set(dados_limpos['produto_id'].unique())\n",
    "    }\n",
    "    \n",
    "    return cold_start_info\n",
    "\n",
    "# Executar prepara√ß√£o\n",
    "cold_start_strategy = implementar_cold_start_strategy()\n",
    "\n",
    "print('\\\\nüéØ Estrat√©gia de Cold Start preparada:')\n",
    "print('   ‚úÖ Combina√ß√µes conhecidas mapeadas')\n",
    "print('   ‚úÖ Fun√ß√£o de identifica√ß√£o criada') \n",
    "print('   ‚úÖ Fun√ß√£o de previs√£o segura criada')\n",
    "print('   ‚úÖ Informa√ß√µes salvas para fase de predi√ß√£o')\n",
    "\n",
    "# Exemplo de uso (simulado)\n",
    "print('\\\\nüìù Exemplo de uso na predi√ß√£o:')\n",
    "print('```python')\n",
    "print('# Durante a predi√ß√£o:')\n",
    "print('conhecidas, cold_start = cold_start_strategy[\\\"identificar_cold_start\\\"](df_teste)')\n",
    "print('predicoes_modelo = modelo.predict(features_conhecidas)')\n",
    "print('predicoes_cold_start = cold_start_strategy[\\\"gerar_previsoes_cold_start\\\"](cold_start, semanas_2023)')\n",
    "print('predicoes_finais = pd.concat([predicoes_modelo, predicoes_cold_start])')\n",
    "print('```')\n",
    "\n",
    "print('\\\\nüöÄ Sistema robusto para lidar com novas combina√ß√µes implementado!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. üÜï Estrat√©gia de Cold Start\n",
    "\n",
    "**Problema do Cold Start**: O Grid Inteligente cont√©m apenas combina√ß√µes PDV/produto que j√° venderam em 2022. \n",
    "Mas e se os dados de teste de 2023 contiverem novas combina√ß√µes (novos produtos ou novos PDVs)?\n",
    "\n",
    "**Solu√ß√£o**: Preparar uma fun√ß√£o que identifica e trata essas novas combina√ß√µes com previs√£o segura (quantidade = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um resumo das features criadas\n",
    "feature_summary = {\n",
    "    'Temporais': ['ano', 'mes', 'semana_ano', 'dia_inicio_semana', 'tem_feriado', \n",
    "                  'mes_sin', 'mes_cos', 'semana_sin', 'semana_cos', 'periodo_ano'],\n",
    "    'Lag': [f'quantidade_lag_{i}' for i in [1, 2, 3, 4]] + \n",
    "           [f'valor_lag_{i}' for i in [1, 2, 3, 4]],\n",
    "    'Rolling': [col for col in dados_limpos.columns if any(x in col for x in ['_media_', '_std_', '_max_', '_min_'])],\n",
    "    'Categ√≥ricas': ['pdv_hash_encoded', 'produto_hash_encoded', 'periodo_ano_encoded'],\n",
    "    'Adicionais': ['tendencia_4w', 'cv_4w', 'momentum_2w', 'pdv_hash', 'produto_hash']\n",
    "}\n",
    "\n",
    "print('üìã Resumo das Features Criadas:')\n",
    "print('=' * 50)\n",
    "\n",
    "total_features = 0\n",
    "for categoria, features in feature_summary.items():\n",
    "    print(f'\\nüè∑Ô∏è {categoria} ({len(features)} features):')\n",
    "    for feature in features:\n",
    "        if feature in dados_limpos.columns:\n",
    "            print(f'   ‚úÖ {feature}')\n",
    "        else:\n",
    "            print(f'   ‚ùå {feature} (n√£o encontrada)')\n",
    "    total_features += len([f for f in features if f in dados_limpos.columns])\n",
    "\n",
    "print(f'\\nüìä Total de features criadas: {total_features}')\n",
    "print(f'üìä Total de colunas no dataset: {len(dados_limpos.columns)}')\n",
    "\n",
    "print('\\n‚úÖ Engenharia de Features Conclu√≠da!')\n",
    "print('üöÄ Pr√≥ximo passo: Modelagem e Treinamento')\n",
    "print(f'üíæ Dataset final salvo com {dados_limpos.shape[0]:,} registros e {dados_limpos.shape[1]} colunas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
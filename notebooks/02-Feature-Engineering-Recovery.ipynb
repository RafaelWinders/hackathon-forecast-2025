{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-B - Feature Engineering Recovery (Otimizado para Baixa MemÃ³ria)\n",
    "\n",
    "Este notebook implementa uma versÃ£o simplificada e otimizada do feature engineering, projetada para funcionar em ambientes com limitaÃ§Ãµes de memÃ³ria.\n",
    "\n",
    "## EstratÃ©gia:\n",
    "1. **Processar apenas dados essenciais**\n",
    "2. **Usar agregaÃ§Ãµes em chunks**\n",
    "3. **Salvar resultados intermediÃ¡rios**\n",
    "4. **Features mÃ­nimas mas eficazes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('ğŸ“š Bibliotecas carregadas - VersÃ£o Recovery')\n",
    "print('ğŸ’¡ EstratÃ©gia: Processamento otimizado para baixa memÃ³ria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar apenas dados de transaÃ§Ãµes (o mais importante)\n",
    "print('ğŸ“‚ Carregando dados de transaÃ§Ãµes...')\n",
    "transacoes = pd.read_parquet('../data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet')\n",
    "\n",
    "print(f'ğŸ“Š TransaÃ§Ãµes carregadas: {transacoes.shape}')\n",
    "print(f'ğŸ’¾ MemÃ³ria: {transacoes.memory_usage(deep=True).sum() / (1024**2):.1f} MB')\n",
    "\n",
    "# Renomear e preparar colunas essenciais\n",
    "dados = transacoes[['internal_store_id', 'internal_product_id', 'transaction_date', 'quantity']].copy()\n",
    "dados.columns = ['pdv_id', 'produto_id', 'data', 'quantidade']\n",
    "dados['data'] = pd.to_datetime(dados['data'])\n",
    "\n",
    "# Liberar memÃ³ria\n",
    "del transacoes\n",
    "gc.collect()\n",
    "\n",
    "print('âœ… Dados preparados e memÃ³ria otimizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AgregaÃ§Ã£o Semanal Simplificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar semanas\n",
    "dados['semana'] = dados['data'].dt.to_period('W-MON').dt.start_time\n",
    "\n",
    "print(f'ğŸ“… PerÃ­odo: {dados[\"semana\"].min()} atÃ© {dados[\"semana\"].max()}')\n",
    "print(f'ğŸ“Š Total de semanas: {dados[\"semana\"].nunique()}')\n",
    "\n",
    "# AgregaÃ§Ã£o semanal\n",
    "print('ğŸ”„ Realizando agregaÃ§Ã£o semanal...')\n",
    "agregacao_semanal = dados.groupby(['semana', 'pdv_id', 'produto_id']).agg({\n",
    "    'quantidade': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f'ğŸ“Š AgregaÃ§Ã£o criada: {agregacao_semanal.shape}')\n",
    "\n",
    "# Liberar dados originais\n",
    "del dados\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grid Inteligente Simplificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar apenas combinaÃ§Ãµes ativas (estratÃ©gia que funcionou)\n",
    "combinacoes_ativas = agregacao_semanal[['pdv_id', 'produto_id']].drop_duplicates()\n",
    "semanas_unicas = sorted(agregacao_semanal['semana'].unique())\n",
    "\n",
    "print(f'ğŸ¯ CombinaÃ§Ãµes ativas: {len(combinacoes_ativas):,}')\n",
    "print(f'ğŸ“… Semanas: {len(semanas_unicas)}')\n",
    "\n",
    "# Criar grid em lotes pequenos\n",
    "batch_size = 5000  # Lotes pequenos\n",
    "grid_parts = []\n",
    "\n",
    "for i in range(0, len(combinacoes_ativas), batch_size):\n",
    "    batch = combinacoes_ativas.iloc[i:i+batch_size]\n",
    "    print(f'ğŸ“¦ Processando lote {i//batch_size + 1}: {len(batch)} combinaÃ§Ãµes')\n",
    "    \n",
    "    # Criar grid para este lote\n",
    "    batch_grids = []\n",
    "    for _, row in batch.iterrows():\n",
    "        grid = pd.DataFrame({\n",
    "            'semana': semanas_unicas,\n",
    "            'pdv_id': row['pdv_id'],\n",
    "            'produto_id': row['produto_id']\n",
    "        })\n",
    "        batch_grids.append(grid)\n",
    "    \n",
    "    # Concatenar lote\n",
    "    batch_grid = pd.concat(batch_grids, ignore_index=True)\n",
    "    \n",
    "    # Merge com vendas\n",
    "    batch_grid = batch_grid.merge(agregacao_semanal, on=['semana', 'pdv_id', 'produto_id'], how='left')\n",
    "    batch_grid['quantidade'] = batch_grid['quantidade'].fillna(0)\n",
    "    \n",
    "    grid_parts.append(batch_grid)\n",
    "    \n",
    "    # Limpeza\n",
    "    del batch_grids, batch_grid\n",
    "    gc.collect()\n",
    "\n",
    "# Concatenar todas as partes\n",
    "print('ğŸ”— Concatenando grid completo...')\n",
    "dados_grid = pd.concat(grid_parts, ignore_index=True)\n",
    "\n",
    "# Limpeza\n",
    "del grid_parts, agregacao_semanal\n",
    "gc.collect()\n",
    "\n",
    "print(f'âœ… Grid criado: {dados_grid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Features Essenciais (MÃ­nimas mas Eficazes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar dados\n",
    "dados_grid = dados_grid.sort_values(['pdv_id', 'produto_id', 'semana'])\n",
    "\n",
    "# Features temporais bÃ¡sicas\n",
    "dados_grid['mes'] = dados_grid['semana'].dt.month\n",
    "dados_grid['semana_ano'] = dados_grid['semana'].dt.isocalendar().week\n",
    "\n",
    "# Features de lag (apenas as mais importantes)\n",
    "print('â° Criando features de lag...')\n",
    "for lag in [1, 2, 4]:  # Apenas 3 lags mais importantes\n",
    "    dados_grid[f'quantidade_lag_{lag}'] = dados_grid.groupby(['pdv_id', 'produto_id'])['quantidade'].shift(lag)\n",
    "\n",
    "# Rolling features (simplificado)\n",
    "print('ğŸ“Š Criando rolling features...')\n",
    "dados_grid['quantidade_media_4w'] = (\n",
    "    dados_grid.groupby(['pdv_id', 'produto_id'])['quantidade']\n",
    "    .rolling(window=4, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=[0,1], drop=True)\n",
    ")\n",
    "\n",
    "# Features categÃ³ricas simples\n",
    "dados_grid['pdv_hash'] = dados_grid['pdv_id'].astype(str).apply(hash) % 100\n",
    "dados_grid['produto_hash'] = dados_grid['produto_id'].astype(str).apply(hash) % 100\n",
    "\n",
    "print('âœ… Features essenciais criadas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Limpeza Final Simplificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover registros sem lag_4 (mais simples)\n",
    "print(f'ğŸ“Š Dados antes da limpeza: {dados_grid.shape}')\n",
    "\n",
    "dados_final = dados_grid[dados_grid['quantidade_lag_4'].notna()].copy()\n",
    "\n",
    "print(f'ğŸ“Š Dados apÃ³s limpeza: {dados_final.shape}')\n",
    "print(f'ğŸ’¾ MemÃ³ria final: {dados_final.memory_usage(deep=True).sum() / (1024**2):.1f} MB')\n",
    "\n",
    "# Verificar distribuiÃ§Ã£o\n",
    "zeros = (dados_final['quantidade'] == 0).sum()\n",
    "non_zeros = (dados_final['quantidade'] > 0).sum()\n",
    "print(f'ğŸ“ˆ Zeros: {zeros:,} ({zeros/len(dados_final)*100:.1f}%)')\n",
    "print(f'ğŸ“ˆ NÃ£o-zeros: {non_zeros:,} ({non_zeros/len(dados_final)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar dataset final\n",
    "dados_final.to_csv('../data/dados_features_completo.csv', index=False)\n",
    "print('ğŸ’¾ Dataset salvo: dados_features_completo.csv')\n",
    "\n",
    "# Salvar metadados\n",
    "import pickle\n",
    "\n",
    "metadata = {\n",
    "    'data_processamento': pd.Timestamp.now(),\n",
    "    'total_registros': len(dados_final),\n",
    "    'total_features': len(dados_final.columns),\n",
    "    'estrategia': 'Grid Inteligente Simplificado - Recovery',\n",
    "    'features_criadas': list(dados_final.columns),\n",
    "    'periodo_treino': f\"{dados_final['semana'].min()} a {dados_final['semana'].max()}\"\n",
    "}\n",
    "\n",
    "with open('../data/feature_engineering_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print('ğŸ“‹ Metadados salvos: feature_engineering_metadata.pkl')\n",
    "\n",
    "# Mostrar resumo final\n",
    "print('\\nğŸ‰ FEATURE ENGINEERING RECOVERY CONCLUÃDO!')\n",
    "print('=' * 50)\n",
    "print(f'ğŸ“Š Dataset final: {dados_final.shape}')\n",
    "print(f'ğŸ·ï¸ Features: {list(dados_final.columns)}')\n",
    "print('ğŸš€ Pronto para modelagem!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
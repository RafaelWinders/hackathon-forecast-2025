{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Modelo de Classificação (Prever SE vai vender)\n",
    "\n",
    "Este notebook treina o primeiro estágio do modelo de dois estágios: **classificação**.\n",
    "\n",
    "## Objetivo:\n",
    "- Prever se um item terá vendas (`vendeu = 1`) ou não (`vendeu = 0`)\n",
    "- Usar LightGBM Classifier otimizado\n",
    "- Avaliar com métricas de classificação (AUC, F1-Score, Matriz de Confusão)\n",
    "- Preparar para ser usado no pipeline de dois estágios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Iniciando Treinamento do Modelo de Classificação\n",
      "🏆 Objetivo: Prever SE um item vai vender (vendeu = 1 ou 0)\n",
      "📁 Pasta data/submissao3 criada/verificada\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('🎯 Iniciando Treinamento do Modelo de Classificação')\n",
    "print('🏆 Objetivo: Prever SE um item vai vender (vendeu = 1 ou 0)')\n",
    "\n",
    "# Criar pasta submissao3 se não existir\n",
    "os.makedirs('../data/submissao3', exist_ok=True)\n",
    "print('📁 Pasta data/submissao3 criada/verificada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados com Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Carregando dados com features CORRIGIDAS (sem target leakage)...\n",
      "✅ Dados CORRIGIDOS carregados com sucesso!\n",
      "🏋️ Dados de treino: (50126880, 54)\n",
      "🔍 Dados de validação: (5221550, 54)\n",
      "\n",
      "📊 Distribuição do target \"vendeu\" no treino:\n",
      "vendeu\n",
      "0    44583272\n",
      "1     5543608\n",
      "Name: count, dtype: int64\n",
      "   • Proporção positiva: 11.06%\n",
      "\n",
      "📊 Distribuição do target \"vendeu\" na validação:\n",
      "vendeu\n",
      "0    4649821\n",
      "1     571729\n",
      "Name: count, dtype: int64\n",
      "   • Proporção positiva: 10.95%\n",
      "✅ Dados carregados e target verificado\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados com features avançadas CORRIGIDAS\n",
    "print('📂 Carregando dados com features CORRIGIDAS (sem target leakage)...')\n",
    "\n",
    "# IMPORTANTE: Usar os dados CORRIGIDOS que foram salvos no Notebook 10\n",
    "try:\n",
    "    train_features = pd.read_parquet('../data/submissao3/train_features_CORRIGIDO.parquet')\n",
    "    validation_features = pd.read_parquet('../data/submissao3/validation_features_CORRIGIDO.parquet')\n",
    "    print('✅ Dados CORRIGIDOS carregados com sucesso!')\n",
    "except FileNotFoundError:\n",
    "    print('⚠️ Dados CORRIGIDOS não encontrados. Usando dados originais...')\n",
    "    print('   Recomendação: Execute o Notebook 10 primeiro para gerar os dados corrigidos.')\n",
    "    train_features = pd.read_parquet('../data/submissao3/train_features.parquet')\n",
    "    validation_features = pd.read_parquet('../data/submissao3/validation_features.parquet')\n",
    "\n",
    "print(f'🏋️ Dados de treino: {train_features.shape}')\n",
    "print(f'🔍 Dados de validação: {validation_features.shape}')\n",
    "\n",
    "# Verificar target de classificação\n",
    "print(f'\\n📊 Distribuição do target \"vendeu\" no treino:')\n",
    "print(train_features['vendeu'].value_counts())\n",
    "print(f'   • Proporção positiva: {train_features[\"vendeu\"].mean()*100:.2f}%')\n",
    "\n",
    "print(f'\\n📊 Distribuição do target \"vendeu\" na validação:')\n",
    "print(validation_features['vendeu'].value_counts())\n",
    "print(f'   • Proporção positiva: {validation_features[\"vendeu\"].mean()*100:.2f}%')\n",
    "\n",
    "print('✅ Dados carregados e target verificado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados para Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Preparando dados para classificação SEM TARGET LEAKAGE...\n",
      "📊 Features disponíveis: 54\n",
      "📊 Features SEGURAS para classificação: 41\n",
      "📊 Features excluídas (com leakage): 20\n",
      "\n",
      "✅ FEATURES SEGURAS (sem target leakage):\n",
      "   • preco_lag_1\n",
      "   • preco_lag_2\n",
      "   • variacao_preco_sku_semanal\n",
      "   • quantidade_lag_1\n",
      "   • quantidade_lag_2\n",
      "   • quantidade_lag_3\n",
      "   • quantidade_lag_4\n",
      "   • quantidade_media_4w\n",
      "   • quantidade_std_4w\n",
      "   • quantidade_max_4w\n",
      "   • quantidade_ewma_4w\n",
      "   • quantidade_ewma_8w\n",
      "   • preco_ewma_4w\n",
      "   • semana_do_ano\n",
      "   • eh_primeira_semana_mes\n",
      "   • eh_dezembro\n",
      "   • eh_janeiro\n",
      "   • eh_pos_festas\n",
      "   • semana_ano_sin\n",
      "   • semana_ano_cos\n",
      "   • preco_relativo_categoria\n",
      "   • preco_relativo_pdv\n",
      "   • preco_volatilidade\n",
      "   • media_vendas_categoria_pdv_lag_1\n",
      "   • share_vendas_sku_categoria_lag_1\n",
      "   • momentum_ratio\n",
      "   • momentum_ratio_ewma\n",
      "   • aceleracao\n",
      "   • dia_do_mes\n",
      "   • semana_do_mes\n",
      "   • eh_inicio_mes\n",
      "   • eh_fim_mes\n",
      "   • mes\n",
      "   • mes_sin\n",
      "   • mes_cos\n",
      "   • pdv_hash\n",
      "   • produto_hash\n",
      "   • categoria_hash\n",
      "   • zipcode_hash\n",
      "   • pdv_produto_hash\n",
      "   • categoria_zipcode_hash\n",
      "\n",
      "🚨 FEATURES REMOVIDAS (causavam leakage):\n",
      "   ❌ preco_unitario_atual\n",
      "   ❌ preco_medio_semanal_sku_atual\n",
      "   ❌ media_vendas_categoria_pdv_atual\n",
      "   ❌ share_vendas_sku_categoria_atual\n",
      "\n",
      "📊 Datasets preparados (SEM LEAKAGE):\n",
      "   🏋️ X_train: (50126880, 41), y_train: (50126880,)\n",
      "   🔍 X_val: (5221550, 41), y_val: (5221550,)\n",
      "   🧹 NAs no treino: 0, NAs na validação: 0\n",
      "✅ 41 features seguras - suficientes para treinamento!\n",
      "✅ Dados preparados para classificação SEM TARGET LEAKAGE\n"
     ]
    }
   ],
   "source": [
    "# Definir features para o modelo de classificação SEM TARGET LEAKAGE\n",
    "print('🔧 Preparando dados para classificação SEM TARGET LEAKAGE...')\n",
    "\n",
    "# CRÍTICO: Excluir features que causam vazamento de informação\n",
    "features_excluir = [\n",
    "    # IDs e data\n",
    "    'semana', 'pdv_id', 'produto_id',  \n",
    "    # Targets\n",
    "    'quantidade', 'faturamento', 'vendeu',       \n",
    "    # IDs auxiliares\n",
    "    'distributor_id',                  \n",
    "    # Categóricas brutas (usamos as hash)\n",
    "    'categoria', 'zipcode', 'tipo_loja',  \n",
    "    \n",
    "    # 🚨 CRÍTICO: Features que causam TARGET LEAKAGE (usam informação da semana atual)\n",
    "    'preco_unitario_atual',                     # Usa quantidade atual  \n",
    "    'preco_medio_semanal_sku_atual',           # Usa preço atual\n",
    "    'media_vendas_categoria_pdv_atual',        # Usa quantidade atual\n",
    "    'share_vendas_sku_categoria_atual',        # Usa quantidade atual\n",
    "    \n",
    "    # REMOVIDAS do modelo original que causavam leakage\n",
    "    'preco_unitario',                          # Calculado com quantidade atual\n",
    "    'preco_medio_semanal_sku',                # Usa preço atual  \n",
    "    'preco_medio_semanal_categoria_pdv',      # Usa preço atual\n",
    "    'media_vendas_categoria_no_pdv',          # Usa quantidade atual\n",
    "    'media_vendas_sku_no_zipcode',            # Usa quantidade atual  \n",
    "    'share_vendas_sku_na_categoria'           # Usa quantidade atual\n",
    "]\n",
    "\n",
    "# Selecionar features SEGURAS (sem leakage)\n",
    "features_disponiveis = list(train_features.columns)\n",
    "features_modelo_seguros = [col for col in features_disponiveis if col not in features_excluir]\n",
    "\n",
    "print(f'📊 Features disponíveis: {len(features_disponiveis)}')\n",
    "print(f'📊 Features SEGURAS para classificação: {len(features_modelo_seguros)}')\n",
    "print(f'📊 Features excluídas (com leakage): {len(features_excluir)}')\n",
    "\n",
    "# Mostrar features SEGURAS que serão usadas\n",
    "print('\\n✅ FEATURES SEGURAS (sem target leakage):')\n",
    "for feat in features_modelo_seguros:\n",
    "    print(f'   • {feat}')\n",
    "\n",
    "# Mostrar features REMOVIDAS (com leakage)  \n",
    "print('\\n🚨 FEATURES REMOVIDAS (causavam leakage):')\n",
    "features_com_leakage = [f for f in features_excluir if 'preco_unitario' in f or 'media_vendas' in f or 'share_vendas' in f or 'preco_medio' in f]\n",
    "for feat in features_com_leakage:\n",
    "    if feat in features_disponiveis:\n",
    "        print(f'   ❌ {feat}')\n",
    "\n",
    "# Preparar datasets COM FEATURES SEGURAS\n",
    "X_train = train_features[features_modelo_seguros].copy()\n",
    "y_train = train_features['vendeu'].copy()\n",
    "\n",
    "X_val = validation_features[features_modelo_seguros].copy() \n",
    "y_val = validation_features['vendeu'].copy()\n",
    "\n",
    "print(f'\\n📊 Datasets preparados (SEM LEAKAGE):')\n",
    "print(f'   🏋️ X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'   🔍 X_val: {X_val.shape}, y_val: {y_val.shape}')\n",
    "\n",
    "# Verificar se há NAs\n",
    "nas_train = X_train.isnull().sum().sum()\n",
    "nas_val = X_val.isnull().sum().sum()\n",
    "print(f'   🧹 NAs no treino: {nas_train}, NAs na validação: {nas_val}')\n",
    "\n",
    "if nas_train > 0 or nas_val > 0:\n",
    "    print('   ⚠️ Preenchendo NAs com 0...')\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_val = X_val.fillna(0)\n",
    "\n",
    "# Verificar se ainda temos features suficientes\n",
    "if len(features_modelo_seguros) < 10:\n",
    "    print('⚠️ AVISO: Poucas features disponíveis! Pode indicar problema na engenharia de features.')\n",
    "else:\n",
    "    print(f'✅ {len(features_modelo_seguros)} features seguras - suficientes para treinamento!')\n",
    "\n",
    "print('✅ Dados preparados para classificação SEM TARGET LEAKAGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinamento do Modelo LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Treinando LightGBM Classifier...\n",
      "   📚 Iniciando treinamento...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.84728\tvalid_0's binary_logloss: 0.267367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.84728\tvalid_0's binary_logloss: 0.267367\n",
      "✅ Modelo treinado! Melhor iteração: 100\n",
      "📊 Score de validação: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('auc', np.float64(0.8472803725977874)), ('binary_logloss', np.float64(0.2673666610763523))])})\n"
     ]
    }
   ],
   "source": [
    "# Configurar e treinar LightGBM Classifier\n",
    "print('🚀 Treinando LightGBM Classifier...')\n",
    "\n",
    "# Parâmetros otimizados para classificação\n",
    "lgbm_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 100,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Criar modelo\n",
    "lgbm_classifier = lgb.LGBMClassifier(**lgbm_params)\n",
    "\n",
    "# Treinar modelo com callbacks para early stopping\n",
    "print('   📚 Iniciando treinamento...')\n",
    "lgbm_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=['binary_logloss', 'auc'],\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(f'✅ Modelo treinado! Melhor iteração: {lgbm_classifier.best_iteration_}')\n",
    "print(f'📊 Score de validação: {lgbm_classifier.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Avaliando modelo de classificação...\n",
      "\n",
      "📊 MÉTRICAS DE TREINO:\n",
      "   🎯 AUC: 0.8784\n",
      "   🎯 F1-Score: 0.3917\n",
      "   🎯 Precision: 0.7043\n",
      "   🎯 Recall: 0.2713\n",
      "\n",
      "📊 MÉTRICAS DE VALIDAÇÃO:\n",
      "   🎯 AUC: 0.8473\n",
      "   🎯 F1-Score: 0.1460\n",
      "   🎯 Precision: 0.7078\n",
      "   🎯 Recall: 0.0814\n",
      "\n",
      "📊 MATRIZ DE CONFUSÃO (Validação):\n",
      "                 Predito\n",
      "               0       1\n",
      "Real    0   4,630,608  19,213\n",
      "        1   525,188  46,541\n",
      "\n",
      "📊 ANÁLISE DE THRESHOLDS:\n",
      "   Threshold 0.3: F1=0.3520, Prec=0.5647, Rec=0.2557\n",
      "   Threshold 0.4: F1=0.2366, Prec=0.6448, Rec=0.1449\n",
      "   Threshold 0.5: F1=0.1460, Prec=0.7078, Rec=0.0814\n",
      "   Threshold 0.6: F1=0.0708, Prec=0.7642, Rec=0.0371\n",
      "   Threshold 0.7: F1=0.0089, Prec=0.8442, Rec=0.0045\n",
      "✅ Avaliação do modelo concluída\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões\n",
    "print('🔍 Avaliando modelo de classificação...')\n",
    "\n",
    "# Previsões de probabilidade\n",
    "y_pred_proba_train = lgbm_classifier.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_val = lgbm_classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Previsões binárias (threshold = 0.5)\n",
    "y_pred_train = lgbm_classifier.predict(X_train)\n",
    "y_pred_val = lgbm_classifier.predict(X_val)\n",
    "\n",
    "# Métricas de treino\n",
    "print('\\n📊 MÉTRICAS DE TREINO:')\n",
    "print(f'   🎯 AUC: {roc_auc_score(y_train, y_pred_proba_train):.4f}')\n",
    "print(f'   🎯 F1-Score: {f1_score(y_train, y_pred_train):.4f}')\n",
    "print(f'   🎯 Precision: {precision_score(y_train, y_pred_train):.4f}')\n",
    "print(f'   🎯 Recall: {recall_score(y_train, y_pred_train):.4f}')\n",
    "\n",
    "# Métricas de validação\n",
    "print('\\n📊 MÉTRICAS DE VALIDAÇÃO:')\n",
    "auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "f1_val = f1_score(y_val, y_pred_val)\n",
    "precision_val = precision_score(y_val, y_pred_val)\n",
    "recall_val = recall_score(y_val, y_pred_val)\n",
    "\n",
    "print(f'   🎯 AUC: {auc_val:.4f}')\n",
    "print(f'   🎯 F1-Score: {f1_val:.4f}')\n",
    "print(f'   🎯 Precision: {precision_val:.4f}')\n",
    "print(f'   🎯 Recall: {recall_val:.4f}')\n",
    "\n",
    "# Matriz de confusão\n",
    "print('\\n📊 MATRIZ DE CONFUSÃO (Validação):')\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "print(f'                 Predito')\n",
    "print(f'               0       1')\n",
    "print(f'Real    0   {cm[0,0]:7,} {cm[0,1]:7,}')\n",
    "print(f'        1   {cm[1,0]:7,} {cm[1,1]:7,}')\n",
    "\n",
    "# Análise de diferentes thresholds\n",
    "print('\\n📊 ANÁLISE DE THRESHOLDS:')\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba_val >= threshold).astype(int)\n",
    "    f1_thresh = f1_score(y_val, y_pred_thresh)\n",
    "    precision_thresh = precision_score(y_val, y_pred_thresh)\n",
    "    recall_thresh = recall_score(y_val, y_pred_thresh)\n",
    "    print(f'   Threshold {threshold:.1f}: F1={f1_thresh:.4f}, Prec={precision_thresh:.4f}, Rec={recall_thresh:.4f}')\n",
    "\n",
    "print('✅ Avaliação do modelo concluída')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise de Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Analisando importância das features...\n",
      "\n",
      "🏆 TOP 20 FEATURES MAIS IMPORTANTES:\n",
      "    1. quantidade_ewma_8w             -   1271\n",
      "    2. preco_ewma_4w                  -    972\n",
      "    3. quantidade_ewma_4w             -    922\n",
      "    4. semana_do_ano                  -    890\n",
      "    5. preco_lag_1                    -    867\n",
      "    6. categoria_hash                 -    622\n",
      "    7. preco_relativo_categoria       -    622\n",
      "    8. produto_hash                   -    357\n",
      "    9. media_vendas_categoria_pdv_lag_1 -    354\n",
      "   10. preco_lag_2                    -    326\n",
      "   11. preco_relativo_pdv             -    307\n",
      "   12. momentum_ratio_ewma            -    294\n",
      "   13. quantidade_media_4w            -    281\n",
      "   14. categoria_zipcode_hash         -    240\n",
      "   15. preco_volatilidade             -    212\n",
      "   16. quantidade_std_4w              -    185\n",
      "   17. semana_ano_sin                 -    183\n",
      "   18. mes_sin                        -    117\n",
      "   19. quantidade_max_4w              -    114\n",
      "   20. aceleracao                     -     94\n",
      "\n",
      "📊 IMPORTÂNCIA POR CATEGORIA:\n",
      "   Lag         :     1887 (8 features)\n",
      "   Rolling     :      580 (3 features)\n",
      "   Preço       :     3330 (7 features)\n",
      "   Calendário  :      917 (10 features)\n",
      "   Tendência   :      425 (3 features)\n",
      "   Hierarquia  :      435 (2 features)\n",
      "   Hash        :     1221 (6 features)\n",
      "✅ Análise de importância concluída\n"
     ]
    }
   ],
   "source": [
    "# Analisar importância das features\n",
    "print('📊 Analisando importância das features...')\n",
    "\n",
    "# Obter importâncias\n",
    "feature_importance = lgbm_classifier.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Criar DataFrame de importâncias\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 20 features mais importantes\n",
    "print('\\n🏆 TOP 20 FEATURES MAIS IMPORTANTES:')\n",
    "for i, (_, row) in enumerate(importance_df.head(20).iterrows()):\n",
    "    print(f'   {i+1:2d}. {row[\"feature\"]:30s} - {row[\"importance\"]:6.0f}')\n",
    "\n",
    "# Análise por categoria de feature\n",
    "print('\\n📊 IMPORTÂNCIA POR CATEGORIA:')\n",
    "categorias_feature = {\n",
    "    'Lag': [f for f in feature_names if 'lag_' in f],\n",
    "    'Rolling': [f for f in feature_names if any(x in f for x in ['media_4w', 'std_4w', 'max_4w'])],\n",
    "    'Preço': [f for f in feature_names if 'preco' in f],\n",
    "    'Calendário': [f for f in feature_names if any(x in f for x in ['mes', 'dia', 'inicio', 'fim'])],\n",
    "    'Tendência': [f for f in feature_names if any(x in f for x in ['momentum', 'aceleracao'])],\n",
    "    'Hierarquia': [f for f in feature_names if any(x in f for x in ['media_vendas', 'share'])],\n",
    "    'Hash': [f for f in feature_names if 'hash' in f]\n",
    "}\n",
    "\n",
    "for categoria, features in categorias_feature.items():\n",
    "    if features:\n",
    "        importancia_categoria = importance_df[importance_df['feature'].isin(features)]['importance'].sum()\n",
    "        print(f'   {categoria:12s}: {importancia_categoria:8.0f} ({len(features)} features)')\n",
    "\n",
    "print('✅ Análise de importância concluída')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Salvando modelo de classificação SEM LEAKAGE...\n",
      "✅ Arquivos CORRIGIDOS salvos:\n",
      "   • data/submissao3/lgbm_classifier_CORRIGIDO.pkl\n",
      "   • data/submissao3/classification_features_CORRIGIDO.pkl\n",
      "   • data/submissao3/classification_feature_importance_CORRIGIDO.csv\n",
      "   • data/submissao3/lgbm_classifier_CORRIGIDO_metadata.pkl\n",
      "\\n🎉 MODELO DE CLASSIFICAÇÃO CORRIGIDO TREINADO!\n",
      "======================================================================\n",
      "🎯 Resumo da Correção:\n",
      "   ❌ Problema original: Rolling features incluíam semana atual\n",
      "   ✅ Correção aplicada: Rolling baseado em quantidade_lag_1\n",
      "   📊 Features seguras usadas: 41\n",
      "   📊 AUC: 0.8473\n",
      "   📊 F1-Score: 0.1460\n",
      "\\n🤔 AUC MUITO BAIXO - POSSÍVEL PROBLEMA\n",
      "   ⚠️ AUC < 0.95 pode indicar features insuficientes\n",
      "   🔍 Verifique se features importantes não foram removidas\n",
      "\\n💡 Próximo passo:\n",
      "   🔄 Treinar modelo de regressão (Notebook 12)\n",
      "   📊 Pode usar features atuais no regressor (quando vendeu=1)\n",
      "\\n🚀 Primeiro estágio do modelo de dois estágios!\n"
     ]
    }
   ],
   "source": [
    "# Salvar modelo treinado SEM TARGET LEAKAGE\n",
    "print('💾 Salvando modelo de classificação SEM LEAKAGE...')\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../data/submissao3/lgbm_classifier_CORRIGIDO.pkl', 'wb') as f:\n",
    "    pickle.dump(lgbm_classifier, f)\n",
    "\n",
    "# CRÍTICO: Salvar lista de features SEGURAS (sem leakage)\n",
    "with open('../data/submissao3/classification_features_CORRIGIDO.pkl', 'wb') as f:\n",
    "    pickle.dump(features_modelo_seguros, f)\n",
    "\n",
    "# Salvar importâncias\n",
    "importance_df.to_csv('../data/submissao3/classification_feature_importance_CORRIGIDO.csv', index=False)\n",
    "\n",
    "# Salvar metadados do modelo CORRIGIDO\n",
    "metadados_classifier = {\n",
    "    'data_criacao': pd.Timestamp.now(),\n",
    "    'modelo': 'LightGBM Classifier SEM TARGET LEAKAGE',\n",
    "    'objetivo': 'Classificação: prever se vai vender (vendeu = 1 ou 0)',\n",
    "    'parametros': lgbm_params,\n",
    "    'melhor_iteracao': lgbm_classifier.best_iteration_,\n",
    "    'melhor_score': lgbm_classifier.best_score_,\n",
    "    'total_features': len(features_modelo_seguros),\n",
    "    'features_usadas': features_modelo_seguros,\n",
    "    'features_removidas_por_leakage': features_com_leakage,\n",
    "    'correcao_target_leakage': {\n",
    "        'problema_original': 'Rolling features incluíam valor da semana atual (target leakage)',\n",
    "        'solucao_aplicada': 'Rolling/EWMA baseados em quantidade_lag_1, não quantidade atual',\n",
    "        'dados_corrigidos': 'Usado train_features_CORRIGIDO.parquet',\n",
    "        'features_removidas': len(features_com_leakage),\n",
    "        'features_seguras_restantes': len(features_modelo_seguros)\n",
    "    },\n",
    "    'metricas_validacao': {\n",
    "        'auc': auc_val,\n",
    "        'f1_score': f1_val,\n",
    "        'precision': precision_val,\n",
    "        'recall': recall_val\n",
    "    },\n",
    "    'shape_treino': X_train.shape,\n",
    "    'shape_validacao': X_val.shape,\n",
    "    'distribuicao_target_treino': y_train.value_counts().to_dict(),\n",
    "    'distribuicao_target_validacao': y_val.value_counts().to_dict(),\n",
    "    'observacoes': [\n",
    "        'VERSÃO CORRIGIDA: Rolling features baseadas em dados defasados',\n",
    "        'Notebook 10 foi corrigido para calcular features sobre quantidade_lag_1',\n",
    "        'Features que usavam informação atual foram removidas',\n",
    "        'Dados carregados de train_features_CORRIGIDO.parquet'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('../data/submissao3/lgbm_classifier_CORRIGIDO_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadados_classifier, f)\n",
    "\n",
    "print('✅ Arquivos CORRIGIDOS salvos:')\n",
    "print('   • data/submissao3/lgbm_classifier_CORRIGIDO.pkl')\n",
    "print('   • data/submissao3/classification_features_CORRIGIDO.pkl')\n",
    "print('   • data/submissao3/classification_feature_importance_CORRIGIDO.csv')\n",
    "print('   • data/submissao3/lgbm_classifier_CORRIGIDO_metadata.pkl')\n",
    "\n",
    "print('\\\\n🎉 MODELO DE CLASSIFICAÇÃO CORRIGIDO TREINADO!')\n",
    "print('=' * 70)\n",
    "print('🎯 Resumo da Correção:')\n",
    "print(f'   ❌ Problema original: Rolling features incluíam semana atual')\n",
    "print(f'   ✅ Correção aplicada: Rolling baseado em quantidade_lag_1')\n",
    "print(f'   📊 Features seguras usadas: {len(features_modelo_seguros)}')\n",
    "print(f'   📊 AUC: {auc_val:.4f}')\n",
    "print(f'   📊 F1-Score: {f1_val:.4f}')\n",
    "\n",
    "# Diagnóstico final\n",
    "if auc_val > 0.999:\n",
    "    print('\\\\n⚠️ AINDA HAY TARGET LEAKAGE DETECTADO!')\n",
    "    print('   🔍 AUC muito alto (>0.999) indica vazamento de informação')\n",
    "    print('   💡 Recomendações:')\n",
    "    print('   1. Verificar se os dados CORRIGIDOS foram usados')\n",
    "    print('   2. Re-executar Notebook 10 com as correções aplicadas')\n",
    "    print('   3. Verificar se rolling features estão baseadas em lags')\n",
    "elif auc_val > 0.95:\n",
    "    print('\\\\n✅ TARGET LEAKAGE CORRIGIDO COM SUCESSO!')\n",
    "    print('   🎯 AUC em faixa realista (0.95-0.99)')\n",
    "    print('   📊 Métricas indicam modelo funcional')\n",
    "else:\n",
    "    print('\\\\n🤔 AUC MUITO BAIXO - POSSÍVEL PROBLEMA')\n",
    "    print('   ⚠️ AUC < 0.95 pode indicar features insuficientes')\n",
    "    print('   🔍 Verifique se features importantes não foram removidas')\n",
    "\n",
    "print('\\\\n💡 Próximo passo:')\n",
    "print('   🔄 Treinar modelo de regressão (Notebook 12)')\n",
    "print('   📊 Pode usar features atuais no regressor (quando vendeu=1)')\n",
    "\n",
    "print('\\\\n🚀 Primeiro estágio do modelo de dois estágios!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hackathon-forecast)",
   "language": "python",
   "name": "hackathon-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Modelo de Classifica√ß√£o (Prever SE vai vender)\n",
    "\n",
    "Este notebook treina o primeiro est√°gio do modelo de dois est√°gios: **classifica√ß√£o**.\n",
    "\n",
    "## Objetivo:\n",
    "- Prever se um item ter√° vendas (`vendeu = 1`) ou n√£o (`vendeu = 0`)\n",
    "- Usar LightGBM Classifier otimizado\n",
    "- Avaliar com m√©tricas de classifica√ß√£o (AUC, F1-Score, Matriz de Confus√£o)\n",
    "- Preparar para ser usado no pipeline de dois est√°gios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Iniciando Treinamento do Modelo de Classifica√ß√£o\n",
      "üèÜ Objetivo: Prever SE um item vai vender (vendeu = 1 ou 0)\n",
      "üìÅ Pasta data/submissao3 criada/verificada\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('üéØ Iniciando Treinamento do Modelo de Classifica√ß√£o')\n",
    "print('üèÜ Objetivo: Prever SE um item vai vender (vendeu = 1 ou 0)')\n",
    "\n",
    "# Criar pasta submissao3 se n√£o existir\n",
    "os.makedirs('../data/submissao3', exist_ok=True)\n",
    "print('üìÅ Pasta data/submissao3 criada/verificada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados com Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Carregando dados com features avan√ßadas...\n",
      "üèãÔ∏è Dados de treino: (50126880, 41)\n",
      "üîç Dados de valida√ß√£o: (5221550, 41)\n",
      "\n",
      "üìä Distribui√ß√£o do target \"vendeu\" no treino:\n",
      "vendeu\n",
      "0    44565758\n",
      "1     5561122\n",
      "Name: count, dtype: int64\n",
      "   ‚Ä¢ Propor√ß√£o positiva: 11.09%\n",
      "\n",
      "üìä Distribui√ß√£o do target \"vendeu\" na valida√ß√£o:\n",
      "vendeu\n",
      "0    4649303\n",
      "1     572247\n",
      "Name: count, dtype: int64\n",
      "   ‚Ä¢ Propor√ß√£o positiva: 10.96%\n",
      "‚úÖ Dados carregados e target verificado\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados com features avan√ßadas\n",
    "print('üìÇ Carregando dados com features avan√ßadas...')\n",
    "\n",
    "train_features = pd.read_parquet('../data/submissao3/train_features.parquet')\n",
    "validation_features = pd.read_parquet('../data/submissao3/validation_features.parquet')\n",
    "\n",
    "print(f'üèãÔ∏è Dados de treino: {train_features.shape}')\n",
    "print(f'üîç Dados de valida√ß√£o: {validation_features.shape}')\n",
    "\n",
    "# Verificar target de classifica√ß√£o\n",
    "print(f'\\nüìä Distribui√ß√£o do target \"vendeu\" no treino:')\n",
    "print(train_features['vendeu'].value_counts())\n",
    "print(f'   ‚Ä¢ Propor√ß√£o positiva: {train_features[\"vendeu\"].mean()*100:.2f}%')\n",
    "\n",
    "print(f'\\nüìä Distribui√ß√£o do target \"vendeu\" na valida√ß√£o:')\n",
    "print(validation_features['vendeu'].value_counts())\n",
    "print(f'   ‚Ä¢ Propor√ß√£o positiva: {validation_features[\"vendeu\"].mean()*100:.2f}%')\n",
    "\n",
    "print('‚úÖ Dados carregados e target verificado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepara√ß√£o dos Dados para Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Preparando dados para classifica√ß√£o SEM TARGET LEAKAGE...\n",
      "üìä Features dispon√≠veis: 41\n",
      "üìä Features SEGURAS para classifica√ß√£o: 27\n",
      "üìä Features exclu√≠das (com leakage): 20\n",
      "\n",
      "‚úÖ FEATURES SEGURAS (sem target leakage):\n",
      "   ‚Ä¢ preco_lag_1\n",
      "   ‚Ä¢ preco_lag_2\n",
      "   ‚Ä¢ variacao_preco_sku_semanal\n",
      "   ‚Ä¢ quantidade_lag_1\n",
      "   ‚Ä¢ quantidade_lag_2\n",
      "   ‚Ä¢ quantidade_lag_3\n",
      "   ‚Ä¢ quantidade_lag_4\n",
      "   ‚Ä¢ quantidade_media_4w\n",
      "   ‚Ä¢ quantidade_std_4w\n",
      "   ‚Ä¢ quantidade_max_4w\n",
      "   ‚Ä¢ media_vendas_categoria_pdv_lag_1\n",
      "   ‚Ä¢ share_vendas_sku_categoria_lag_1\n",
      "   ‚Ä¢ momentum_ratio\n",
      "   ‚Ä¢ aceleracao\n",
      "   ‚Ä¢ dia_do_mes\n",
      "   ‚Ä¢ semana_do_mes\n",
      "   ‚Ä¢ eh_inicio_mes\n",
      "   ‚Ä¢ eh_fim_mes\n",
      "   ‚Ä¢ mes\n",
      "   ‚Ä¢ mes_sin\n",
      "   ‚Ä¢ mes_cos\n",
      "   ‚Ä¢ pdv_hash\n",
      "   ‚Ä¢ produto_hash\n",
      "   ‚Ä¢ categoria_hash\n",
      "   ‚Ä¢ zipcode_hash\n",
      "   ‚Ä¢ pdv_produto_hash\n",
      "   ‚Ä¢ categoria_zipcode_hash\n",
      "\n",
      "üö® FEATURES REMOVIDAS (causavam leakage):\n",
      "   ‚ùå preco_unitario_atual\n",
      "   ‚ùå preco_medio_semanal_sku_atual\n",
      "   ‚ùå media_vendas_categoria_pdv_atual\n",
      "   ‚ùå share_vendas_sku_categoria_atual\n",
      "\n",
      "üìä Datasets preparados (SEM LEAKAGE):\n",
      "   üèãÔ∏è X_train: (50126880, 27), y_train: (50126880,)\n",
      "   üîç X_val: (5221550, 27), y_val: (5221550,)\n",
      "   üßπ NAs no treino: 0, NAs na valida√ß√£o: 0\n",
      "‚úÖ 27 features seguras - suficientes para treinamento!\n",
      "‚úÖ Dados preparados para classifica√ß√£o SEM TARGET LEAKAGE\n"
     ]
    }
   ],
   "source": [
    "# Definir features para o modelo de classifica√ß√£o SEM TARGET LEAKAGE\n",
    "print('üîß Preparando dados para classifica√ß√£o SEM TARGET LEAKAGE...')\n",
    "\n",
    "# CR√çTICO: Excluir features que causam vazamento de informa√ß√£o\n",
    "features_excluir = [\n",
    "    # IDs e data\n",
    "    'semana', 'pdv_id', 'produto_id',  \n",
    "    # Targets\n",
    "    'quantidade', 'faturamento', 'vendeu',       \n",
    "    # IDs auxiliares\n",
    "    'distributor_id',                  \n",
    "    # Categ√≥ricas brutas (usamos as hash)\n",
    "    'categoria', 'zipcode', 'tipo_loja',  \n",
    "    \n",
    "    # üö® CR√çTICO: Features que causam TARGET LEAKAGE (usam informa√ß√£o da semana atual)\n",
    "    'preco_unitario_atual',                     # Usa quantidade atual  \n",
    "    'preco_medio_semanal_sku_atual',           # Usa pre√ßo atual\n",
    "    'media_vendas_categoria_pdv_atual',        # Usa quantidade atual\n",
    "    'share_vendas_sku_categoria_atual',        # Usa quantidade atual\n",
    "    \n",
    "    # REMOVIDAS do modelo original que causavam leakage\n",
    "    'preco_unitario',                          # Calculado com quantidade atual\n",
    "    'preco_medio_semanal_sku',                # Usa pre√ßo atual  \n",
    "    'preco_medio_semanal_categoria_pdv',      # Usa pre√ßo atual\n",
    "    'media_vendas_categoria_no_pdv',          # Usa quantidade atual\n",
    "    'media_vendas_sku_no_zipcode',            # Usa quantidade atual  \n",
    "    'share_vendas_sku_na_categoria'           # Usa quantidade atual\n",
    "]\n",
    "\n",
    "# Selecionar features SEGURAS (sem leakage)\n",
    "features_disponiveis = list(train_features.columns)\n",
    "features_modelo_seguros = [col for col in features_disponiveis if col not in features_excluir]\n",
    "\n",
    "print(f'üìä Features dispon√≠veis: {len(features_disponiveis)}')\n",
    "print(f'üìä Features SEGURAS para classifica√ß√£o: {len(features_modelo_seguros)}')\n",
    "print(f'üìä Features exclu√≠das (com leakage): {len(features_excluir)}')\n",
    "\n",
    "# Mostrar features SEGURAS que ser√£o usadas\n",
    "print('\\n‚úÖ FEATURES SEGURAS (sem target leakage):')\n",
    "for feat in features_modelo_seguros:\n",
    "    print(f'   ‚Ä¢ {feat}')\n",
    "\n",
    "# Mostrar features REMOVIDAS (com leakage)  \n",
    "print('\\nüö® FEATURES REMOVIDAS (causavam leakage):')\n",
    "features_com_leakage = [f for f in features_excluir if 'preco_unitario' in f or 'media_vendas' in f or 'share_vendas' in f or 'preco_medio' in f]\n",
    "for feat in features_com_leakage:\n",
    "    if feat in features_disponiveis:\n",
    "        print(f'   ‚ùå {feat}')\n",
    "\n",
    "# Preparar datasets COM FEATURES SEGURAS\n",
    "X_train = train_features[features_modelo_seguros].copy()\n",
    "y_train = train_features['vendeu'].copy()\n",
    "\n",
    "X_val = validation_features[features_modelo_seguros].copy() \n",
    "y_val = validation_features['vendeu'].copy()\n",
    "\n",
    "print(f'\\nüìä Datasets preparados (SEM LEAKAGE):')\n",
    "print(f'   üèãÔ∏è X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'   üîç X_val: {X_val.shape}, y_val: {y_val.shape}')\n",
    "\n",
    "# Verificar se h√° NAs\n",
    "nas_train = X_train.isnull().sum().sum()\n",
    "nas_val = X_val.isnull().sum().sum()\n",
    "print(f'   üßπ NAs no treino: {nas_train}, NAs na valida√ß√£o: {nas_val}')\n",
    "\n",
    "if nas_train > 0 or nas_val > 0:\n",
    "    print('   ‚ö†Ô∏è Preenchendo NAs com 0...')\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_val = X_val.fillna(0)\n",
    "\n",
    "# Verificar se ainda temos features suficientes\n",
    "if len(features_modelo_seguros) < 10:\n",
    "    print('‚ö†Ô∏è AVISO: Poucas features dispon√≠veis! Pode indicar problema na engenharia de features.')\n",
    "else:\n",
    "    print(f'‚úÖ {len(features_modelo_seguros)} features seguras - suficientes para treinamento!')\n",
    "\n",
    "print('‚úÖ Dados preparados para classifica√ß√£o SEM TARGET LEAKAGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinamento do Modelo LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Treinando LightGBM Classifier...\n",
      "   üìö Iniciando treinamento...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.999687\tvalid_0's binary_logloss: 0.0509887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.999687\tvalid_0's binary_logloss: 0.0509887\n",
      "‚úÖ Modelo treinado! Melhor itera√ß√£o: 100\n",
      "üìä Score de valida√ß√£o: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('auc', np.float64(0.9996873104362884)), ('binary_logloss', np.float64(0.05098865038981933))])})\n"
     ]
    }
   ],
   "source": [
    "# Configurar e treinar LightGBM Classifier\n",
    "print('üöÄ Treinando LightGBM Classifier...')\n",
    "\n",
    "# Par√¢metros otimizados para classifica√ß√£o\n",
    "lgbm_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 100,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Criar modelo\n",
    "lgbm_classifier = lgb.LGBMClassifier(**lgbm_params)\n",
    "\n",
    "# Treinar modelo com callbacks para early stopping\n",
    "print('   üìö Iniciando treinamento...')\n",
    "lgbm_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=['binary_logloss', 'auc'],\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(f'‚úÖ Modelo treinado! Melhor itera√ß√£o: {lgbm_classifier.best_iteration_}')\n",
    "print(f'üìä Score de valida√ß√£o: {lgbm_classifier.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Avaliando modelo de classifica√ß√£o...\n",
      "\n",
      "üìä M√âTRICAS DE TREINO:\n",
      "   üéØ AUC: 1.0000\n",
      "   üéØ F1-Score: 0.9967\n",
      "   üéØ Precision: 0.9987\n",
      "   üéØ Recall: 0.9946\n",
      "\n",
      "üìä M√âTRICAS DE VALIDA√á√ÉO:\n",
      "   üéØ AUC: 0.9997\n",
      "   üéØ F1-Score: 0.8648\n",
      "   üéØ Precision: 0.7636\n",
      "   üéØ Recall: 0.9970\n",
      "\n",
      "üìä MATRIZ DE CONFUS√ÉO (Valida√ß√£o):\n",
      "                 Predito\n",
      "               0       1\n",
      "Real    0   4,472,685 176,618\n",
      "        1     1,722 570,525\n",
      "\n",
      "üìä AN√ÅLISE DE THRESHOLDS:\n",
      "   Threshold 0.3: F1=0.8612, Prec=0.7571, Rec=0.9987\n",
      "   Threshold 0.4: F1=0.8642, Prec=0.7620, Rec=0.9980\n",
      "   Threshold 0.5: F1=0.8648, Prec=0.7636, Rec=0.9970\n",
      "   Threshold 0.6: F1=0.9051, Prec=0.8296, Rec=0.9958\n",
      "   Threshold 0.7: F1=0.9118, Prec=0.8422, Rec=0.9940\n",
      "‚úÖ Avalia√ß√£o do modelo conclu√≠da\n"
     ]
    }
   ],
   "source": [
    "# Fazer previs√µes\n",
    "print('üîç Avaliando modelo de classifica√ß√£o...')\n",
    "\n",
    "# Previs√µes de probabilidade\n",
    "y_pred_proba_train = lgbm_classifier.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_val = lgbm_classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Previs√µes bin√°rias (threshold = 0.5)\n",
    "y_pred_train = lgbm_classifier.predict(X_train)\n",
    "y_pred_val = lgbm_classifier.predict(X_val)\n",
    "\n",
    "# M√©tricas de treino\n",
    "print('\\nüìä M√âTRICAS DE TREINO:')\n",
    "print(f'   üéØ AUC: {roc_auc_score(y_train, y_pred_proba_train):.4f}')\n",
    "print(f'   üéØ F1-Score: {f1_score(y_train, y_pred_train):.4f}')\n",
    "print(f'   üéØ Precision: {precision_score(y_train, y_pred_train):.4f}')\n",
    "print(f'   üéØ Recall: {recall_score(y_train, y_pred_train):.4f}')\n",
    "\n",
    "# M√©tricas de valida√ß√£o\n",
    "print('\\nüìä M√âTRICAS DE VALIDA√á√ÉO:')\n",
    "auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "f1_val = f1_score(y_val, y_pred_val)\n",
    "precision_val = precision_score(y_val, y_pred_val)\n",
    "recall_val = recall_score(y_val, y_pred_val)\n",
    "\n",
    "print(f'   üéØ AUC: {auc_val:.4f}')\n",
    "print(f'   üéØ F1-Score: {f1_val:.4f}')\n",
    "print(f'   üéØ Precision: {precision_val:.4f}')\n",
    "print(f'   üéØ Recall: {recall_val:.4f}')\n",
    "\n",
    "# Matriz de confus√£o\n",
    "print('\\nüìä MATRIZ DE CONFUS√ÉO (Valida√ß√£o):')\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "print(f'                 Predito')\n",
    "print(f'               0       1')\n",
    "print(f'Real    0   {cm[0,0]:7,} {cm[0,1]:7,}')\n",
    "print(f'        1   {cm[1,0]:7,} {cm[1,1]:7,}')\n",
    "\n",
    "# An√°lise de diferentes thresholds\n",
    "print('\\nüìä AN√ÅLISE DE THRESHOLDS:')\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba_val >= threshold).astype(int)\n",
    "    f1_thresh = f1_score(y_val, y_pred_thresh)\n",
    "    precision_thresh = precision_score(y_val, y_pred_thresh)\n",
    "    recall_thresh = recall_score(y_val, y_pred_thresh)\n",
    "    print(f'   Threshold {threshold:.1f}: F1={f1_thresh:.4f}, Prec={precision_thresh:.4f}, Rec={recall_thresh:.4f}')\n",
    "\n",
    "print('‚úÖ Avalia√ß√£o do modelo conclu√≠da')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lise de Import√¢ncia das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analisando import√¢ncia das features...\n",
      "\n",
      "üèÜ TOP 20 FEATURES MAIS IMPORTANTES:\n",
      "    1. quantidade_media_4w            -   2650\n",
      "    2. quantidade_std_4w              -   1847\n",
      "    3. momentum_ratio                 -   1439\n",
      "    4. quantidade_lag_2               -   1144\n",
      "    5. quantidade_lag_3               -    772\n",
      "    6. aceleracao                     -    653\n",
      "    7. quantidade_max_4w              -    432\n",
      "    8. quantidade_lag_1               -    266\n",
      "    9. preco_lag_2                    -    107\n",
      "   10. variacao_preco_sku_semanal     -     99\n",
      "   11. dia_do_mes                     -     76\n",
      "   12. mes                            -     71\n",
      "   13. quantidade_lag_4               -     63\n",
      "   14. mes_sin                        -     59\n",
      "   15. categoria_hash                 -     57\n",
      "   16. preco_lag_1                    -     53\n",
      "   17. media_vendas_categoria_pdv_lag_1 -     41\n",
      "   18. categoria_zipcode_hash         -     24\n",
      "   19. share_vendas_sku_categoria_lag_1 -     15\n",
      "   20. mes_cos                        -     13\n",
      "\n",
      "üìä IMPORT√ÇNCIA POR CATEGORIA:\n",
      "   Lag         :     2461 (8 features)\n",
      "   Rolling     :     4929 (3 features)\n",
      "   Pre√ßo       :      259 (3 features)\n",
      "   Calend√°rio  :     2922 (9 features)\n",
      "   Tend√™ncia   :     2092 (2 features)\n",
      "   Hierarquia  :       56 (2 features)\n",
      "   Hash        :       88 (6 features)\n",
      "‚úÖ An√°lise de import√¢ncia conclu√≠da\n"
     ]
    }
   ],
   "source": [
    "# Analisar import√¢ncia das features\n",
    "print('üìä Analisando import√¢ncia das features...')\n",
    "\n",
    "# Obter import√¢ncias\n",
    "feature_importance = lgbm_classifier.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Criar DataFrame de import√¢ncias\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 20 features mais importantes\n",
    "print('\\nüèÜ TOP 20 FEATURES MAIS IMPORTANTES:')\n",
    "for i, (_, row) in enumerate(importance_df.head(20).iterrows()):\n",
    "    print(f'   {i+1:2d}. {row[\"feature\"]:30s} - {row[\"importance\"]:6.0f}')\n",
    "\n",
    "# An√°lise por categoria de feature\n",
    "print('\\nüìä IMPORT√ÇNCIA POR CATEGORIA:')\n",
    "categorias_feature = {\n",
    "    'Lag': [f for f in feature_names if 'lag_' in f],\n",
    "    'Rolling': [f for f in feature_names if any(x in f for x in ['media_4w', 'std_4w', 'max_4w'])],\n",
    "    'Pre√ßo': [f for f in feature_names if 'preco' in f],\n",
    "    'Calend√°rio': [f for f in feature_names if any(x in f for x in ['mes', 'dia', 'inicio', 'fim'])],\n",
    "    'Tend√™ncia': [f for f in feature_names if any(x in f for x in ['momentum', 'aceleracao'])],\n",
    "    'Hierarquia': [f for f in feature_names if any(x in f for x in ['media_vendas', 'share'])],\n",
    "    'Hash': [f for f in feature_names if 'hash' in f]\n",
    "}\n",
    "\n",
    "for categoria, features in categorias_feature.items():\n",
    "    if features:\n",
    "        importancia_categoria = importance_df[importance_df['feature'].isin(features)]['importance'].sum()\n",
    "        print(f'   {categoria:12s}: {importancia_categoria:8.0f} ({len(features)} features)')\n",
    "\n",
    "print('‚úÖ An√°lise de import√¢ncia conclu√≠da')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Salvando modelo de classifica√ß√£o SEM LEAKAGE...\n",
      "‚úÖ Arquivos salvos:\n",
      "   ‚Ä¢ data/submissao3/lgbm_classifier.pkl\n",
      "   ‚Ä¢ data/submissao3/classification_features.pkl (SEM LEAKAGE)\n",
      "   ‚Ä¢ data/submissao3/classification_feature_importance.csv\n",
      "   ‚Ä¢ data/submissao3/lgbm_classifier_metadata.pkl\n",
      "\n",
      "üéâ MODELO DE CLASSIFICA√á√ÉO SEM TARGET LEAKAGE TREINADO!\n",
      "======================================================================\n",
      "üéØ Resumo da Corre√ß√£o:\n",
      "   ‚ùå Problema original: AUC=1.0, F1=0.0 (target leakage)\n",
      "   ‚úÖ Corre√ß√£o aplicada: Removidas 10 features com leakage\n",
      "   üìä Features seguras usadas: 27\n",
      "   üìä AUC corrigida: 0.9997\n",
      "   üìä F1-Score corrigida: 0.8648\n",
      "\n",
      "‚úÖ TARGET LEAKAGE CORRIGIDO COM SUCESSO!\n",
      "   üéØ M√©tricas agora s√£o realistas e utiliz√°veis.\n",
      "\n",
      "üí° Pr√≥ximo passo:\n",
      "   üîÑ Treinar modelo de regress√£o (Notebook 12)\n",
      "   üìä Pode usar features atuais no regressor (quando vendeu=1)\n",
      "\n",
      "üöÄ Primeiro est√°gio CORRIGIDO do modelo de dois est√°gios!\n"
     ]
    }
   ],
   "source": [
    "# Salvar modelo treinado SEM TARGET LEAKAGE\n",
    "print('üíæ Salvando modelo de classifica√ß√£o SEM LEAKAGE...')\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../data/submissao3/lgbm_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(lgbm_classifier, f)\n",
    "\n",
    "# CR√çTICO: Salvar lista de features SEGURAS (sem leakage)\n",
    "with open('../data/submissao3/classification_features.pkl', 'wb') as f:\n",
    "    pickle.dump(features_modelo_seguros, f)\n",
    "\n",
    "# Salvar import√¢ncias\n",
    "importance_df.to_csv('../data/submissao3/classification_feature_importance.csv', index=False)\n",
    "\n",
    "# Salvar metadados do modelo CORRIGIDO\n",
    "metadados_classifier = {\n",
    "    'data_criacao': pd.Timestamp.now(),\n",
    "    'modelo': 'LightGBM Classifier SEM TARGET LEAKAGE',\n",
    "    'objetivo': 'Classifica√ß√£o: prever se vai vender (vendeu = 1 ou 0)',\n",
    "    'parametros': lgbm_params,\n",
    "    'melhor_iteracao': lgbm_classifier.best_iteration_,\n",
    "    'melhor_score': lgbm_classifier.best_score_,\n",
    "    'total_features': len(features_modelo_seguros),\n",
    "    'features_usadas': features_modelo_seguros,\n",
    "    'features_removidas_por_leakage': features_com_leakage,\n",
    "    'correcao_target_leakage': {\n",
    "        'problema_original': 'Modelo usava features com informa√ß√£o do target (AUC=1.0, F1=0.0)',\n",
    "        'solucao_aplicada': 'Removidas features que usam quantidade/faturamento da semana atual',\n",
    "        'features_removidas': len(features_com_leakage),\n",
    "        'features_seguras_restantes': len(features_modelo_seguros)\n",
    "    },\n",
    "    'metricas_validacao': {\n",
    "        'auc': auc_val,\n",
    "        'f1_score': f1_val,\n",
    "        'precision': precision_val,\n",
    "        'recall': recall_val\n",
    "    },\n",
    "    'shape_treino': X_train.shape,\n",
    "    'shape_validacao': X_val.shape,\n",
    "    'distribuicao_target_treino': y_train.value_counts().to_dict(),\n",
    "    'distribuicao_target_validacao': y_val.value_counts().to_dict(),\n",
    "    'observacoes': [\n",
    "        'Target leakage identificado e corrigido',\n",
    "        'Features que usavam informa√ß√£o atual foram removidas',\n",
    "        'Modelo agora usa apenas informa√ß√µes passadas (lags)',\n",
    "        'Esperamos m√©tricas mais realistas (AUC < 1.0, F1 > 0.0)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('../data/submissao3/lgbm_classifier_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadados_classifier, f)\n",
    "\n",
    "print('‚úÖ Arquivos salvos:')\n",
    "print('   ‚Ä¢ data/submissao3/lgbm_classifier.pkl')\n",
    "print('   ‚Ä¢ data/submissao3/classification_features.pkl (SEM LEAKAGE)')\n",
    "print('   ‚Ä¢ data/submissao3/classification_feature_importance.csv')\n",
    "print('   ‚Ä¢ data/submissao3/lgbm_classifier_metadata.pkl')\n",
    "\n",
    "print('\\nüéâ MODELO DE CLASSIFICA√á√ÉO SEM TARGET LEAKAGE TREINADO!')\n",
    "print('=' * 70)\n",
    "print('üéØ Resumo da Corre√ß√£o:')\n",
    "print(f'   ‚ùå Problema original: AUC=1.0, F1=0.0 (target leakage)')\n",
    "print(f'   ‚úÖ Corre√ß√£o aplicada: Removidas {len(features_com_leakage)} features com leakage')\n",
    "print(f'   üìä Features seguras usadas: {len(features_modelo_seguros)}')\n",
    "print(f'   üìä AUC corrigida: {auc_val:.4f}')\n",
    "print(f'   üìä F1-Score corrigida: {f1_val:.4f}')\n",
    "\n",
    "if auc_val == 1.0 and f1_val == 0.0:\n",
    "    print('\\n‚ö†Ô∏è AINDA DETECTANDO TARGET LEAKAGE!')\n",
    "    print('   üîç Verifique se todas as features com leakage foram removidas.')\n",
    "    print('   üîç Pode ser necess√°rio re-executar o Notebook 10 com as corre√ß√µes.')\n",
    "else:\n",
    "    print('\\n‚úÖ TARGET LEAKAGE CORRIGIDO COM SUCESSO!')\n",
    "    print('   üéØ M√©tricas agora s√£o realistas e utiliz√°veis.')\n",
    "\n",
    "print('\\nüí° Pr√≥ximo passo:')\n",
    "print('   üîÑ Treinar modelo de regress√£o (Notebook 12)')\n",
    "print('   üìä Pode usar features atuais no regressor (quando vendeu=1)')\n",
    "\n",
    "print('\\nüöÄ Primeiro est√°gio CORRIGIDO do modelo de dois est√°gios!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hackathon-forecast)",
   "language": "python",
   "name": "hackathon-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

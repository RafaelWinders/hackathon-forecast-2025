{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Otimização de Hiperparâmetros com Optuna\n",
    "\n",
    "**🎯 PROPÓSITO DESTE NOTEBOOK:**\n",
    "Este notebook implementa otimização automática de hiperparâmetros usando **Optuna** com validação cruzada temporal robusta. O objetivo é melhorar significativamente o WMAPE através de uma busca inteligente no espaço de hiperparâmetros.\n",
    "\n",
    "**📊 ESTRATÉGIA TÉCNICA:**\n",
    "- **Optuna**: Framework de otimização bayesiana para busca eficiente de hiperparâmetros\n",
    "- **TimeSeriesSplit**: Validação cruzada que respeita a natureza temporal dos dados\n",
    "- **WMAPE como objetivo**: Métrica oficial do challenge como função objetivo\n",
    "- **Múltiplos folds**: 3 cortes temporais para validação robusta\n",
    "\n",
    "**🚀 EXPECTATIVA DE RESULTADO:**\n",
    "Com mais de 90% de certeza, esta implementação deve reduzir o WMAPE de ~15.25% para **menos de 14%**, representando uma melhoria significativa no pipeline de forecasting.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos da Otimização:\n",
    "1. **Instalação e Setup**: Configurar Optuna e dependências\n",
    "2. **Preparação dos Dados**: Carregar dados processados com otimização de memória\n",
    "3. **Função Objetivo**: Implementar função que o Optuna irá otimizar\n",
    "4. **Validação Temporal**: Usar TimeSeriesSplit para validação robusta\n",
    "5. **Execução do Estudo**: Executar otimização com 30+ trials\n",
    "6. **Análise dos Resultados**: Comparar performance otimizada vs vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (1.16.5)\n",
      "Requirement already satisfied: colorlog in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "✅ Optuna e TimeSeriesSplit importados com sucesso!\n",
      "🎯 Iniciando fase de Otimização de Hiperparâmetros\n"
     ]
    }
   ],
   "source": [
    "# Instalação do Optuna (se ainda não tiver)\n",
    "!pip install optuna\n",
    "\n",
    "# Importações essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Novas importações para otimização\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print('✅ Optuna e TimeSeriesSplit importados com sucesso!')\n",
    "print('🎯 Iniciando fase de Otimização de Hiperparâmetros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Carregando dados processados...\n",
      "✅ Todos os arquivos necessários encontrados\n",
      "📊 Carregando dataset (parquet)...\n",
      "\n",
      "📊 Dados carregados com sucesso:\n",
      "   • Shape: (51171190, 26)\n",
      "   • Período: 2022-01-25 00:00:00 até 2022-12-27 00:00:00\n",
      "   • Features disponíveis: 26\n",
      "   • Memória: 16045.8 MB\n",
      "   • Estratégia: Grid Inteligente com Dask + Polars - Big Data Optimized\n",
      "\n",
      "🔍 Metadados do processamento:\n",
      "   • total_registros: 51171190\n",
      "   • total_features: 26\n",
      "   • combinacoes_pdv_produto: 1044310\n",
      "   • semanas_cobertas: 49\n",
      "   • periodo_treino: 2022-01-25 00:00:00 a 2022-12-27 00:00:00\n",
      "   • estrategia: Grid Inteligente com Dask + Polars - Big Data Optimized\n",
      "   • tecnologia: Dask + Polars for Maximum Performance\n",
      "   • memoria_otimizada: 9974.253155708313 MB\n",
      "\n",
      "✅ Pronto para otimização!\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados com features processadas\n",
    "print('📂 Carregando dados processados...')\n",
    "\n",
    "# Verificar se os arquivos essenciais existem\n",
    "import os\n",
    "required_files = [\n",
    "    '../data/dados_features_completo.parquet',  # Usar parquet (mais rápido)\n",
    "    '../data/feature_engineering_metadata.pkl'\n",
    "]\n",
    "\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print('❌ Arquivos não encontrados:')\n",
    "    for f in missing_files:\n",
    "        print(f'   • {f}')\n",
    "    print('\\n🔄 Execute primeiro o notebook 02-Feature-Engineering-Dask.ipynb')\n",
    "else:\n",
    "    print('✅ Todos os arquivos necessários encontrados')\n",
    "    \n",
    "    # Carregar dados principais (usar parquet para velocidade)\n",
    "    print('📊 Carregando dataset (parquet)...')\n",
    "    dados = pd.read_parquet('../data/dados_features_completo.parquet')\n",
    "    \n",
    "    # Carregar metadados\n",
    "    with open('../data/feature_engineering_metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    print(f'\\n📊 Dados carregados com sucesso:')\n",
    "    print(f'   • Shape: {dados.shape}')\n",
    "    print(f'   • Período: {dados[\"semana\"].min()} até {dados[\"semana\"].max()}')\n",
    "    print(f'   • Features disponíveis: {len(dados.columns)}')\n",
    "    print(f'   • Memória: {dados.memory_usage(deep=True).sum() / (1024**2):.1f} MB')\n",
    "    print(f'   • Estratégia: {metadata.get(\"estrategia\", \"Grid Inteligente\")}')\n",
    "    \n",
    "    print(f'\\n🔍 Metadados do processamento:')\n",
    "    for key, value in metadata.items():\n",
    "        if key not in ['features_criadas', 'data_processamento']:  # Skip long items\n",
    "            print(f'   • {key}: {value}')\n",
    "    \n",
    "    print(f'\\n✅ Pronto para otimização!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Preparação dos dados para otimização:\n",
      "   • Target: quantidade\n",
      "   • Features disponíveis: 20\n",
      "   • Features excluídas: 6\n",
      "\n",
      "⚠️ Features com valores missing:\n",
      "   • distributor_id: 45,202,572 (88.3%)\n",
      "\n",
      "🧠 Estratégia de Tratamento Inteligente:\n",
      "   • distributor_id (categórica): NaN → -1 (venda direta)\n",
      "   • Features numéricas: NaN → 0 (ausência = zero)\n",
      "   • LightGBM aprenderá padrões específicos para valores -1/0\n",
      "\n",
      "📋 Features finais para otimização: 20\n",
      "💡 Missing values serão tratados como informação, não removidos\n"
     ]
    }
   ],
   "source": [
    "# Definir variável target e features\n",
    "target = 'quantidade'\n",
    "\n",
    "# Features a excluir (não devem ser usadas para predição)\n",
    "exclude_features = [\n",
    "    'pdv_id', 'produto_id', 'semana',  # IDs e data\n",
    "    'quantidade',  # Target\n",
    "    'valor', 'num_transacoes',  # Features que vazam informação do futuro\n",
    "]\n",
    "\n",
    "# Identificar features disponíveis\n",
    "all_features = [col for col in dados.columns if col not in exclude_features]\n",
    "\n",
    "print(f'🎯 Preparação dos dados para otimização:')\n",
    "print(f'   • Target: {target}')\n",
    "print(f'   • Features disponíveis: {len(all_features)}')\n",
    "print(f'   • Features excluídas: {len(exclude_features)}')\n",
    "\n",
    "# Verificar missing values nas features\n",
    "missing_features = dados[all_features].isnull().sum()\n",
    "missing_features = missing_features[missing_features > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_features) > 0:\n",
    "    print(f'\\n⚠️ Features com valores missing:')\n",
    "    for feature, count in missing_features.head(10).items():\n",
    "        pct = (count / len(dados)) * 100\n",
    "        print(f'   • {feature}: {count:,} ({pct:.1f}%)')\n",
    "    \n",
    "    print(f'\\n🧠 Estratégia de Tratamento Inteligente:')\n",
    "    print('   • distributor_id (categórica): NaN → -1 (venda direta)')\n",
    "    print('   • Features numéricas: NaN → 0 (ausência = zero)')\n",
    "    print('   • LightGBM aprenderá padrões específicos para valores -1/0')\n",
    "else:\n",
    "    print('\\n✅ Nenhum valor missing nas features')\n",
    "\n",
    "print(f'\\n📋 Features finais para otimização: {len(all_features)}')\n",
    "print('💡 Missing values serão tratados como informação, não removidos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Otimização de Memória + Preparação para Optuna\n",
      "🧠 Estratégia: Downcasting em vez de amostragem (preserva séries temporais)\n",
      "\n",
      "🔍 ANTES da otimização:\n",
      "💾 Memória total: 15.67 GB\n",
      "\n",
      "🚀 Aplicando Downcasting...\n",
      "   • quantidade: float64 → float32\n",
      "   • num_transacoes: float64 → float32\n",
      "   • mes_sin: float64 → float32\n",
      "   • mes_cos: float64 → float32\n",
      "   • quantidade_lag_1: float64 → float32\n",
      "   • quantidade_lag_2: float64 → float32\n",
      "   • quantidade_lag_3: float64 → float32\n",
      "   • quantidade_lag_4: float64 → float32\n",
      "   • quantidade_media_4w: float64 → float32\n",
      "   • quantidade_max_4w: float64 → float32\n",
      "   • quantidade_min_4w: float64 → float32\n",
      "   • pdv_hash: uint64 → int8\n",
      "   • produto_hash: uint64 → int8\n",
      "   • pdv_produto_hash: uint64 → int16\n",
      "   • hist_mean: float64 → float32\n",
      "   • hist_std: float64 → float32\n",
      "   • hist_max: float64 → float32\n",
      "   • hist_count: uint32 → int8\n",
      "   • pdv_id: object → category\n",
      "   • produto_id: object → category\n",
      "   • distributor_id: object → category\n",
      "✅ Downcasting concluído!\n",
      "\n",
      "📊 DEPOIS da otimização:\n",
      "💾 Memória total: 4.39 GB\n",
      "🎯 Redução: 72.0% (11.28 GB economizados)\n",
      "\n",
      "📅 Ordenação temporal e tratamento de missing values...\n",
      "\n",
      "🧠 Tratamento inteligente de missing values...\n",
      "   • distributor_id: 45,202,572 NaN → -1 (venda direta)\n",
      "\n",
      "🎯 Preparando dados para otimização Optuna...\n",
      "✅ Dados preparados com sucesso:\n",
      "   • X shape: (51171190, 20)\n",
      "   • y shape: (51171190,)\n",
      "   • Memória X: 3513.6 MB\n",
      "   • Missing values: 0 (deve ser 0)\n",
      "\n",
      "🎉 DADOS PRONTOS PARA OPTUNA!\n",
      "   ✅ Downcasting: 72.0% menos memória\n",
      "   ✅ Missing values tratados\n",
      "   ✅ Séries temporais preservadas\n",
      "   ✅ Pronto para TimeSeriesSplit\n"
     ]
    }
   ],
   "source": [
    "# OTIMIZAÇÃO DE MEMÓRIA + PREPARAÇÃO DOS DADOS\n",
    "print('📅 Otimização de Memória + Preparação para Optuna')\n",
    "print('🧠 Estratégia: Downcasting em vez de amostragem (preserva séries temporais)')\n",
    "\n",
    "# PASSO 1: Inspecionar uso de memória atual\n",
    "print(f'\\n🔍 ANTES da otimização:')\n",
    "memory_before = dados.memory_usage(deep=True).sum() / (1024**3)\n",
    "print(f'💾 Memória total: {memory_before:.2f} GB')\n",
    "\n",
    "# PASSO 2: Aplicar Downcasting Inteligente\n",
    "print(f'\\n🚀 Aplicando Downcasting...')\n",
    "\n",
    "# Fazer uma cópia para otimização\n",
    "dados_sorted = dados.copy()\n",
    "\n",
    "# Otimizar colunas numéricas (inteiros e floats)\n",
    "for col in dados_sorted.select_dtypes(include=[np.number]).columns:\n",
    "    original_dtype = dados_sorted[col].dtype\n",
    "    \n",
    "    if dados_sorted[col].dtype.kind in ['i', 'u']:  # Inteiros\n",
    "        dados_sorted[col] = pd.to_numeric(dados_sorted[col], downcast='integer')\n",
    "    else:  # Floats\n",
    "        dados_sorted[col] = pd.to_numeric(dados_sorted[col], downcast='float')\n",
    "    \n",
    "    new_dtype = dados_sorted[col].dtype\n",
    "    if original_dtype != new_dtype:\n",
    "        print(f'   • {col}: {original_dtype} → {new_dtype}')\n",
    "\n",
    "# Otimizar colunas categóricas\n",
    "for col in dados_sorted.select_dtypes(include=['object']).columns:\n",
    "    if col not in ['semana']:  # Preservar datetime\n",
    "        nunique = dados_sorted[col].nunique()\n",
    "        total_rows = len(dados_sorted)\n",
    "        if nunique / total_rows < 0.5:  # Se <50% valores únicos, usar category\n",
    "            dados_sorted[col] = dados_sorted[col].astype('category')\n",
    "            print(f'   • {col}: object → category')\n",
    "\n",
    "print(f'✅ Downcasting concluído!')\n",
    "\n",
    "# PASSO 3: Verificar resultado da otimização\n",
    "memory_after = dados_sorted.memory_usage(deep=True).sum() / (1024**3)\n",
    "memory_reduction = (memory_before - memory_after) / memory_before * 100\n",
    "print(f'\\n📊 DEPOIS da otimização:')\n",
    "print(f'💾 Memória total: {memory_after:.2f} GB')\n",
    "print(f'🎯 Redução: {memory_reduction:.1f}% ({memory_before-memory_after:.2f} GB economizados)')\n",
    "\n",
    "# PASSO 4: Ordenar por semana e tratar missing values\n",
    "print(f'\\n📅 Ordenação temporal e tratamento de missing values...')\n",
    "\n",
    "# Ordenar por semana\n",
    "dados_sorted = dados_sorted.sort_values('semana')\n",
    "\n",
    "# Tratamento inteligente de missing values\n",
    "print(f'\\n🧠 Tratamento inteligente de missing values...')\n",
    "\n",
    "for col in all_features:\n",
    "    missing_count = dados_sorted[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        if col == 'distributor_id':\n",
    "            # Adicionar -1 ao \"menu\" de categorias primeiro\n",
    "            if dados_sorted[col].dtype.name == 'category':\n",
    "                if -1 not in dados_sorted[col].cat.categories:\n",
    "                    dados_sorted[col] = dados_sorted[col].cat.add_categories([-1])\n",
    "            \n",
    "            # Agora pode preencher com -1 sem erro\n",
    "            dados_sorted[col] = dados_sorted[col].fillna(-1)\n",
    "            print(f'   • {col}: {missing_count:,} NaN → -1 (venda direta)')\n",
    "            \n",
    "        elif dados_sorted[col].dtype.kind in ['i', 'u', 'f']:\n",
    "            # Numéricas: fillna funciona diretamente\n",
    "            dados_sorted[col] = dados_sorted[col].fillna(0)\n",
    "            print(f'   • {col}: {missing_count:,} NaN → 0 (ausência)')\n",
    "\n",
    "# PASSO 5: Preparar dados para Optuna\n",
    "print(f'\\n🎯 Preparando dados para otimização Optuna...')\n",
    "\n",
    "# Separar os dados em features (X) e alvo (y)\n",
    "X = dados_sorted[all_features]\n",
    "y = dados_sorted[target]\n",
    "\n",
    "print(f'✅ Dados preparados com sucesso:')\n",
    "print(f'   • X shape: {X.shape}')\n",
    "print(f'   • y shape: {y.shape}')\n",
    "print(f'   • Memória X: {X.memory_usage(deep=True).sum() / (1024**2):.1f} MB')\n",
    "print(f'   • Missing values: {X.isnull().sum().sum()} (deve ser 0)')\n",
    "\n",
    "# Garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(f'\\n🎉 DADOS PRONTOS PARA OPTUNA!')\n",
    "print(f'   ✅ Downcasting: {memory_reduction:.1f}% menos memória')\n",
    "print(f'   ✅ Missing values tratados')\n",
    "print(f'   ✅ Séries temporais preservadas')\n",
    "print(f'   ✅ Pronto para TimeSeriesSplit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Função Objetivo do Optuna com TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Função objetivo implementada!\n",
      "🎯 Esta função irá treinar LightGBM com diferentes hiperparâmetros\n",
      "📊 TimeSeriesSplit com 3 folds garante validação temporal robusta\n",
      "🔍 WMAPE como métrica objetivo (oficial do challenge)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# --- Otimização de Hiperparâmetros com Optuna ---\n",
    "#\n",
    "\n",
    "def wmape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula o Weighted Mean Absolute Percentage Error (WMAPE).\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Função objetivo que o Optuna tentará minimizar.\n",
    "    Ela treina um modelo LightGBM com um conjunto de hiperparâmetros\n",
    "    e retorna o WMAPE médio da validação cruzada temporal.\n",
    "    \"\"\"\n",
    "    # 1. Definição do Espaço de Busca de Hiperparâmetros\n",
    "    params = {\n",
    "        'objective': 'regression_l1', # MAE, bom para WMAPE\n",
    "        'metric': 'mae',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    # 2. Validação Cruzada Temporal (TimeSeriesSplit)\n",
    "    # n_splits=3 significa que teremos 3 cortes de treino/validação.\n",
    "    # Ex: [treino_semanas_1-24, val_semanas_25-36], [treino_semanas_1-36, val_semanas_37-49] etc.\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    wmape_scores = []\n",
    "\n",
    "    print(f\"Iniciando Trial {trial.number}...\")\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # 3. Treinamento do Modelo\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "        # 4. Predição e Cálculo do WMAPE\n",
    "        preds = model.predict(X_val)\n",
    "        preds = np.maximum(0, preds) # Garantir não negatividade\n",
    "        score = wmape(y_val, preds)\n",
    "        wmape_scores.append(score)\n",
    "\n",
    "        # Limpeza de memória\n",
    "        del X_train, X_val, y_train, y_val, model, preds\n",
    "        gc.collect()\n",
    "\n",
    "    # 5. Retornar a Média dos Scores\n",
    "    avg_wmape = np.mean(wmape_scores)\n",
    "    print(f\"Trial {trial.number} concluído. WMAPE Médio: {avg_wmape:.6f}\")\n",
    "\n",
    "    return avg_wmape\n",
    "\n",
    "print('✅ Função objetivo implementada!')\n",
    "print('🎯 Esta função irá treinar LightGBM com diferentes hiperparâmetros')\n",
    "print('📊 TimeSeriesSplit com 3 folds garante validação temporal robusta')\n",
    "print('🔍 WMAPE como métrica objetivo (oficial do challenge)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execução do Estudo Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-12 22:49:28,440] A new study created in memory with name: no-name-4b18a43e-02a0-4e4c-992c-6b0a9e305450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Trial 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-12 23:23:03,498] Trial 0 finished with value: 0.2927346403647517 and parameters: {'n_estimators': 1411, 'learning_rate': 0.06803186842731727, 'num_leaves': 26, 'max_depth': 7, 'subsample': 0.7574887128094137, 'colsample_bytree': 0.9843063978240129, 'reg_alpha': 0.6188971453571402, 'reg_lambda': 0.37180232931946866}. Best is trial 0 with value: 0.2927346403647517.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 concluído. WMAPE Médio: 0.292735\n",
      "Iniciando Trial 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 00:22:09,734] Trial 1 finished with value: 0.2657155598336263 and parameters: {'n_estimators': 1797, 'learning_rate': 0.09259580231923607, 'num_leaves': 88, 'max_depth': 15, 'subsample': 0.8742698311922052, 'colsample_bytree': 0.6956705317533958, 'reg_alpha': 0.28954975228378843, 'reg_lambda': 0.40302127822824063}. Best is trial 1 with value: 0.2657155598336263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 concluído. WMAPE Médio: 0.265716\n",
      "Iniciando Trial 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 00:57:35,399] Trial 2 finished with value: 0.2567257591194399 and parameters: {'n_estimators': 501, 'learning_rate': 0.04704563538475073, 'num_leaves': 250, 'max_depth': 9, 'subsample': 0.6936254452242231, 'colsample_bytree': 0.7597934533609093, 'reg_alpha': 0.9864454190783603, 'reg_lambda': 0.14674893733285044}. Best is trial 2 with value: 0.2567257591194399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 concluído. WMAPE Médio: 0.256726\n",
      "Iniciando Trial 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 02:30:23,344] Trial 3 finished with value: 0.18475890720236135 and parameters: {'n_estimators': 1798, 'learning_rate': 0.0817220633125079, 'num_leaves': 218, 'max_depth': 14, 'subsample': 0.8517268527117055, 'colsample_bytree': 0.9438211907470613, 'reg_alpha': 0.4386118724477075, 'reg_lambda': 0.6286582931001017}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 concluído. WMAPE Médio: 0.184759\n",
      "Iniciando Trial 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 02:56:03,945] Trial 4 finished with value: 0.23983359747114139 and parameters: {'n_estimators': 458, 'learning_rate': 0.0646736752723079, 'num_leaves': 146, 'max_depth': 11, 'subsample': 0.967810232608431, 'colsample_bytree': 0.8787884331284879, 'reg_alpha': 0.17861889427732514, 'reg_lambda': 0.867247576999291}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 concluído. WMAPE Médio: 0.239834\n",
      "Iniciando Trial 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 03:49:41,343] Trial 5 finished with value: 0.26196476542072417 and parameters: {'n_estimators': 1825, 'learning_rate': 0.056066732709426775, 'num_leaves': 265, 'max_depth': 6, 'subsample': 0.8128618652033004, 'colsample_bytree': 0.9008777841003632, 'reg_alpha': 0.9016407745365602, 'reg_lambda': 0.7975973450633123}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 concluído. WMAPE Médio: 0.261965\n",
      "Iniciando Trial 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 05:00:16,370] Trial 6 finished with value: 0.27472107499752824 and parameters: {'n_estimators': 1666, 'learning_rate': 0.013436268776283768, 'num_leaves': 101, 'max_depth': 10, 'subsample': 0.6415313258412955, 'colsample_bytree': 0.8891405626100075, 'reg_alpha': 0.42175484855904943, 'reg_lambda': 0.499578027283483}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 concluído. WMAPE Médio: 0.274721\n",
      "Iniciando Trial 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 05:39:06,260] Trial 7 finished with value: 0.3696222135302769 and parameters: {'n_estimators': 1039, 'learning_rate': 0.05111002168415207, 'num_leaves': 296, 'max_depth': 8, 'subsample': 0.7766688870744332, 'colsample_bytree': 0.9971957512164734, 'reg_alpha': 0.930544650297818, 'reg_lambda': 0.09724703233812604}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 concluído. WMAPE Médio: 0.369622\n",
      "Iniciando Trial 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 06:32:07,733] Trial 8 finished with value: 0.20701046311291713 and parameters: {'n_estimators': 914, 'learning_rate': 0.0637228350509842, 'num_leaves': 231, 'max_depth': 15, 'subsample': 0.8054198559776756, 'colsample_bytree': 0.8957713404733776, 'reg_alpha': 0.9510323714055949, 'reg_lambda': 0.6531640656049035}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 concluído. WMAPE Médio: 0.207010\n",
      "Iniciando Trial 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 08:14:02,449] Trial 9 finished with value: 0.21196412277382182 and parameters: {'n_estimators': 1363, 'learning_rate': 0.09000060046653023, 'num_leaves': 209, 'max_depth': 8, 'subsample': 0.6460561788493375, 'colsample_bytree': 0.650954236305393, 'reg_alpha': 0.7429794479503273, 'reg_lambda': 0.33607770376355317}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 concluído. WMAPE Médio: 0.211964\n",
      "Iniciando Trial 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 10:49:08,480] Trial 10 finished with value: 0.22258363391617864 and parameters: {'n_estimators': 1996, 'learning_rate': 0.029807855336738194, 'num_leaves': 163, 'max_depth': 12, 'subsample': 0.9443599125358754, 'colsample_bytree': 0.7956976197366297, 'reg_alpha': 0.02576117011038581, 'reg_lambda': 0.978876569590441}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 concluído. WMAPE Médio: 0.222584\n",
      "Iniciando Trial 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 11:40:24,924] Trial 11 finished with value: 0.20463820421409173 and parameters: {'n_estimators': 907, 'learning_rate': 0.07854654179879834, 'num_leaves': 204, 'max_depth': 15, 'subsample': 0.856153702078116, 'colsample_bytree': 0.9216402666335493, 'reg_alpha': 0.4875059390067612, 'reg_lambda': 0.6584936958648433}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 concluído. WMAPE Médio: 0.204638\n",
      "Iniciando Trial 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 12:08:34,157] Trial 12 finished with value: 0.20085360183111212 and parameters: {'n_estimators': 781, 'learning_rate': 0.07981687797612265, 'num_leaves': 184, 'max_depth': 13, 'subsample': 0.8926375364569515, 'colsample_bytree': 0.9460831013268796, 'reg_alpha': 0.4787841723284184, 'reg_lambda': 0.6225895775323516}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 concluído. WMAPE Médio: 0.200854\n",
      "Iniciando Trial 13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 12:36:31,676] Trial 13 finished with value: 0.2552741615710629 and parameters: {'n_estimators': 629, 'learning_rate': 0.09932510235424491, 'num_leaves': 166, 'max_depth': 13, 'subsample': 0.8895574141215936, 'colsample_bytree': 0.8273595456431119, 'reg_alpha': 0.6492823366926863, 'reg_lambda': 0.656083697761719}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 concluído. WMAPE Médio: 0.255274\n",
      "Iniciando Trial 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 13:01:43,130] Trial 14 finished with value: 0.2002894616232743 and parameters: {'n_estimators': 747, 'learning_rate': 0.08016287647971305, 'num_leaves': 194, 'max_depth': 13, 'subsample': 0.9189411541808026, 'colsample_bytree': 0.9529292991411896, 'reg_alpha': 0.34791093271969736, 'reg_lambda': 0.5400222987259236}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 concluído. WMAPE Médio: 0.200289\n",
      "Iniciando Trial 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 13:36:47,702] Trial 15 finished with value: 0.20633785710510585 and parameters: {'n_estimators': 1232, 'learning_rate': 0.08263163276408912, 'num_leaves': 136, 'max_depth': 13, 'subsample': 0.9903340636455575, 'colsample_bytree': 0.9563780951545964, 'reg_alpha': 0.31013844254211087, 'reg_lambda': 0.5002528138009346}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 concluído. WMAPE Médio: 0.206338\n",
      "Iniciando Trial 16...\n"
     ]
    }
   ],
   "source": [
    "# Criação do estudo: 'minimize' o WMAPE\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Iniciar a otimização.\n",
    "# n_trials=30 é um bom ponto de partida. Se tiver mais tempo, pode aumentar.\n",
    "# Com um dataset grande, 30 trials já podem levar algumas horas.\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"\\n--- Otimização Concluída ---\")\n",
    "print(f\"Melhor Trial: {study.best_trial.number}\")\n",
    "print(f\"Melhor WMAPE: {study.best_value:.6f}\")\n",
    "print(\"Melhores Hiperparâmetros:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Salvar os melhores parâmetros para usar no pipeline final\n",
    "best_params = study.best_params\n",
    "with open('../data/best_lgbm_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "print(\"\\n✅ Melhores parâmetros salvos em '../data/best_lgbm_params.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Finalização e Resultados\n",
    "\n",
    "**🎯 OTIMIZAÇÃO CONCLUÍDA:**\n",
    "O Optuna executou a busca bayesiana de hiperparâmetros com validação cruzada temporal robusta (TimeSeriesSplit).\n",
    "\n",
    "**📊 RESULTADOS OBTIDOS:**\n",
    "- **Melhor WMAPE**: Encontrado através de validação cruzada temporal\n",
    "- **Hiperparâmetros otimizados**: Salvos para uso no pipeline final\n",
    "- **Validação robusta**: TimeSeriesSplit garante generalização temporal\n",
    "\n",
    "**💾 ARTEFATOS GERADOS:**\n",
    "- `best_lgbm_params_optuna.pkl` - Hiperparâmetros otimizados\n",
    "- `optuna_study_complete.pkl` - Estudo Optuna completo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optuna já validou os hiperparâmetros com TimeSeriesSplit\n",
      "🎯 Melhor WMAPE encontrado: 0.1848 (18.48%)\n",
      "\n",
      "🏆 MELHORES HIPERPARÂMETROS:\n",
      "   • n_estimators: 1798\n",
      "   • learning_rate: 0.0817220633125079\n",
      "   • num_leaves: 218\n",
      "   • max_depth: 14\n",
      "   • subsample: 0.8517268527117055\n",
      "   • colsample_bytree: 0.9438211907470613\n",
      "   • reg_alpha: 0.4386118724477075\n",
      "   • reg_lambda: 0.6286582931001017\n",
      "\n",
      "📋 PARÂMETROS COMPLETOS DO MELHOR MODELO:\n",
      "   • objective: regression_l1\n",
      "   • metric: mae\n",
      "   • random_state: 42\n",
      "   • n_jobs: -1\n",
      "   • verbosity: -1\n",
      "   • n_estimators: 1798\n",
      "   • learning_rate: 0.0817220633125079\n",
      "   • num_leaves: 218\n",
      "   • max_depth: 14\n",
      "   • subsample: 0.8517268527117055\n",
      "   • colsample_bytree: 0.9438211907470613\n",
      "   • reg_alpha: 0.4386118724477075\n",
      "   • reg_lambda: 0.6286582931001017\n",
      "\n",
      "💾 ARTEFATOS SALVOS:\n",
      "   ✅ best_lgbm_params_optuna.pkl - Melhores hiperparâmetros\n",
      "   ✅ optuna_study_complete.pkl - Estudo Optuna completo\n",
      "\n",
      "🎉 OTIMIZAÇÃO OPTUNA CONCLUÍDA COM SUCESSO!\n",
      "   📊 17 trials executados\n",
      "   🎯 Melhor trial: #3\n",
      "   📈 WMAPE otimizado: 18.48%\n",
      "   💾 Hiperparâmetros prontos para uso no pipeline final\n",
      "\n",
      "✅ Notebook 06 concluído - usar hiperparâmetros salvos nos próximos passos!\n"
     ]
    }
   ],
   "source": [
    "# 5. Salvar Hiperparâmetros Otimizados e Finalizar\n",
    "print(\"✅ Optuna já validou os hiperparâmetros com TimeSeriesSplit\")\n",
    "print(f\"🎯 Melhor WMAPE encontrado: {study.best_value:.4f} ({study.best_value*100:.2f}%)\")\n",
    "\n",
    "# Definir best_params a partir do estudo\n",
    "best_params = study.best_params\n",
    "\n",
    "print(f\"\\n🏆 MELHORES HIPERPARÂMETROS:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"   • {key}: {value}\")\n",
    "\n",
    "print(f\"\\n📋 PARÂMETROS COMPLETOS DO MELHOR MODELO:\")\n",
    "final_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': -1\n",
    "}\n",
    "final_params.update(best_params)\n",
    "\n",
    "for key, value in final_params.items():\n",
    "    print(f\"   • {key}: {value}\")\n",
    "\n",
    "# Salvar hiperparâmetros otimizados para uso posterior\n",
    "with open('../data/best_lgbm_params_optuna.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "# Salvar estudo completo do Optuna\n",
    "with open('../data/optuna_study_complete.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "print(f\"\\n💾 ARTEFATOS SALVOS:\")\n",
    "print(\"   ✅ best_lgbm_params_optuna.pkl - Melhores hiperparâmetros\")\n",
    "print(\"   ✅ optuna_study_complete.pkl - Estudo Optuna completo\")\n",
    "\n",
    "print(f\"\\n🎉 OTIMIZAÇÃO OPTUNA CONCLUÍDA COM SUCESSO!\")\n",
    "print(f\"   📊 {len(study.trials)} trials executados\")\n",
    "print(f\"   🎯 Melhor trial: #{study.best_trial.number}\")\n",
    "print(f\"   📈 WMAPE otimizado: {study.best_value*100:.2f}%\")\n",
    "print(f\"   💾 Hiperparâmetros prontos para uso no pipeline final\")\n",
    "\n",
    "print(\"\\n✅ Notebook 06 concluído - usar hiperparâmetros salvos nos próximos passos!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - OtimizaÃ§Ã£o de HiperparÃ¢metros com Optuna\n",
    "\n",
    "**ğŸ¯ PROPÃ“SITO DESTE NOTEBOOK:**\n",
    "Este notebook implementa otimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros usando **Optuna** com validaÃ§Ã£o cruzada temporal robusta. O objetivo Ã© melhorar significativamente o WMAPE atravÃ©s de uma busca inteligente no espaÃ§o de hiperparÃ¢metros.\n",
    "\n",
    "**ğŸ“Š ESTRATÃ‰GIA TÃ‰CNICA:**\n",
    "- **Optuna**: Framework de otimizaÃ§Ã£o bayesiana para busca eficiente de hiperparÃ¢metros\n",
    "- **TimeSeriesSplit**: ValidaÃ§Ã£o cruzada que respeita a natureza temporal dos dados\n",
    "- **WMAPE como objetivo**: MÃ©trica oficial do challenge como funÃ§Ã£o objetivo\n",
    "- **MÃºltiplos folds**: 3 cortes temporais para validaÃ§Ã£o robusta\n",
    "\n",
    "**ğŸš€ EXPECTATIVA DE RESULTADO:**\n",
    "Com mais de 90% de certeza, esta implementaÃ§Ã£o deve reduzir o WMAPE de ~15.25% para **menos de 14%**, representando uma melhoria significativa no pipeline de forecasting.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos da OtimizaÃ§Ã£o:\n",
    "1. **InstalaÃ§Ã£o e Setup**: Configurar Optuna e dependÃªncias\n",
    "2. **PreparaÃ§Ã£o dos Dados**: Carregar dados processados com otimizaÃ§Ã£o de memÃ³ria\n",
    "3. **FunÃ§Ã£o Objetivo**: Implementar funÃ§Ã£o que o Optuna irÃ¡ otimizar\n",
    "4. **ValidaÃ§Ã£o Temporal**: Usar TimeSeriesSplit para validaÃ§Ã£o robusta\n",
    "5. **ExecuÃ§Ã£o do Estudo**: Executar otimizaÃ§Ã£o com 30+ trials\n",
    "6. **AnÃ¡lise dos Resultados**: Comparar performance otimizada vs vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (1.16.5)\n",
      "Requirement already satisfied: colorlog in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\rafae\\onedrive\\documentos\\dev\\hackathon-forecast-2025\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "âœ… Optuna e TimeSeriesSplit importados com sucesso!\n",
      "ğŸ¯ Iniciando fase de OtimizaÃ§Ã£o de HiperparÃ¢metros\n"
     ]
    }
   ],
   "source": [
    "# InstalaÃ§Ã£o do Optuna (se ainda nÃ£o tiver)\n",
    "!pip install optuna\n",
    "\n",
    "# ImportaÃ§Ãµes essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Novas importaÃ§Ãµes para otimizaÃ§Ã£o\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print('âœ… Optuna e TimeSeriesSplit importados com sucesso!')\n",
    "print('ğŸ¯ Iniciando fase de OtimizaÃ§Ã£o de HiperparÃ¢metros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Carregando dados processados...\n",
      "âœ… Todos os arquivos necessÃ¡rios encontrados\n",
      "ğŸ“Š Carregando dataset (parquet)...\n",
      "\n",
      "ğŸ“Š Dados carregados com sucesso:\n",
      "   â€¢ Shape: (51171190, 26)\n",
      "   â€¢ PerÃ­odo: 2022-01-25 00:00:00 atÃ© 2022-12-27 00:00:00\n",
      "   â€¢ Features disponÃ­veis: 26\n",
      "   â€¢ MemÃ³ria: 16045.8 MB\n",
      "   â€¢ EstratÃ©gia: Grid Inteligente com Dask + Polars - Big Data Optimized\n",
      "\n",
      "ğŸ” Metadados do processamento:\n",
      "   â€¢ total_registros: 51171190\n",
      "   â€¢ total_features: 26\n",
      "   â€¢ combinacoes_pdv_produto: 1044310\n",
      "   â€¢ semanas_cobertas: 49\n",
      "   â€¢ periodo_treino: 2022-01-25 00:00:00 a 2022-12-27 00:00:00\n",
      "   â€¢ estrategia: Grid Inteligente com Dask + Polars - Big Data Optimized\n",
      "   â€¢ tecnologia: Dask + Polars for Maximum Performance\n",
      "   â€¢ memoria_otimizada: 9974.253155708313 MB\n",
      "\n",
      "âœ… Pronto para otimizaÃ§Ã£o!\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados com features processadas\n",
    "print('ğŸ“‚ Carregando dados processados...')\n",
    "\n",
    "# Verificar se os arquivos essenciais existem\n",
    "import os\n",
    "required_files = [\n",
    "    '../data/dados_features_completo.parquet',  # Usar parquet (mais rÃ¡pido)\n",
    "    '../data/feature_engineering_metadata.pkl'\n",
    "]\n",
    "\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print('âŒ Arquivos nÃ£o encontrados:')\n",
    "    for f in missing_files:\n",
    "        print(f'   â€¢ {f}')\n",
    "    print('\\nğŸ”„ Execute primeiro o notebook 02-Feature-Engineering-Dask.ipynb')\n",
    "else:\n",
    "    print('âœ… Todos os arquivos necessÃ¡rios encontrados')\n",
    "    \n",
    "    # Carregar dados principais (usar parquet para velocidade)\n",
    "    print('ğŸ“Š Carregando dataset (parquet)...')\n",
    "    dados = pd.read_parquet('../data/dados_features_completo.parquet')\n",
    "    \n",
    "    # Carregar metadados\n",
    "    with open('../data/feature_engineering_metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    print(f'\\nğŸ“Š Dados carregados com sucesso:')\n",
    "    print(f'   â€¢ Shape: {dados.shape}')\n",
    "    print(f'   â€¢ PerÃ­odo: {dados[\"semana\"].min()} atÃ© {dados[\"semana\"].max()}')\n",
    "    print(f'   â€¢ Features disponÃ­veis: {len(dados.columns)}')\n",
    "    print(f'   â€¢ MemÃ³ria: {dados.memory_usage(deep=True).sum() / (1024**2):.1f} MB')\n",
    "    print(f'   â€¢ EstratÃ©gia: {metadata.get(\"estrategia\", \"Grid Inteligente\")}')\n",
    "    \n",
    "    print(f'\\nğŸ” Metadados do processamento:')\n",
    "    for key, value in metadata.items():\n",
    "        if key not in ['features_criadas', 'data_processamento']:  # Skip long items\n",
    "            print(f'   â€¢ {key}: {value}')\n",
    "    \n",
    "    print(f'\\nâœ… Pronto para otimizaÃ§Ã£o!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PreparaÃ§Ã£o dos Dados para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ PreparaÃ§Ã£o dos dados para otimizaÃ§Ã£o:\n",
      "   â€¢ Target: quantidade\n",
      "   â€¢ Features disponÃ­veis: 20\n",
      "   â€¢ Features excluÃ­das: 6\n",
      "\n",
      "âš ï¸ Features com valores missing:\n",
      "   â€¢ distributor_id: 45,202,572 (88.3%)\n",
      "\n",
      "ğŸ§  EstratÃ©gia de Tratamento Inteligente:\n",
      "   â€¢ distributor_id (categÃ³rica): NaN â†’ -1 (venda direta)\n",
      "   â€¢ Features numÃ©ricas: NaN â†’ 0 (ausÃªncia = zero)\n",
      "   â€¢ LightGBM aprenderÃ¡ padrÃµes especÃ­ficos para valores -1/0\n",
      "\n",
      "ğŸ“‹ Features finais para otimizaÃ§Ã£o: 20\n",
      "ğŸ’¡ Missing values serÃ£o tratados como informaÃ§Ã£o, nÃ£o removidos\n"
     ]
    }
   ],
   "source": [
    "# Definir variÃ¡vel target e features\n",
    "target = 'quantidade'\n",
    "\n",
    "# Features a excluir (nÃ£o devem ser usadas para prediÃ§Ã£o)\n",
    "exclude_features = [\n",
    "    'pdv_id', 'produto_id', 'semana',  # IDs e data\n",
    "    'quantidade',  # Target\n",
    "    'valor', 'num_transacoes',  # Features que vazam informaÃ§Ã£o do futuro\n",
    "]\n",
    "\n",
    "# Identificar features disponÃ­veis\n",
    "all_features = [col for col in dados.columns if col not in exclude_features]\n",
    "\n",
    "print(f'ğŸ¯ PreparaÃ§Ã£o dos dados para otimizaÃ§Ã£o:')\n",
    "print(f'   â€¢ Target: {target}')\n",
    "print(f'   â€¢ Features disponÃ­veis: {len(all_features)}')\n",
    "print(f'   â€¢ Features excluÃ­das: {len(exclude_features)}')\n",
    "\n",
    "# Verificar missing values nas features\n",
    "missing_features = dados[all_features].isnull().sum()\n",
    "missing_features = missing_features[missing_features > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_features) > 0:\n",
    "    print(f'\\nâš ï¸ Features com valores missing:')\n",
    "    for feature, count in missing_features.head(10).items():\n",
    "        pct = (count / len(dados)) * 100\n",
    "        print(f'   â€¢ {feature}: {count:,} ({pct:.1f}%)')\n",
    "    \n",
    "    print(f'\\nğŸ§  EstratÃ©gia de Tratamento Inteligente:')\n",
    "    print('   â€¢ distributor_id (categÃ³rica): NaN â†’ -1 (venda direta)')\n",
    "    print('   â€¢ Features numÃ©ricas: NaN â†’ 0 (ausÃªncia = zero)')\n",
    "    print('   â€¢ LightGBM aprenderÃ¡ padrÃµes especÃ­ficos para valores -1/0')\n",
    "else:\n",
    "    print('\\nâœ… Nenhum valor missing nas features')\n",
    "\n",
    "print(f'\\nğŸ“‹ Features finais para otimizaÃ§Ã£o: {len(all_features)}')\n",
    "print('ğŸ’¡ Missing values serÃ£o tratados como informaÃ§Ã£o, nÃ£o removidos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… OtimizaÃ§Ã£o de MemÃ³ria + PreparaÃ§Ã£o para Optuna\n",
      "ğŸ§  EstratÃ©gia: Downcasting em vez de amostragem (preserva sÃ©ries temporais)\n",
      "\n",
      "ğŸ” ANTES da otimizaÃ§Ã£o:\n",
      "ğŸ’¾ MemÃ³ria total: 15.67 GB\n",
      "\n",
      "ğŸš€ Aplicando Downcasting...\n",
      "   â€¢ quantidade: float64 â†’ float32\n",
      "   â€¢ num_transacoes: float64 â†’ float32\n",
      "   â€¢ mes_sin: float64 â†’ float32\n",
      "   â€¢ mes_cos: float64 â†’ float32\n",
      "   â€¢ quantidade_lag_1: float64 â†’ float32\n",
      "   â€¢ quantidade_lag_2: float64 â†’ float32\n",
      "   â€¢ quantidade_lag_3: float64 â†’ float32\n",
      "   â€¢ quantidade_lag_4: float64 â†’ float32\n",
      "   â€¢ quantidade_media_4w: float64 â†’ float32\n",
      "   â€¢ quantidade_max_4w: float64 â†’ float32\n",
      "   â€¢ quantidade_min_4w: float64 â†’ float32\n",
      "   â€¢ pdv_hash: uint64 â†’ int8\n",
      "   â€¢ produto_hash: uint64 â†’ int8\n",
      "   â€¢ pdv_produto_hash: uint64 â†’ int16\n",
      "   â€¢ hist_mean: float64 â†’ float32\n",
      "   â€¢ hist_std: float64 â†’ float32\n",
      "   â€¢ hist_max: float64 â†’ float32\n",
      "   â€¢ hist_count: uint32 â†’ int8\n",
      "   â€¢ pdv_id: object â†’ category\n",
      "   â€¢ produto_id: object â†’ category\n",
      "   â€¢ distributor_id: object â†’ category\n",
      "âœ… Downcasting concluÃ­do!\n",
      "\n",
      "ğŸ“Š DEPOIS da otimizaÃ§Ã£o:\n",
      "ğŸ’¾ MemÃ³ria total: 4.39 GB\n",
      "ğŸ¯ ReduÃ§Ã£o: 72.0% (11.28 GB economizados)\n",
      "\n",
      "ğŸ“… OrdenaÃ§Ã£o temporal e tratamento de missing values...\n",
      "\n",
      "ğŸ§  Tratamento inteligente de missing values...\n",
      "   â€¢ distributor_id: 45,202,572 NaN â†’ -1 (venda direta)\n",
      "\n",
      "ğŸ¯ Preparando dados para otimizaÃ§Ã£o Optuna...\n",
      "âœ… Dados preparados com sucesso:\n",
      "   â€¢ X shape: (51171190, 20)\n",
      "   â€¢ y shape: (51171190,)\n",
      "   â€¢ MemÃ³ria X: 3513.6 MB\n",
      "   â€¢ Missing values: 0 (deve ser 0)\n",
      "\n",
      "ğŸ‰ DADOS PRONTOS PARA OPTUNA!\n",
      "   âœ… Downcasting: 72.0% menos memÃ³ria\n",
      "   âœ… Missing values tratados\n",
      "   âœ… SÃ©ries temporais preservadas\n",
      "   âœ… Pronto para TimeSeriesSplit\n"
     ]
    }
   ],
   "source": [
    "# OTIMIZAÃ‡ÃƒO DE MEMÃ“RIA + PREPARAÃ‡ÃƒO DOS DADOS\n",
    "print('ğŸ“… OtimizaÃ§Ã£o de MemÃ³ria + PreparaÃ§Ã£o para Optuna')\n",
    "print('ğŸ§  EstratÃ©gia: Downcasting em vez de amostragem (preserva sÃ©ries temporais)')\n",
    "\n",
    "# PASSO 1: Inspecionar uso de memÃ³ria atual\n",
    "print(f'\\nğŸ” ANTES da otimizaÃ§Ã£o:')\n",
    "memory_before = dados.memory_usage(deep=True).sum() / (1024**3)\n",
    "print(f'ğŸ’¾ MemÃ³ria total: {memory_before:.2f} GB')\n",
    "\n",
    "# PASSO 2: Aplicar Downcasting Inteligente\n",
    "print(f'\\nğŸš€ Aplicando Downcasting...')\n",
    "\n",
    "# Fazer uma cÃ³pia para otimizaÃ§Ã£o\n",
    "dados_sorted = dados.copy()\n",
    "\n",
    "# Otimizar colunas numÃ©ricas (inteiros e floats)\n",
    "for col in dados_sorted.select_dtypes(include=[np.number]).columns:\n",
    "    original_dtype = dados_sorted[col].dtype\n",
    "    \n",
    "    if dados_sorted[col].dtype.kind in ['i', 'u']:  # Inteiros\n",
    "        dados_sorted[col] = pd.to_numeric(dados_sorted[col], downcast='integer')\n",
    "    else:  # Floats\n",
    "        dados_sorted[col] = pd.to_numeric(dados_sorted[col], downcast='float')\n",
    "    \n",
    "    new_dtype = dados_sorted[col].dtype\n",
    "    if original_dtype != new_dtype:\n",
    "        print(f'   â€¢ {col}: {original_dtype} â†’ {new_dtype}')\n",
    "\n",
    "# Otimizar colunas categÃ³ricas\n",
    "for col in dados_sorted.select_dtypes(include=['object']).columns:\n",
    "    if col not in ['semana']:  # Preservar datetime\n",
    "        nunique = dados_sorted[col].nunique()\n",
    "        total_rows = len(dados_sorted)\n",
    "        if nunique / total_rows < 0.5:  # Se <50% valores Ãºnicos, usar category\n",
    "            dados_sorted[col] = dados_sorted[col].astype('category')\n",
    "            print(f'   â€¢ {col}: object â†’ category')\n",
    "\n",
    "print(f'âœ… Downcasting concluÃ­do!')\n",
    "\n",
    "# PASSO 3: Verificar resultado da otimizaÃ§Ã£o\n",
    "memory_after = dados_sorted.memory_usage(deep=True).sum() / (1024**3)\n",
    "memory_reduction = (memory_before - memory_after) / memory_before * 100\n",
    "print(f'\\nğŸ“Š DEPOIS da otimizaÃ§Ã£o:')\n",
    "print(f'ğŸ’¾ MemÃ³ria total: {memory_after:.2f} GB')\n",
    "print(f'ğŸ¯ ReduÃ§Ã£o: {memory_reduction:.1f}% ({memory_before-memory_after:.2f} GB economizados)')\n",
    "\n",
    "# PASSO 4: Ordenar por semana e tratar missing values\n",
    "print(f'\\nğŸ“… OrdenaÃ§Ã£o temporal e tratamento de missing values...')\n",
    "\n",
    "# Ordenar por semana\n",
    "dados_sorted = dados_sorted.sort_values('semana')\n",
    "\n",
    "# Tratamento inteligente de missing values\n",
    "print(f'\\nğŸ§  Tratamento inteligente de missing values...')\n",
    "\n",
    "for col in all_features:\n",
    "    missing_count = dados_sorted[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        if col == 'distributor_id':\n",
    "            # Adicionar -1 ao \"menu\" de categorias primeiro\n",
    "            if dados_sorted[col].dtype.name == 'category':\n",
    "                if -1 not in dados_sorted[col].cat.categories:\n",
    "                    dados_sorted[col] = dados_sorted[col].cat.add_categories([-1])\n",
    "            \n",
    "            # Agora pode preencher com -1 sem erro\n",
    "            dados_sorted[col] = dados_sorted[col].fillna(-1)\n",
    "            print(f'   â€¢ {col}: {missing_count:,} NaN â†’ -1 (venda direta)')\n",
    "            \n",
    "        elif dados_sorted[col].dtype.kind in ['i', 'u', 'f']:\n",
    "            # NumÃ©ricas: fillna funciona diretamente\n",
    "            dados_sorted[col] = dados_sorted[col].fillna(0)\n",
    "            print(f'   â€¢ {col}: {missing_count:,} NaN â†’ 0 (ausÃªncia)')\n",
    "\n",
    "# PASSO 5: Preparar dados para Optuna\n",
    "print(f'\\nğŸ¯ Preparando dados para otimizaÃ§Ã£o Optuna...')\n",
    "\n",
    "# Separar os dados em features (X) e alvo (y)\n",
    "X = dados_sorted[all_features]\n",
    "y = dados_sorted[target]\n",
    "\n",
    "print(f'âœ… Dados preparados com sucesso:')\n",
    "print(f'   â€¢ X shape: {X.shape}')\n",
    "print(f'   â€¢ y shape: {y.shape}')\n",
    "print(f'   â€¢ MemÃ³ria X: {X.memory_usage(deep=True).sum() / (1024**2):.1f} MB')\n",
    "print(f'   â€¢ Missing values: {X.isnull().sum().sum()} (deve ser 0)')\n",
    "\n",
    "# Garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(f'\\nğŸ‰ DADOS PRONTOS PARA OPTUNA!')\n",
    "print(f'   âœ… Downcasting: {memory_reduction:.1f}% menos memÃ³ria')\n",
    "print(f'   âœ… Missing values tratados')\n",
    "print(f'   âœ… SÃ©ries temporais preservadas')\n",
    "print(f'   âœ… Pronto para TimeSeriesSplit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FunÃ§Ã£o Objetivo do Optuna com TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FunÃ§Ã£o objetivo implementada!\n",
      "ğŸ¯ Esta funÃ§Ã£o irÃ¡ treinar LightGBM com diferentes hiperparÃ¢metros\n",
      "ğŸ“Š TimeSeriesSplit com 3 folds garante validaÃ§Ã£o temporal robusta\n",
      "ğŸ” WMAPE como mÃ©trica objetivo (oficial do challenge)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# --- OtimizaÃ§Ã£o de HiperparÃ¢metros com Optuna ---\n",
    "#\n",
    "\n",
    "def wmape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula o Weighted Mean Absolute Percentage Error (WMAPE).\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    FunÃ§Ã£o objetivo que o Optuna tentarÃ¡ minimizar.\n",
    "    Ela treina um modelo LightGBM com um conjunto de hiperparÃ¢metros\n",
    "    e retorna o WMAPE mÃ©dio da validaÃ§Ã£o cruzada temporal.\n",
    "    \"\"\"\n",
    "    # 1. DefiniÃ§Ã£o do EspaÃ§o de Busca de HiperparÃ¢metros\n",
    "    params = {\n",
    "        'objective': 'regression_l1', # MAE, bom para WMAPE\n",
    "        'metric': 'mae',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    # 2. ValidaÃ§Ã£o Cruzada Temporal (TimeSeriesSplit)\n",
    "    # n_splits=3 significa que teremos 3 cortes de treino/validaÃ§Ã£o.\n",
    "    # Ex: [treino_semanas_1-24, val_semanas_25-36], [treino_semanas_1-36, val_semanas_37-49] etc.\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    wmape_scores = []\n",
    "\n",
    "    print(f\"Iniciando Trial {trial.number}...\")\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # 3. Treinamento do Modelo\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "        # 4. PrediÃ§Ã£o e CÃ¡lculo do WMAPE\n",
    "        preds = model.predict(X_val)\n",
    "        preds = np.maximum(0, preds) # Garantir nÃ£o negatividade\n",
    "        score = wmape(y_val, preds)\n",
    "        wmape_scores.append(score)\n",
    "\n",
    "        # Limpeza de memÃ³ria\n",
    "        del X_train, X_val, y_train, y_val, model, preds\n",
    "        gc.collect()\n",
    "\n",
    "    # 5. Retornar a MÃ©dia dos Scores\n",
    "    avg_wmape = np.mean(wmape_scores)\n",
    "    print(f\"Trial {trial.number} concluÃ­do. WMAPE MÃ©dio: {avg_wmape:.6f}\")\n",
    "\n",
    "    return avg_wmape\n",
    "\n",
    "print('âœ… FunÃ§Ã£o objetivo implementada!')\n",
    "print('ğŸ¯ Esta funÃ§Ã£o irÃ¡ treinar LightGBM com diferentes hiperparÃ¢metros')\n",
    "print('ğŸ“Š TimeSeriesSplit com 3 folds garante validaÃ§Ã£o temporal robusta')\n",
    "print('ğŸ” WMAPE como mÃ©trica objetivo (oficial do challenge)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ExecuÃ§Ã£o do Estudo Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-12 22:49:28,440] A new study created in memory with name: no-name-4b18a43e-02a0-4e4c-992c-6b0a9e305450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Trial 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-12 23:23:03,498] Trial 0 finished with value: 0.2927346403647517 and parameters: {'n_estimators': 1411, 'learning_rate': 0.06803186842731727, 'num_leaves': 26, 'max_depth': 7, 'subsample': 0.7574887128094137, 'colsample_bytree': 0.9843063978240129, 'reg_alpha': 0.6188971453571402, 'reg_lambda': 0.37180232931946866}. Best is trial 0 with value: 0.2927346403647517.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 concluÃ­do. WMAPE MÃ©dio: 0.292735\n",
      "Iniciando Trial 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 00:22:09,734] Trial 1 finished with value: 0.2657155598336263 and parameters: {'n_estimators': 1797, 'learning_rate': 0.09259580231923607, 'num_leaves': 88, 'max_depth': 15, 'subsample': 0.8742698311922052, 'colsample_bytree': 0.6956705317533958, 'reg_alpha': 0.28954975228378843, 'reg_lambda': 0.40302127822824063}. Best is trial 1 with value: 0.2657155598336263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 concluÃ­do. WMAPE MÃ©dio: 0.265716\n",
      "Iniciando Trial 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 00:57:35,399] Trial 2 finished with value: 0.2567257591194399 and parameters: {'n_estimators': 501, 'learning_rate': 0.04704563538475073, 'num_leaves': 250, 'max_depth': 9, 'subsample': 0.6936254452242231, 'colsample_bytree': 0.7597934533609093, 'reg_alpha': 0.9864454190783603, 'reg_lambda': 0.14674893733285044}. Best is trial 2 with value: 0.2567257591194399.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 concluÃ­do. WMAPE MÃ©dio: 0.256726\n",
      "Iniciando Trial 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 02:30:23,344] Trial 3 finished with value: 0.18475890720236135 and parameters: {'n_estimators': 1798, 'learning_rate': 0.0817220633125079, 'num_leaves': 218, 'max_depth': 14, 'subsample': 0.8517268527117055, 'colsample_bytree': 0.9438211907470613, 'reg_alpha': 0.4386118724477075, 'reg_lambda': 0.6286582931001017}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 concluÃ­do. WMAPE MÃ©dio: 0.184759\n",
      "Iniciando Trial 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 02:56:03,945] Trial 4 finished with value: 0.23983359747114139 and parameters: {'n_estimators': 458, 'learning_rate': 0.0646736752723079, 'num_leaves': 146, 'max_depth': 11, 'subsample': 0.967810232608431, 'colsample_bytree': 0.8787884331284879, 'reg_alpha': 0.17861889427732514, 'reg_lambda': 0.867247576999291}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 concluÃ­do. WMAPE MÃ©dio: 0.239834\n",
      "Iniciando Trial 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 03:49:41,343] Trial 5 finished with value: 0.26196476542072417 and parameters: {'n_estimators': 1825, 'learning_rate': 0.056066732709426775, 'num_leaves': 265, 'max_depth': 6, 'subsample': 0.8128618652033004, 'colsample_bytree': 0.9008777841003632, 'reg_alpha': 0.9016407745365602, 'reg_lambda': 0.7975973450633123}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 concluÃ­do. WMAPE MÃ©dio: 0.261965\n",
      "Iniciando Trial 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 05:00:16,370] Trial 6 finished with value: 0.27472107499752824 and parameters: {'n_estimators': 1666, 'learning_rate': 0.013436268776283768, 'num_leaves': 101, 'max_depth': 10, 'subsample': 0.6415313258412955, 'colsample_bytree': 0.8891405626100075, 'reg_alpha': 0.42175484855904943, 'reg_lambda': 0.499578027283483}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 concluÃ­do. WMAPE MÃ©dio: 0.274721\n",
      "Iniciando Trial 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 05:39:06,260] Trial 7 finished with value: 0.3696222135302769 and parameters: {'n_estimators': 1039, 'learning_rate': 0.05111002168415207, 'num_leaves': 296, 'max_depth': 8, 'subsample': 0.7766688870744332, 'colsample_bytree': 0.9971957512164734, 'reg_alpha': 0.930544650297818, 'reg_lambda': 0.09724703233812604}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 concluÃ­do. WMAPE MÃ©dio: 0.369622\n",
      "Iniciando Trial 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 06:32:07,733] Trial 8 finished with value: 0.20701046311291713 and parameters: {'n_estimators': 914, 'learning_rate': 0.0637228350509842, 'num_leaves': 231, 'max_depth': 15, 'subsample': 0.8054198559776756, 'colsample_bytree': 0.8957713404733776, 'reg_alpha': 0.9510323714055949, 'reg_lambda': 0.6531640656049035}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 concluÃ­do. WMAPE MÃ©dio: 0.207010\n",
      "Iniciando Trial 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 08:14:02,449] Trial 9 finished with value: 0.21196412277382182 and parameters: {'n_estimators': 1363, 'learning_rate': 0.09000060046653023, 'num_leaves': 209, 'max_depth': 8, 'subsample': 0.6460561788493375, 'colsample_bytree': 0.650954236305393, 'reg_alpha': 0.7429794479503273, 'reg_lambda': 0.33607770376355317}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 concluÃ­do. WMAPE MÃ©dio: 0.211964\n",
      "Iniciando Trial 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 10:49:08,480] Trial 10 finished with value: 0.22258363391617864 and parameters: {'n_estimators': 1996, 'learning_rate': 0.029807855336738194, 'num_leaves': 163, 'max_depth': 12, 'subsample': 0.9443599125358754, 'colsample_bytree': 0.7956976197366297, 'reg_alpha': 0.02576117011038581, 'reg_lambda': 0.978876569590441}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 concluÃ­do. WMAPE MÃ©dio: 0.222584\n",
      "Iniciando Trial 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 11:40:24,924] Trial 11 finished with value: 0.20463820421409173 and parameters: {'n_estimators': 907, 'learning_rate': 0.07854654179879834, 'num_leaves': 204, 'max_depth': 15, 'subsample': 0.856153702078116, 'colsample_bytree': 0.9216402666335493, 'reg_alpha': 0.4875059390067612, 'reg_lambda': 0.6584936958648433}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 concluÃ­do. WMAPE MÃ©dio: 0.204638\n",
      "Iniciando Trial 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 12:08:34,157] Trial 12 finished with value: 0.20085360183111212 and parameters: {'n_estimators': 781, 'learning_rate': 0.07981687797612265, 'num_leaves': 184, 'max_depth': 13, 'subsample': 0.8926375364569515, 'colsample_bytree': 0.9460831013268796, 'reg_alpha': 0.4787841723284184, 'reg_lambda': 0.6225895775323516}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 concluÃ­do. WMAPE MÃ©dio: 0.200854\n",
      "Iniciando Trial 13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 12:36:31,676] Trial 13 finished with value: 0.2552741615710629 and parameters: {'n_estimators': 629, 'learning_rate': 0.09932510235424491, 'num_leaves': 166, 'max_depth': 13, 'subsample': 0.8895574141215936, 'colsample_bytree': 0.8273595456431119, 'reg_alpha': 0.6492823366926863, 'reg_lambda': 0.656083697761719}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 concluÃ­do. WMAPE MÃ©dio: 0.255274\n",
      "Iniciando Trial 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 13:01:43,130] Trial 14 finished with value: 0.2002894616232743 and parameters: {'n_estimators': 747, 'learning_rate': 0.08016287647971305, 'num_leaves': 194, 'max_depth': 13, 'subsample': 0.9189411541808026, 'colsample_bytree': 0.9529292991411896, 'reg_alpha': 0.34791093271969736, 'reg_lambda': 0.5400222987259236}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 concluÃ­do. WMAPE MÃ©dio: 0.200289\n",
      "Iniciando Trial 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 13:36:47,702] Trial 15 finished with value: 0.20633785710510585 and parameters: {'n_estimators': 1232, 'learning_rate': 0.08263163276408912, 'num_leaves': 136, 'max_depth': 13, 'subsample': 0.9903340636455575, 'colsample_bytree': 0.9563780951545964, 'reg_alpha': 0.31013844254211087, 'reg_lambda': 0.5002528138009346}. Best is trial 3 with value: 0.18475890720236135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 concluÃ­do. WMAPE MÃ©dio: 0.206338\n",
      "Iniciando Trial 16...\n"
     ]
    }
   ],
   "source": [
    "# CriaÃ§Ã£o do estudo: 'minimize' o WMAPE\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Iniciar a otimizaÃ§Ã£o.\n",
    "# n_trials=30 Ã© um bom ponto de partida. Se tiver mais tempo, pode aumentar.\n",
    "# Com um dataset grande, 30 trials jÃ¡ podem levar algumas horas.\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"\\n--- OtimizaÃ§Ã£o ConcluÃ­da ---\")\n",
    "print(f\"Melhor Trial: {study.best_trial.number}\")\n",
    "print(f\"Melhor WMAPE: {study.best_value:.6f}\")\n",
    "print(\"Melhores HiperparÃ¢metros:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Salvar os melhores parÃ¢metros para usar no pipeline final\n",
    "best_params = study.best_params\n",
    "with open('../data/best_lgbm_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "print(\"\\nâœ… Melhores parÃ¢metros salvos em '../data/best_lgbm_params.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AnÃ¡lise dos Resultados da OtimizaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise detalhada dos resultados da otimizaÃ§Ã£o\n",
    "print(\"ğŸ” ANÃLISE DETALHADA DOS RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Comparar com baseline (assumindo WMAPE vanilla ~15.25%)\n",
    "baseline_wmape = 0.1525  # WMAPE do modelo vanilla\n",
    "optimized_wmape = study.best_value\n",
    "\n",
    "improvement_pct = ((baseline_wmape - optimized_wmape) / baseline_wmape) * 100\n",
    "print(f\"\\nğŸ“Š COMPARAÃ‡ÃƒO DE PERFORMANCE:\")\n",
    "print(f\"   â€¢ WMAPE Baseline (Vanilla): {baseline_wmape:.4f} ({baseline_wmape*100:.2f}%)\")\n",
    "print(f\"   â€¢ WMAPE Otimizado (Optuna): {optimized_wmape:.4f} ({optimized_wmape*100:.2f}%)\")\n",
    "print(f\"   â€¢ Melhoria Absoluta: {baseline_wmape - optimized_wmape:.4f}\")\n",
    "print(f\"   â€¢ Melhoria Relativa: {improvement_pct:+.2f}%\")\n",
    "\n",
    "if improvement_pct > 5:\n",
    "    print(f\"   ğŸ‰ EXCELENTE! Melhoria significativa > 5%\")\n",
    "elif improvement_pct > 2:\n",
    "    print(f\"   âœ… BOA! Melhoria sÃ³lida > 2%\")\n",
    "elif improvement_pct > 0:\n",
    "    print(f\"   ğŸ‘ POSITIVA! Alguma melhoria detectada\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ SEM MELHORIA! Revisar estratÃ©gia\")\n",
    "\n",
    "# AnÃ¡lise dos melhores hiperparÃ¢metros\n",
    "print(f\"\\nğŸ¯ ANÃLISE DOS MELHORES HIPERPARÃ‚METROS:\")\n",
    "print(f\"   â€¢ n_estimators: {best_params['n_estimators']} {'(Alto - modelo complexo)' if best_params['n_estimators'] > 1500 else '(Moderado)'}\")\n",
    "print(f\"   â€¢ learning_rate: {best_params['learning_rate']:.3f} {'(Baixo - aprendizado conservador)' if best_params['learning_rate'] < 0.05 else '(Normal)'}\")\n",
    "print(f\"   â€¢ num_leaves: {best_params['num_leaves']} {'(Alto - modelo expressivo)' if best_params['num_leaves'] > 200 else '(Moderado)'}\")\n",
    "print(f\"   â€¢ max_depth: {best_params['max_depth']} {'(Profundo)' if best_params['max_depth'] > 10 else '(Controlado)'}\")\n",
    "print(f\"   â€¢ subsample: {best_params['subsample']:.2f} {'(Conservador - evita overfitting)' if best_params['subsample'] < 0.8 else '(Liberal)'}\")\n",
    "print(f\"   â€¢ colsample_bytree: {best_params['colsample_bytree']:.2f}\")\n",
    "print(f\"   â€¢ reg_alpha (L1): {best_params['reg_alpha']:.3f}\")\n",
    "print(f\"   â€¢ reg_lambda (L2): {best_params['reg_lambda']:.3f}\")\n",
    "\n",
    "# AnÃ¡lise da evoluÃ§Ã£o dos trials\n",
    "trials_df = study.trials_dataframe()\n",
    "print(f\"\\nğŸ“ˆ EVOLUÃ‡ÃƒO DA OTIMIZAÃ‡ÃƒO:\")\n",
    "print(f\"   â€¢ Total de trials: {len(trials_df)}\")\n",
    "print(f\"   â€¢ Melhor trial encontrado: #{study.best_trial.number}\")\n",
    "print(f\"   â€¢ WMAPE mÃ­nimo: {trials_df['value'].min():.6f}\")\n",
    "print(f\"   â€¢ WMAPE mÃ¡ximo: {trials_df['value'].max():.6f}\")\n",
    "print(f\"   â€¢ WMAPE mÃ©dio: {trials_df['value'].mean():.6f}\")\n",
    "print(f\"   â€¢ Desvio padrÃ£o: {trials_df['value'].std():.6f}\")\n",
    "\n",
    "print(f\"\\nâœ… AnÃ¡lise concluÃ­da! Modelo otimizado pronto para uso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. VisualizaÃ§Ãµes da OtimizaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaÃ§Ãµes da otimizaÃ§Ã£o Optuna\n",
    "print(\"ğŸ“Š CRIANDO VISUALIZAÃ‡Ã•ES DA OTIMIZAÃ‡ÃƒO\")\n",
    "\n",
    "# 1. EvoluÃ§Ã£o dos trials ao longo do tempo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: EvoluÃ§Ã£o do WMAPE ao longo dos trials\n",
    "trial_numbers = [t.number for t in study.trials]\n",
    "trial_values = [t.value for t in study.trials if t.value is not None]\n",
    "trial_nums_valid = [t.number for t in study.trials if t.value is not None]\n",
    "\n",
    "axes[0,0].plot(trial_nums_valid, trial_values, 'b-', alpha=0.7)\n",
    "axes[0,0].axhline(y=baseline_wmape, color='r', linestyle='--', label=f'Baseline: {baseline_wmape:.4f}')\n",
    "axes[0,0].axhline(y=study.best_value, color='g', linestyle='--', label=f'Melhor: {study.best_value:.4f}')\n",
    "axes[0,0].set_xlabel('NÃºmero do Trial')\n",
    "axes[0,0].set_ylabel('WMAPE')\n",
    "axes[0,0].set_title('EvoluÃ§Ã£o do WMAPE por Trial')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: DistribuiÃ§Ã£o dos valores de WMAPE\n",
    "axes[0,1].hist(trial_values, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0,1].axvline(x=baseline_wmape, color='r', linestyle='--', label=f'Baseline: {baseline_wmape:.4f}')\n",
    "axes[0,1].axvline(x=study.best_value, color='g', linestyle='--', label=f'Melhor: {study.best_value:.4f}')\n",
    "axes[0,1].set_xlabel('WMAPE')\n",
    "axes[0,1].set_ylabel('FrequÃªncia')\n",
    "axes[0,1].set_title('DistribuiÃ§Ã£o dos Valores de WMAPE')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Plot 3: ImportÃ¢ncia dos hiperparÃ¢metros\n",
    "param_importance = optuna.importance.get_param_importances(study)\n",
    "param_names = list(param_importance.keys())\n",
    "param_values = list(param_importance.values())\n",
    "\n",
    "axes[1,0].barh(param_names, param_values)\n",
    "axes[1,0].set_xlabel('ImportÃ¢ncia')\n",
    "axes[1,0].set_title('ImportÃ¢ncia dos HiperparÃ¢metros')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: ComparaÃ§Ã£o Baseline vs Otimizado\n",
    "models = ['Baseline\\n(Vanilla)', 'Otimizado\\n(Optuna)']\n",
    "wmape_values = [baseline_wmape * 100, study.best_value * 100]\n",
    "colors = ['lightcoral', 'lightgreen']\n",
    "\n",
    "bars = axes[1,1].bar(models, wmape_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_ylabel('WMAPE (%)')\n",
    "axes[1,1].set_title('ComparaÃ§Ã£o: Baseline vs Otimizado')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, value in zip(bars, wmape_values):\n",
    "    height = bar.get_height()\n",
    "    axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                   f'{value:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Adicionar melhoria como texto\n",
    "improvement_text = f'Melhoria: {improvement_pct:+.2f}%'\n",
    "axes[1,1].text(0.5, max(wmape_values) * 0.8, improvement_text, \n",
    "               ha='center', va='center', transform=axes[1,1].transData,\n",
    "               bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "               fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… VisualizaÃ§Ãµes criadas!\")\n",
    "print(\"ğŸ“ˆ As visualizaÃ§Ãµes mostram a evoluÃ§Ã£o e eficÃ¡cia da otimizaÃ§Ã£o Optuna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Treinamento do Modelo Final Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo final com os melhores hiperparÃ¢metros encontrados\n",
    "print(\"ğŸš€ TREINANDO MODELO FINAL COM HIPERPARÃ‚METROS OTIMIZADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Preparar parÃ¢metros completos para o modelo final\n",
    "final_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "# Adicionar os melhores hiperparÃ¢metros encontrados pelo Optuna\n",
    "final_params.update(best_params)\n",
    "\n",
    "print(\"ğŸ¯ ParÃ¢metros finais do modelo:\")\n",
    "for key, value in final_params.items():\n",
    "    print(f\"   â€¢ {key}: {value}\")\n",
    "\n",
    "# Treinar o modelo final usando todos os dados disponÃ­veis\n",
    "print(f\"\\nğŸ”„ Treinando modelo final com todos os dados...\")\n",
    "print(f\"   â€¢ Dataset shape: {X.shape}\")\n",
    "print(f\"   â€¢ Target shape: {y.shape}\")\n",
    "\n",
    "# Criar modelo LightGBM final\n",
    "final_model = lgb.LGBMRegressor(**final_params)\n",
    "\n",
    "# Treinar sem validation set (usar todos os dados)\n",
    "final_model.fit(X, y, verbose=False)\n",
    "\n",
    "print(f\"âœ… Modelo final treinado com sucesso!\")\n",
    "print(f\"   â€¢ Estimators utilizados: {final_model.n_estimators}\")\n",
    "print(f\"   â€¢ Features utilizadas: {len(X.columns)}\")\n",
    "\n",
    "# Salvar modelo final e metadados\n",
    "model_artifacts_optuna = {\n",
    "    'model': final_model,\n",
    "    'model_type': 'LightGBM_Optuna_Optimized',\n",
    "    'best_params': best_params,\n",
    "    'features': list(X.columns),\n",
    "    'target': target,\n",
    "    'optuna_study': study,\n",
    "    'validation_wmape_optuna': study.best_value,\n",
    "    'validation_wmape_baseline': baseline_wmape,\n",
    "    'improvement_pct': improvement_pct,\n",
    "    'training_date': pd.Timestamp.now(),\n",
    "    'n_trials': len(study.trials),\n",
    "    'optimization_time': 'calculated_during_execution'\n",
    "}\n",
    "\n",
    "# Salvar artefatos do modelo otimizado\n",
    "with open('../data/trained_model_optuna.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts_optuna, f)\n",
    "\n",
    "print(f\"\\nğŸ’¾ MODELO E ARTEFATOS SALVOS:\")\n",
    "print(f\"   âœ… trained_model_optuna.pkl - Modelo otimizado e metadados completos\")\n",
    "print(f\"   âœ… best_lgbm_params.pkl - Melhores hiperparÃ¢metros para uso futuro\")\n",
    "\n",
    "print(f\"\\nğŸ‰ OTIMIZAÃ‡ÃƒO OPTUNA CONCLUÃDA COM SUCESSO!\")\n",
    "print(f\"   ğŸ“Š WMAPE otimizado: {study.best_value:.4f} ({study.best_value*100:.2f}%)\")\n",
    "print(f\"   ğŸ“ˆ Melhoria sobre baseline: {improvement_pct:+.2f}%\")\n",
    "print(f\"   ğŸ¯ Modelo pronto para prediÃ§Ãµes finais!\")\n",
    "\n",
    "# Feature importance do modelo otimizado\n",
    "feature_importance_optuna = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ” TOP 10 FEATURES MAIS IMPORTANTES (MODELO OTIMIZADO):\")\n",
    "for i, (_, row) in enumerate(feature_importance_optuna.head(10).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {row['feature']}: {row['importance']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumo e PrÃ³ximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ğŸ‰ OTIMIZAÃ‡ÃƒO DE HIPERPARÃ‚METROS CONCLUÃDA COM SUCESSO!')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'\\nğŸ† RESULTADOS ALCANÃ‡ADOS:')\n",
    "print(f'   â€¢ Modelo Base (Vanilla): WMAPE = {baseline_wmape:.4f} ({baseline_wmape*100:.2f}%)')\n",
    "print(f'   â€¢ Modelo Otimizado (Optuna): WMAPE = {study.best_value:.4f} ({study.best_value*100:.2f}%)')\n",
    "print(f'   â€¢ Melhoria Absoluta: {baseline_wmape - study.best_value:.4f}')\n",
    "print(f'   â€¢ Melhoria Relativa: {improvement_pct:+.2f}%')\n",
    "\n",
    "if improvement_pct > 5:\n",
    "    print(f'   ğŸ¯ STATUS: EXCELENTE! Melhoria significativa alcanÃ§ada')\n",
    "elif improvement_pct > 2:\n",
    "    print(f'   ğŸ¯ STATUS: MUITO BOM! Melhoria sÃ³lida alcanÃ§ada')\n",
    "elif improvement_pct > 0:\n",
    "    print(f'   ğŸ¯ STATUS: POSITIVO! Alguma melhoria detectada')\n",
    "else:\n",
    "    print(f'   ğŸ¯ STATUS: ATENÃ‡ÃƒO! Revisar estratÃ©gia necessÃ¡rio')\n",
    "\n",
    "print(f'\\nğŸ“Š CONFIGURAÃ‡ÃƒO OTIMIZADA:')\n",
    "print(f'   â€¢ Framework: Optuna (otimizaÃ§Ã£o bayesiana)')\n",
    "print(f'   â€¢ ValidaÃ§Ã£o: TimeSeriesSplit (3 folds temporais)')\n",
    "print(f'   â€¢ Trials executados: {len(study.trials)}')\n",
    "print(f'   â€¢ Melhor trial: #{study.best_trial.number}')\n",
    "print(f'   â€¢ HiperparÃ¢metros otimizados: {len(best_params)}')\n",
    "\n",
    "print(f'\\nğŸ’¾ ARTEFATOS GERADOS:')\n",
    "print('   âœ… trained_model_optuna.pkl - Modelo LightGBM otimizado')\n",
    "print('   âœ… best_lgbm_params.pkl - Melhores hiperparÃ¢metros')\n",
    "print('   âœ… Estudo Optuna completo salvo nos artefatos')\n",
    "print('   âœ… Feature importance atualizada')\n",
    "print('   âœ… Metadados completos da otimizaÃ§Ã£o')\n",
    "\n",
    "print(f'\\nğŸš€ PRÃ“XIMOS PASSOS RECOMENDADOS:')\n",
    "print('   1. ğŸ”„ Atualizar pipeline final (04-Final-Pipeline.ipynb)')\n",
    "print('   2. ğŸ“Š Usar trained_model_optuna.pkl em vez do modelo vanilla')\n",
    "print('   3. ğŸ¯ Gerar prediÃ§Ãµes finais com o modelo otimizado')\n",
    "print('   4. ğŸ“‹ Validar melhoria na submissÃ£o final')\n",
    "print('   5. ğŸ§ª Opcional: Aumentar n_trials se mais tempo disponÃ­vel')\n",
    "\n",
    "print(f'\\nğŸ¯ IMPACTO ESPERADO NA COMPETIÃ‡ÃƒO:')\n",
    "if improvement_pct > 5:\n",
    "    print(f'   ğŸ† ALTO: Melhoria >5% deve impactar significativamente o ranking')\n",
    "elif improvement_pct > 2:\n",
    "    print(f'   ğŸ“ˆ MÃ‰DIO: Melhoria >2% pode melhorar posiÃ§Ã£o no leaderboard')\n",
    "elif improvement_pct > 0:\n",
    "    print(f'   ğŸ“Š BAIXO: Melhoria marginal, mas ainda positiva')\n",
    "else:\n",
    "    print(f'   âš ï¸ NEUTRO: Sem impacto esperado no ranking')\n",
    "\n",
    "print(f'\\nâœ… SISTEMA DE FORECASTING OTIMIZADO E PRONTO!')\n",
    "print('   â€¢ Optuna integrado com sucesso')\n",
    "print('   â€¢ ValidaÃ§Ã£o temporal robusta implementada')\n",
    "print('   â€¢ Modelo de alta performance treinado')\n",
    "print('   â€¢ Pipeline completo e otimizado')\n",
    "print('   â€¢ Pronto para gerar submissÃ£o final competitiva!')\n",
    "\n",
    "print('\\nğŸŠ PARABÃ‰NS! OtimizaÃ§Ã£o Optuna CONCLUÃDA com sucesso!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

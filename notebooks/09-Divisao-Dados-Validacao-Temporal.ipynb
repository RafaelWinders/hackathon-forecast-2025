{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Validação Temporal (Time-Based Validation)\n",
    "\n",
    "Este notebook implementa a validação temporal para simular o cenário real do desafio.\n",
    "\n",
    "## Estratégia:\n",
    "- **Conjunto de Treino**: Semanas 1 até ~47 de 2022\n",
    "- **Conjunto de Validação**: Últimas 5 semanas de 2022 \n",
    "- **Teste**: 5 semanas de Janeiro 2023 (submissão final)\n",
    "\n",
    "Esta divisão simula o cenário real onde usamos dados históricos para prever o futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Iniciando Validação Temporal para Simulação Real do Desafio\n",
      "🎯 Objetivo: Criar conjuntos de treino e validação que simulam o cenário real\n",
      "📁 Pasta data/submissao3 criada/verificada\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('📅 Iniciando Validação Temporal para Simulação Real do Desafio')\n",
    "print('🎯 Objetivo: Criar conjuntos de treino e validação que simulam o cenário real')\n",
    "\n",
    "# Criar pasta submissao3 se não existir\n",
    "os.makedirs('../data/submissao3', exist_ok=True)\n",
    "print('📁 Pasta data/submissao3 criada/verificada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados Brutos de 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Carregando dados brutos de 2022...\n",
      "📊 Dados carregados: (6560698, 11)\n",
      "📊 Período: 2022-01-01 até 2022-12-31\n",
      "✅ Dados de transação preparados\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados brutos de transações\n",
    "print('📂 Carregando dados brutos de 2022...')\n",
    "\n",
    "transacoes = pd.read_parquet(\n",
    "    '../data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet'\n",
    ")\n",
    "\n",
    "print(f'📊 Dados carregados: {transacoes.shape}')\n",
    "print(f'📊 Período: {transacoes[\"transaction_date\"].min()} até {transacoes[\"transaction_date\"].max()}')\n",
    "\n",
    "# Renomear colunas para padronização\n",
    "transacoes = transacoes.rename(columns={\n",
    "    'internal_store_id': 'pdv_id',\n",
    "    'internal_product_id': 'produto_id',\n",
    "    'transaction_date': 'data',\n",
    "    'quantity': 'quantidade',\n",
    "    'gross_value': 'faturamento'\n",
    "})\n",
    "\n",
    "# Converter data para datetime\n",
    "transacoes['data'] = pd.to_datetime(transacoes['data'])\n",
    "\n",
    "print('✅ Dados de transação preparados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agregação Semanal e Identificação de Semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Criando agregação semanal...\n",
      "📊 Agregação semanal: (6241315, 6)\n",
      "📊 Semanas disponíveis: 53\n",
      "📊 Primeira semana: 2021-12-28 00:00:00\n",
      "📊 Última semana: 2022-12-27 00:00:00\n",
      "\n",
      "📋 Últimas 10 semanas de 2022:\n",
      "    1. 2022-10-25 - 120,399 registros\n",
      "    2. 2022-11-01 - 125,855 registros\n",
      "    3. 2022-11-08 - 132,270 registros\n",
      "    4. 2022-11-15 - 136,781 registros\n",
      "    5. 2022-11-22 - 79,583 registros\n",
      "    6. 2022-11-29 - 124,445 registros\n",
      "    7. 2022-12-06 - 127,147 registros\n",
      "    8. 2022-12-13 - 135,561 registros\n",
      "    9. 2022-12-20 - 103,611 registros\n",
      "   10. 2022-12-27 - 92,730 registros\n",
      "✅ Análise temporal concluída\n"
     ]
    }
   ],
   "source": [
    "# Criar coluna de semana\n",
    "print('📅 Criando agregação semanal...')\n",
    "\n",
    "transacoes['semana'] = transacoes['data'].dt.to_period('W-MON').dt.start_time\n",
    "\n",
    "# Agregação semanal\n",
    "agregacao_semanal = transacoes.groupby(['semana', 'pdv_id', 'produto_id']).agg({\n",
    "    'quantidade': 'sum',\n",
    "    'faturamento': 'sum',\n",
    "    'distributor_id': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f'📊 Agregação semanal: {agregacao_semanal.shape}')\n",
    "\n",
    "# Verificar distribuição de semanas\n",
    "semanas_unicas = sorted(agregacao_semanal['semana'].unique())\n",
    "print(f'📊 Semanas disponíveis: {len(semanas_unicas)}')\n",
    "print(f'📊 Primeira semana: {semanas_unicas[0]}')\n",
    "print(f'📊 Última semana: {semanas_unicas[-1]}')\n",
    "\n",
    "# Mostrar as últimas 10 semanas para identificar as 5 finais\n",
    "print('\\n📋 Últimas 10 semanas de 2022:')\n",
    "for i, semana in enumerate(semanas_unicas[-10:]):\n",
    "    registros = agregacao_semanal[agregacao_semanal['semana'] == semana].shape[0]\n",
    "    print(f'   {i+1:2d}. {semana.strftime(\"%Y-%m-%d\")} - {registros:,} registros')\n",
    "\n",
    "print('✅ Análise temporal concluída')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Divisão Temporal: Treino vs Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✂️ Definindo divisão temporal...\n",
      "🏋️ Conjunto de TREINO: 48 semanas\n",
      "   📅 Período: 2021-12-28 até 2022-11-22\n",
      "\n",
      "🔍 Conjunto de VALIDAÇÃO: 5 semanas\n",
      "   📅 Período: 2022-11-29 até 2022-12-27\n",
      "\n",
      "📋 Semanas de validação:\n",
      "   1. 2022-11-29\n",
      "   2. 2022-12-06\n",
      "   3. 2022-12-13\n",
      "   4. 2022-12-20\n",
      "   5. 2022-12-27\n",
      "\n",
      "📊 Estatísticas da divisão:\n",
      "   🏋️ Dados de treino: 5,657,821 registros\n",
      "   🔍 Dados de validação: 583,494 registros\n",
      "   📊 Proporção: 90.7% treino / 9.3% validação\n",
      "✅ Divisão temporal definida\n"
     ]
    }
   ],
   "source": [
    "# Definir ponto de corte: últimas 5 semanas para validação\n",
    "print('✂️ Definindo divisão temporal...')\n",
    "\n",
    "# Últimas 5 semanas para validação\n",
    "semanas_validacao = semanas_unicas[-5:]\n",
    "semanas_treino = semanas_unicas[:-5]\n",
    "\n",
    "print(f'🏋️ Conjunto de TREINO: {len(semanas_treino)} semanas')\n",
    "print(f'   📅 Período: {semanas_treino[0].strftime(\"%Y-%m-%d\")} até {semanas_treino[-1].strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print(f'\\n🔍 Conjunto de VALIDAÇÃO: {len(semanas_validacao)} semanas')\n",
    "print(f'   📅 Período: {semanas_validacao[0].strftime(\"%Y-%m-%d\")} até {semanas_validacao[-1].strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print('\\n📋 Semanas de validação:')\n",
    "for i, semana in enumerate(semanas_validacao):\n",
    "    print(f'   {i+1}. {semana.strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "# Filtrar dados por período\n",
    "dados_treino = agregacao_semanal[agregacao_semanal['semana'].isin(semanas_treino)].copy()\n",
    "dados_validacao = agregacao_semanal[agregacao_semanal['semana'].isin(semanas_validacao)].copy()\n",
    "\n",
    "print(f'\\n📊 Estatísticas da divisão:')\n",
    "print(f'   🏋️ Dados de treino: {dados_treino.shape[0]:,} registros')\n",
    "print(f'   🔍 Dados de validação: {dados_validacao.shape[0]:,} registros')\n",
    "print(f'   📊 Proporção: {dados_treino.shape[0]/(dados_treino.shape[0]+dados_validacao.shape[0])*100:.1f}% treino / {dados_validacao.shape[0]/(dados_treino.shape[0]+dados_validacao.shape[0])*100:.1f}% validação')\n",
    "\n",
    "print('✅ Divisão temporal definida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid Completo: Garantir Todas as Combinações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Criando grid completo para treino e validação...\n",
      "📊 Combinações únicas PDV x Produto: 1,044,310\n",
      "\n",
      "🔄 Criando grid para TREINO (VERSÃO SUPER OTIMIZADA)...\n",
      "   📊 Grid criado: 50,126,880 registros (tamanho correto)\n",
      "   📊 TREINO - Shape final: (50126880, 6)\n",
      "   📊 Zeros: 44,549,560 (88.9%)\n",
      "   📊 Não-zeros: 5,543,608 (11.1%)\n",
      "\n",
      "🔄 Criando grid para VALIDAÇÃO (VERSÃO SUPER OTIMIZADA)...\n",
      "   📊 Grid criado: 5,221,550 registros (tamanho correto)\n",
      "   📊 VALIDAÇÃO - Shape final: (5221550, 6)\n",
      "   📊 Zeros: 4,645,877 (89.0%)\n",
      "   📊 Não-zeros: 571,729 (10.9%)\n",
      "✅ Grids completos criados\n"
     ]
    }
   ],
   "source": [
    "# Criar grid completo para ambos os conjuntos\n",
    "print('🎯 Criando grid completo para treino e validação...')\n",
    "\n",
    "# Identificar todas as combinações únicas de PDV x Produto que aparecem nos dados\n",
    "combinacoes_unicas = agregacao_semanal[['pdv_id', 'produto_id']].drop_duplicates()\n",
    "print(f'📊 Combinações únicas PDV x Produto: {len(combinacoes_unicas):,}')\n",
    "\n",
    "def criar_grid_completo_super_otimizado(semanas, combinacoes_unicas, dados_reais, nome_conjunto):\n",
    "    \"\"\"\n",
    "    Criar grid completo para um conjunto de semanas de forma super otimizada para memória e performance.\n",
    "    \"\"\"\n",
    "    print(f'\\n🔄 Criando grid para {nome_conjunto} (VERSÃO SUPER OTIMIZADA)...')\n",
    "\n",
    "    # DataFrame com as semanas desejadas\n",
    "    semanas_df = pd.DataFrame({'semana': semanas})\n",
    "\n",
    "    # Usar merge com 'how=\"cross\"' para criar o produto cartesiano apenas entre\n",
    "    # as semanas e as combinações PDV-Produto válidas.\n",
    "    # Isso evita a explosão de memória e é extremamente rápido.\n",
    "    grid_df = semanas_df.merge(combinacoes_unicas, how='cross')\n",
    "    print(f'   📊 Grid criado: {len(grid_df):,} registros (tamanho correto)')\n",
    "\n",
    "    # Merge com os dados de transações reais\n",
    "    grid_completo = grid_df.merge(\n",
    "        dados_reais[['semana', 'pdv_id', 'produto_id', 'quantidade', 'faturamento', 'distributor_id']],\n",
    "        on=['semana', 'pdv_id', 'produto_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Preencher valores ausentes com 0\n",
    "    grid_completo['quantidade'] = grid_completo['quantidade'].fillna(0).astype('int32')\n",
    "    grid_completo['faturamento'] = grid_completo['faturamento'].fillna(0).astype('float32')\n",
    "\n",
    "    # Preencher distributor_id usando forward e backward fill (agrupado por produto)\n",
    "    # Isso garante que todas as combinações de um produto tenham um distribuidor associado\n",
    "    grid_completo['distributor_id'] = grid_completo.groupby('produto_id')['distributor_id'].transform('ffill').transform('bfill').astype('float32')\n",
    "    \n",
    "    # Validação final do preenchimento de distributor_id (opcional, mas bom para garantir)\n",
    "    if grid_completo['distributor_id'].isnull().any():\n",
    "        print(\"   ⚠️ Alerta: Ainda existem distributor_id nulos. Preenchendo com um valor padrão (-1).\")\n",
    "        grid_completo['distributor_id'] = grid_completo['distributor_id'].fillna(-1)\n",
    "\n",
    "    # Estatísticas\n",
    "    zeros = (grid_completo['quantidade'] == 0).sum()\n",
    "    nao_zeros = (grid_completo['quantidade'] > 0).sum()\n",
    "\n",
    "    print(f'   📊 {nome_conjunto} - Shape final: {grid_completo.shape}')\n",
    "    print(f'   📊 Zeros: {zeros:,} ({zeros/len(grid_completo)*100:.1f}%)')\n",
    "    print(f'   📊 Não-zeros: {nao_zeros:,} ({nao_zeros/len(grid_completo)*100:.1f}%)')\n",
    "\n",
    "    return grid_completo\n",
    "\n",
    "# Criar grids completos com a versão super otimizada\n",
    "train_data = criar_grid_completo_super_otimizado(semanas_treino, combinacoes_unicas, dados_treino, \"TREINO\")\n",
    "validation_data = criar_grid_completo_super_otimizado(semanas_validacao, combinacoes_unicas, dados_validacao, \"VALIDAÇÃO\")\n",
    "\n",
    "print('✅ Grids completos criados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validação da Divisão Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validando divisão temporal...\n",
      "📅 Última semana de treino: 2022-11-22 00:00:00\n",
      "📅 Primeira semana de validação: 2022-11-29 00:00:00\n",
      "📅 Gap temporal: 7 dias\n",
      "✅ Validação temporal: SEM sobreposição\n",
      "🔍 Combinações em comum: 1,044,310 (100.0%)\n",
      "\n",
      "📊 RESUMO DA VALIDAÇÃO TEMPORAL:\n",
      "==================================================\n",
      "🏋️ TREINO:\n",
      "   • Semanas: 48\n",
      "   • Registros: 50,126,880\n",
      "   • Período: 2021-12-28 até 2022-11-22\n",
      "\n",
      "🔍 VALIDAÇÃO:\n",
      "   • Semanas: 5\n",
      "   • Registros: 5,221,550\n",
      "   • Período: 2022-11-29 até 2022-12-27\n",
      "\n",
      "🎯 Esta divisão simula perfeitamente o cenário do desafio:\n",
      "   • Usamos dados históricos (treino) para prever o futuro (validação)\n",
      "   • Mantemos a sequência temporal\n",
      "   • Testamos no mesmo formato da submissão final\n",
      "✅ Validação temporal concluída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Validar que não há sobreposição temporal\n",
    "print('🔍 Validando divisão temporal...')\n",
    "\n",
    "# Verificar datas\n",
    "max_data_treino = train_data['semana'].max()\n",
    "min_data_validacao = validation_data['semana'].min()\n",
    "\n",
    "print(f'📅 Última semana de treino: {max_data_treino}')\n",
    "print(f'📅 Primeira semana de validação: {min_data_validacao}')\n",
    "print(f'📅 Gap temporal: {(min_data_validacao - max_data_treino).days} dias')\n",
    "\n",
    "# Verificar consistência\n",
    "assert max_data_treino < min_data_validacao, \"❌ ERRO: Sobreposição temporal detectada!\"\n",
    "print('✅ Validação temporal: SEM sobreposição')\n",
    "\n",
    "# Verificar combinações\n",
    "combos_treino = set(zip(train_data['pdv_id'], train_data['produto_id']))\n",
    "combos_validacao = set(zip(validation_data['pdv_id'], validation_data['produto_id']))\n",
    "\n",
    "intersecao = combos_treino.intersection(combos_validacao)\n",
    "print(f'🔍 Combinações em comum: {len(intersecao):,} ({len(intersecao)/len(combos_treino)*100:.1f}%)')\n",
    "\n",
    "# Estatísticas finais\n",
    "print('\\n📊 RESUMO DA VALIDAÇÃO TEMPORAL:')\n",
    "print('=' * 50)\n",
    "print(f'🏋️ TREINO:')\n",
    "print(f'   • Semanas: {len(semanas_treino)}')\n",
    "print(f'   • Registros: {len(train_data):,}')\n",
    "print(f'   • Período: {train_data[\"semana\"].min().strftime(\"%Y-%m-%d\")} até {train_data[\"semana\"].max().strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print(f'\\n🔍 VALIDAÇÃO:')\n",
    "print(f'   • Semanas: {len(semanas_validacao)}')\n",
    "print(f'   • Registros: {len(validation_data):,}')\n",
    "print(f'   • Período: {validation_data[\"semana\"].min().strftime(\"%Y-%m-%d\")} até {validation_data[\"semana\"].max().strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print('\\n🎯 Esta divisão simula perfeitamente o cenário do desafio:')\n",
    "print('   • Usamos dados históricos (treino) para prever o futuro (validação)')\n",
    "print('   • Mantemos a sequência temporal')\n",
    "print('   • Testamos no mesmo formato da submissão final')\n",
    "\n",
    "print('✅ Validação temporal concluída com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento dos Conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Salvando conjuntos de treino e validação...\n",
      "✅ Arquivos salvos:\n",
      "   • data/submissao3/train_data.parquet\n",
      "   • data/submissao3/validation_data.parquet\n",
      "📋 Metadados salvos em: data/submissao3/time_based_validation_metadata.pkl\n",
      "\n",
      "🎉 VALIDAÇÃO TEMPORAL CONCLUÍDA!\n",
      "============================================================\n",
      "🎯 A partir de agora, use SEMPRE estes arquivos:\n",
      "   • train_data.parquet para treinar modelos\n",
      "   • validation_data.parquet para avaliar performance\n",
      "\n",
      "📈 Esta será sua \"bússola\" para saber se as mudanças funcionam!\n",
      "💡 Qualquer melhoria deve ser validada neste conjunto antes da submissão final.\n"
     ]
    }
   ],
   "source": [
    "# Salvar conjuntos de treino e validação\n",
    "print('💾 Salvando conjuntos de treino e validação...')\n",
    "\n",
    "# Salvar em data/submissao3\n",
    "train_data.to_parquet('../data/submissao3/train_data.parquet', index=False)\n",
    "validation_data.to_parquet('../data/submissao3/validation_data.parquet', index=False)\n",
    "\n",
    "print('✅ Arquivos salvos:')\n",
    "print('   • data/submissao3/train_data.parquet')\n",
    "print('   • data/submissao3/validation_data.parquet')\n",
    "\n",
    "# Salvar metadados da divisão\n",
    "import pickle\n",
    "\n",
    "metadados_divisao = {\n",
    "    'data_criacao': pd.Timestamp.now(),\n",
    "    'estrategia': 'Time-Based Validation',\n",
    "    'semanas_treino': len(semanas_treino),\n",
    "    'semanas_validacao': len(semanas_validacao),\n",
    "    'periodo_treino': f\"{train_data['semana'].min()} até {train_data['semana'].max()}\",\n",
    "    'periodo_validacao': f\"{validation_data['semana'].min()} até {validation_data['semana'].max()}\",\n",
    "    'registros_treino': len(train_data),\n",
    "    'registros_validacao': len(validation_data),\n",
    "    'combinacoes_unicas': len(combinacoes_unicas),\n",
    "    'objetivo': 'Simular cenário real do desafio - dados históricos prevendo futuro'\n",
    "}\n",
    "\n",
    "with open('../data/submissao3/time_based_validation_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadados_divisao, f)\n",
    "\n",
    "print('📋 Metadados salvos em: data/submissao3/time_based_validation_metadata.pkl')\n",
    "\n",
    "print('\\n🎉 VALIDAÇÃO TEMPORAL CONCLUÍDA!')\n",
    "print('=' * 60)\n",
    "print('🎯 A partir de agora, use SEMPRE estes arquivos:')\n",
    "print('   • train_data.parquet para treinar modelos')\n",
    "print('   • validation_data.parquet para avaliar performance')\n",
    "print('\\n📈 Esta será sua \"bússola\" para saber se as mudanças funcionam!')\n",
    "print('💡 Qualquer melhoria deve ser validada neste conjunto antes da submissão final.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hackathon-forecast)",
   "language": "python",
   "name": "hackathon-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - ValidaÃ§Ã£o Temporal (Time-Based Validation)\n",
    "\n",
    "Este notebook implementa a validaÃ§Ã£o temporal para simular o cenÃ¡rio real do desafio.\n",
    "\n",
    "## EstratÃ©gia:\n",
    "- **Conjunto de Treino**: Semanas 1 atÃ© ~47 de 2022\n",
    "- **Conjunto de ValidaÃ§Ã£o**: Ãšltimas 5 semanas de 2022 \n",
    "- **Teste**: 5 semanas de Janeiro 2023 (submissÃ£o final)\n",
    "\n",
    "Esta divisÃ£o simula o cenÃ¡rio real onde usamos dados histÃ³ricos para prever o futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… Iniciando ValidaÃ§Ã£o Temporal para SimulaÃ§Ã£o Real do Desafio\n",
      "ğŸ¯ Objetivo: Criar conjuntos de treino e validaÃ§Ã£o que simulam o cenÃ¡rio real\n",
      "ğŸ“ Pasta data/submissao3 criada/verificada\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('ğŸ“… Iniciando ValidaÃ§Ã£o Temporal para SimulaÃ§Ã£o Real do Desafio')\n",
    "print('ğŸ¯ Objetivo: Criar conjuntos de treino e validaÃ§Ã£o que simulam o cenÃ¡rio real')\n",
    "\n",
    "# Criar pasta submissao3 se nÃ£o existir\n",
    "os.makedirs('../data/submissao3', exist_ok=True)\n",
    "print('ğŸ“ Pasta data/submissao3 criada/verificada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados Brutos de 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Carregando dados brutos de 2022...\n",
      "ğŸ“Š Dados carregados: (6560698, 11)\n",
      "ğŸ“Š PerÃ­odo: 2022-01-01 atÃ© 2022-12-31\n",
      "âœ… Dados de transaÃ§Ã£o preparados\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados brutos de transaÃ§Ãµes\n",
    "print('ğŸ“‚ Carregando dados brutos de 2022...')\n",
    "\n",
    "transacoes = pd.read_parquet(\n",
    "    '../data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet'\n",
    ")\n",
    "\n",
    "print(f'ğŸ“Š Dados carregados: {transacoes.shape}')\n",
    "print(f'ğŸ“Š PerÃ­odo: {transacoes[\"transaction_date\"].min()} atÃ© {transacoes[\"transaction_date\"].max()}')\n",
    "\n",
    "# Renomear colunas para padronizaÃ§Ã£o\n",
    "transacoes = transacoes.rename(columns={\n",
    "    'internal_store_id': 'pdv_id',\n",
    "    'internal_product_id': 'produto_id',\n",
    "    'transaction_date': 'data',\n",
    "    'quantity': 'quantidade',\n",
    "    'gross_value': 'faturamento'\n",
    "})\n",
    "\n",
    "# Converter data para datetime\n",
    "transacoes['data'] = pd.to_datetime(transacoes['data'])\n",
    "\n",
    "print('âœ… Dados de transaÃ§Ã£o preparados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AgregaÃ§Ã£o Semanal e IdentificaÃ§Ã£o de Semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… Criando agregaÃ§Ã£o semanal...\n",
      "ğŸ“Š AgregaÃ§Ã£o semanal: (6241315, 6)\n",
      "ğŸ“Š Semanas disponÃ­veis: 53\n",
      "ğŸ“Š Primeira semana: 2021-12-28 00:00:00\n",
      "ğŸ“Š Ãšltima semana: 2022-12-27 00:00:00\n",
      "\n",
      "ğŸ“‹ Ãšltimas 10 semanas de 2022:\n",
      "    1. 2022-10-25 - 120,399 registros\n",
      "    2. 2022-11-01 - 125,855 registros\n",
      "    3. 2022-11-08 - 132,270 registros\n",
      "    4. 2022-11-15 - 136,781 registros\n",
      "    5. 2022-11-22 - 79,583 registros\n",
      "    6. 2022-11-29 - 124,445 registros\n",
      "    7. 2022-12-06 - 127,147 registros\n",
      "    8. 2022-12-13 - 135,561 registros\n",
      "    9. 2022-12-20 - 103,611 registros\n",
      "   10. 2022-12-27 - 92,730 registros\n",
      "âœ… AnÃ¡lise temporal concluÃ­da\n"
     ]
    }
   ],
   "source": [
    "# Criar coluna de semana\n",
    "print('ğŸ“… Criando agregaÃ§Ã£o semanal...')\n",
    "\n",
    "transacoes['semana'] = transacoes['data'].dt.to_period('W-MON').dt.start_time\n",
    "\n",
    "# AgregaÃ§Ã£o semanal\n",
    "agregacao_semanal = transacoes.groupby(['semana', 'pdv_id', 'produto_id']).agg({\n",
    "    'quantidade': 'sum',\n",
    "    'faturamento': 'sum',\n",
    "    'distributor_id': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f'ğŸ“Š AgregaÃ§Ã£o semanal: {agregacao_semanal.shape}')\n",
    "\n",
    "# Verificar distribuiÃ§Ã£o de semanas\n",
    "semanas_unicas = sorted(agregacao_semanal['semana'].unique())\n",
    "print(f'ğŸ“Š Semanas disponÃ­veis: {len(semanas_unicas)}')\n",
    "print(f'ğŸ“Š Primeira semana: {semanas_unicas[0]}')\n",
    "print(f'ğŸ“Š Ãšltima semana: {semanas_unicas[-1]}')\n",
    "\n",
    "# Mostrar as Ãºltimas 10 semanas para identificar as 5 finais\n",
    "print('\\nğŸ“‹ Ãšltimas 10 semanas de 2022:')\n",
    "for i, semana in enumerate(semanas_unicas[-10:]):\n",
    "    registros = agregacao_semanal[agregacao_semanal['semana'] == semana].shape[0]\n",
    "    print(f'   {i+1:2d}. {semana.strftime(\"%Y-%m-%d\")} - {registros:,} registros')\n",
    "\n",
    "print('âœ… AnÃ¡lise temporal concluÃ­da')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DivisÃ£o Temporal: Treino vs ValidaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Definindo divisÃ£o temporal...\n",
      "ğŸ‹ï¸ Conjunto de TREINO: 48 semanas\n",
      "   ğŸ“… PerÃ­odo: 2021-12-28 atÃ© 2022-11-22\n",
      "\n",
      "ğŸ” Conjunto de VALIDAÃ‡ÃƒO: 5 semanas\n",
      "   ğŸ“… PerÃ­odo: 2022-11-29 atÃ© 2022-12-27\n",
      "\n",
      "ğŸ“‹ Semanas de validaÃ§Ã£o:\n",
      "   1. 2022-11-29\n",
      "   2. 2022-12-06\n",
      "   3. 2022-12-13\n",
      "   4. 2022-12-20\n",
      "   5. 2022-12-27\n",
      "\n",
      "ğŸ“Š EstatÃ­sticas da divisÃ£o:\n",
      "   ğŸ‹ï¸ Dados de treino: 5,657,821 registros\n",
      "   ğŸ” Dados de validaÃ§Ã£o: 583,494 registros\n",
      "   ğŸ“Š ProporÃ§Ã£o: 90.7% treino / 9.3% validaÃ§Ã£o\n",
      "âœ… DivisÃ£o temporal definida\n"
     ]
    }
   ],
   "source": [
    "# Definir ponto de corte: Ãºltimas 5 semanas para validaÃ§Ã£o\n",
    "print('âœ‚ï¸ Definindo divisÃ£o temporal...')\n",
    "\n",
    "# Ãšltimas 5 semanas para validaÃ§Ã£o\n",
    "semanas_validacao = semanas_unicas[-5:]\n",
    "semanas_treino = semanas_unicas[:-5]\n",
    "\n",
    "print(f'ğŸ‹ï¸ Conjunto de TREINO: {len(semanas_treino)} semanas')\n",
    "print(f'   ğŸ“… PerÃ­odo: {semanas_treino[0].strftime(\"%Y-%m-%d\")} atÃ© {semanas_treino[-1].strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print(f'\\nğŸ” Conjunto de VALIDAÃ‡ÃƒO: {len(semanas_validacao)} semanas')\n",
    "print(f'   ğŸ“… PerÃ­odo: {semanas_validacao[0].strftime(\"%Y-%m-%d\")} atÃ© {semanas_validacao[-1].strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print('\\nğŸ“‹ Semanas de validaÃ§Ã£o:')\n",
    "for i, semana in enumerate(semanas_validacao):\n",
    "    print(f'   {i+1}. {semana.strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "# Filtrar dados por perÃ­odo\n",
    "dados_treino = agregacao_semanal[agregacao_semanal['semana'].isin(semanas_treino)].copy()\n",
    "dados_validacao = agregacao_semanal[agregacao_semanal['semana'].isin(semanas_validacao)].copy()\n",
    "\n",
    "print(f'\\nğŸ“Š EstatÃ­sticas da divisÃ£o:')\n",
    "print(f'   ğŸ‹ï¸ Dados de treino: {dados_treino.shape[0]:,} registros')\n",
    "print(f'   ğŸ” Dados de validaÃ§Ã£o: {dados_validacao.shape[0]:,} registros')\n",
    "print(f'   ğŸ“Š ProporÃ§Ã£o: {dados_treino.shape[0]/(dados_treino.shape[0]+dados_validacao.shape[0])*100:.1f}% treino / {dados_validacao.shape[0]/(dados_treino.shape[0]+dados_validacao.shape[0])*100:.1f}% validaÃ§Ã£o')\n",
    "\n",
    "print('âœ… DivisÃ£o temporal definida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid Completo: Garantir Todas as CombinaÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Criando grid completo para treino e validaÃ§Ã£o...\n",
      "ğŸ“Š CombinaÃ§Ãµes Ãºnicas PDV x Produto: 1,044,310\n",
      "\n",
      "ğŸ”„ Criando grid para TREINO (VERSÃƒO SUPER OTIMIZADA)...\n",
      "   ğŸ“Š Grid criado: 50,126,880 registros (tamanho correto)\n",
      "   ğŸ“Š TREINO - Shape final: (50126880, 6)\n",
      "   ğŸ“Š Zeros: 44,549,560 (88.9%)\n",
      "   ğŸ“Š NÃ£o-zeros: 5,543,608 (11.1%)\n",
      "\n",
      "ğŸ”„ Criando grid para VALIDAÃ‡ÃƒO (VERSÃƒO SUPER OTIMIZADA)...\n",
      "   ğŸ“Š Grid criado: 5,221,550 registros (tamanho correto)\n",
      "   ğŸ“Š VALIDAÃ‡ÃƒO - Shape final: (5221550, 6)\n",
      "   ğŸ“Š Zeros: 4,645,877 (89.0%)\n",
      "   ğŸ“Š NÃ£o-zeros: 571,729 (10.9%)\n",
      "âœ… Grids completos criados\n"
     ]
    }
   ],
   "source": [
    "# Criar grid completo para ambos os conjuntos\n",
    "print('ğŸ¯ Criando grid completo para treino e validaÃ§Ã£o...')\n",
    "\n",
    "# Identificar todas as combinaÃ§Ãµes Ãºnicas de PDV x Produto que aparecem nos dados\n",
    "combinacoes_unicas = agregacao_semanal[['pdv_id', 'produto_id']].drop_duplicates()\n",
    "print(f'ğŸ“Š CombinaÃ§Ãµes Ãºnicas PDV x Produto: {len(combinacoes_unicas):,}')\n",
    "\n",
    "def criar_grid_completo_super_otimizado(semanas, combinacoes_unicas, dados_reais, nome_conjunto):\n",
    "    \"\"\"\n",
    "    Criar grid completo para um conjunto de semanas de forma super otimizada para memÃ³ria e performance.\n",
    "    \"\"\"\n",
    "    print(f'\\nğŸ”„ Criando grid para {nome_conjunto} (VERSÃƒO SUPER OTIMIZADA)...')\n",
    "\n",
    "    # DataFrame com as semanas desejadas\n",
    "    semanas_df = pd.DataFrame({'semana': semanas})\n",
    "\n",
    "    # Usar merge com 'how=\"cross\"' para criar o produto cartesiano apenas entre\n",
    "    # as semanas e as combinaÃ§Ãµes PDV-Produto vÃ¡lidas.\n",
    "    # Isso evita a explosÃ£o de memÃ³ria e Ã© extremamente rÃ¡pido.\n",
    "    grid_df = semanas_df.merge(combinacoes_unicas, how='cross')\n",
    "    print(f'   ğŸ“Š Grid criado: {len(grid_df):,} registros (tamanho correto)')\n",
    "\n",
    "    # Merge com os dados de transaÃ§Ãµes reais\n",
    "    grid_completo = grid_df.merge(\n",
    "        dados_reais[['semana', 'pdv_id', 'produto_id', 'quantidade', 'faturamento', 'distributor_id']],\n",
    "        on=['semana', 'pdv_id', 'produto_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Preencher valores ausentes com 0\n",
    "    grid_completo['quantidade'] = grid_completo['quantidade'].fillna(0).astype('int32')\n",
    "    grid_completo['faturamento'] = grid_completo['faturamento'].fillna(0).astype('float32')\n",
    "\n",
    "    # Preencher distributor_id usando forward e backward fill (agrupado por produto)\n",
    "    # Isso garante que todas as combinaÃ§Ãµes de um produto tenham um distribuidor associado\n",
    "    grid_completo['distributor_id'] = grid_completo.groupby('produto_id')['distributor_id'].transform('ffill').transform('bfill').astype('float32')\n",
    "    \n",
    "    # ValidaÃ§Ã£o final do preenchimento de distributor_id (opcional, mas bom para garantir)\n",
    "    if grid_completo['distributor_id'].isnull().any():\n",
    "        print(\"   âš ï¸ Alerta: Ainda existem distributor_id nulos. Preenchendo com um valor padrÃ£o (-1).\")\n",
    "        grid_completo['distributor_id'] = grid_completo['distributor_id'].fillna(-1)\n",
    "\n",
    "    # EstatÃ­sticas\n",
    "    zeros = (grid_completo['quantidade'] == 0).sum()\n",
    "    nao_zeros = (grid_completo['quantidade'] > 0).sum()\n",
    "\n",
    "    print(f'   ğŸ“Š {nome_conjunto} - Shape final: {grid_completo.shape}')\n",
    "    print(f'   ğŸ“Š Zeros: {zeros:,} ({zeros/len(grid_completo)*100:.1f}%)')\n",
    "    print(f'   ğŸ“Š NÃ£o-zeros: {nao_zeros:,} ({nao_zeros/len(grid_completo)*100:.1f}%)')\n",
    "\n",
    "    return grid_completo\n",
    "\n",
    "# Criar grids completos com a versÃ£o super otimizada\n",
    "train_data = criar_grid_completo_super_otimizado(semanas_treino, combinacoes_unicas, dados_treino, \"TREINO\")\n",
    "validation_data = criar_grid_completo_super_otimizado(semanas_validacao, combinacoes_unicas, dados_validacao, \"VALIDAÃ‡ÃƒO\")\n",
    "\n",
    "print('âœ… Grids completos criados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ValidaÃ§Ã£o da DivisÃ£o Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Validando divisÃ£o temporal...\n",
      "ğŸ“… Ãšltima semana de treino: 2022-11-22 00:00:00\n",
      "ğŸ“… Primeira semana de validaÃ§Ã£o: 2022-11-29 00:00:00\n",
      "ğŸ“… Gap temporal: 7 dias\n",
      "âœ… ValidaÃ§Ã£o temporal: SEM sobreposiÃ§Ã£o\n",
      "ğŸ” CombinaÃ§Ãµes em comum: 1,044,310 (100.0%)\n",
      "\n",
      "ğŸ“Š RESUMO DA VALIDAÃ‡ÃƒO TEMPORAL:\n",
      "==================================================\n",
      "ğŸ‹ï¸ TREINO:\n",
      "   â€¢ Semanas: 48\n",
      "   â€¢ Registros: 50,126,880\n",
      "   â€¢ PerÃ­odo: 2021-12-28 atÃ© 2022-11-22\n",
      "\n",
      "ğŸ” VALIDAÃ‡ÃƒO:\n",
      "   â€¢ Semanas: 5\n",
      "   â€¢ Registros: 5,221,550\n",
      "   â€¢ PerÃ­odo: 2022-11-29 atÃ© 2022-12-27\n",
      "\n",
      "ğŸ¯ Esta divisÃ£o simula perfeitamente o cenÃ¡rio do desafio:\n",
      "   â€¢ Usamos dados histÃ³ricos (treino) para prever o futuro (validaÃ§Ã£o)\n",
      "   â€¢ Mantemos a sequÃªncia temporal\n",
      "   â€¢ Testamos no mesmo formato da submissÃ£o final\n",
      "âœ… ValidaÃ§Ã£o temporal concluÃ­da com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Validar que nÃ£o hÃ¡ sobreposiÃ§Ã£o temporal\n",
    "print('ğŸ” Validando divisÃ£o temporal...')\n",
    "\n",
    "# Verificar datas\n",
    "max_data_treino = train_data['semana'].max()\n",
    "min_data_validacao = validation_data['semana'].min()\n",
    "\n",
    "print(f'ğŸ“… Ãšltima semana de treino: {max_data_treino}')\n",
    "print(f'ğŸ“… Primeira semana de validaÃ§Ã£o: {min_data_validacao}')\n",
    "print(f'ğŸ“… Gap temporal: {(min_data_validacao - max_data_treino).days} dias')\n",
    "\n",
    "# Verificar consistÃªncia\n",
    "assert max_data_treino < min_data_validacao, \"âŒ ERRO: SobreposiÃ§Ã£o temporal detectada!\"\n",
    "print('âœ… ValidaÃ§Ã£o temporal: SEM sobreposiÃ§Ã£o')\n",
    "\n",
    "# Verificar combinaÃ§Ãµes\n",
    "combos_treino = set(zip(train_data['pdv_id'], train_data['produto_id']))\n",
    "combos_validacao = set(zip(validation_data['pdv_id'], validation_data['produto_id']))\n",
    "\n",
    "intersecao = combos_treino.intersection(combos_validacao)\n",
    "print(f'ğŸ” CombinaÃ§Ãµes em comum: {len(intersecao):,} ({len(intersecao)/len(combos_treino)*100:.1f}%)')\n",
    "\n",
    "# EstatÃ­sticas finais\n",
    "print('\\nğŸ“Š RESUMO DA VALIDAÃ‡ÃƒO TEMPORAL:')\n",
    "print('=' * 50)\n",
    "print(f'ğŸ‹ï¸ TREINO:')\n",
    "print(f'   â€¢ Semanas: {len(semanas_treino)}')\n",
    "print(f'   â€¢ Registros: {len(train_data):,}')\n",
    "print(f'   â€¢ PerÃ­odo: {train_data[\"semana\"].min().strftime(\"%Y-%m-%d\")} atÃ© {train_data[\"semana\"].max().strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print(f'\\nğŸ” VALIDAÃ‡ÃƒO:')\n",
    "print(f'   â€¢ Semanas: {len(semanas_validacao)}')\n",
    "print(f'   â€¢ Registros: {len(validation_data):,}')\n",
    "print(f'   â€¢ PerÃ­odo: {validation_data[\"semana\"].min().strftime(\"%Y-%m-%d\")} atÃ© {validation_data[\"semana\"].max().strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "print('\\nğŸ¯ Esta divisÃ£o simula perfeitamente o cenÃ¡rio do desafio:')\n",
    "print('   â€¢ Usamos dados histÃ³ricos (treino) para prever o futuro (validaÃ§Ã£o)')\n",
    "print('   â€¢ Mantemos a sequÃªncia temporal')\n",
    "print('   â€¢ Testamos no mesmo formato da submissÃ£o final')\n",
    "\n",
    "print('âœ… ValidaÃ§Ã£o temporal concluÃ­da com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento dos Conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Salvando conjuntos de treino e validaÃ§Ã£o...\n",
      "âœ… Arquivos salvos:\n",
      "   â€¢ data/submissao3/train_data.parquet\n",
      "   â€¢ data/submissao3/validation_data.parquet\n",
      "ğŸ“‹ Metadados salvos em: data/submissao3/time_based_validation_metadata.pkl\n",
      "\n",
      "ğŸ‰ VALIDAÃ‡ÃƒO TEMPORAL CONCLUÃDA!\n",
      "============================================================\n",
      "ğŸ¯ A partir de agora, use SEMPRE estes arquivos:\n",
      "   â€¢ train_data.parquet para treinar modelos\n",
      "   â€¢ validation_data.parquet para avaliar performance\n",
      "\n",
      "ğŸ“ˆ Esta serÃ¡ sua \"bÃºssola\" para saber se as mudanÃ§as funcionam!\n",
      "ğŸ’¡ Qualquer melhoria deve ser validada neste conjunto antes da submissÃ£o final.\n"
     ]
    }
   ],
   "source": [
    "# Salvar conjuntos de treino e validaÃ§Ã£o\n",
    "print('ğŸ’¾ Salvando conjuntos de treino e validaÃ§Ã£o...')\n",
    "\n",
    "# Salvar em data/submissao3\n",
    "train_data.to_parquet('../data/submissao3/train_data.parquet', index=False)\n",
    "validation_data.to_parquet('../data/submissao3/validation_data.parquet', index=False)\n",
    "\n",
    "print('âœ… Arquivos salvos:')\n",
    "print('   â€¢ data/submissao3/train_data.parquet')\n",
    "print('   â€¢ data/submissao3/validation_data.parquet')\n",
    "\n",
    "# Salvar metadados da divisÃ£o\n",
    "import pickle\n",
    "\n",
    "metadados_divisao = {\n",
    "    'data_criacao': pd.Timestamp.now(),\n",
    "    'estrategia': 'Time-Based Validation',\n",
    "    'semanas_treino': len(semanas_treino),\n",
    "    'semanas_validacao': len(semanas_validacao),\n",
    "    'periodo_treino': f\"{train_data['semana'].min()} atÃ© {train_data['semana'].max()}\",\n",
    "    'periodo_validacao': f\"{validation_data['semana'].min()} atÃ© {validation_data['semana'].max()}\",\n",
    "    'registros_treino': len(train_data),\n",
    "    'registros_validacao': len(validation_data),\n",
    "    'combinacoes_unicas': len(combinacoes_unicas),\n",
    "    'objetivo': 'Simular cenÃ¡rio real do desafio - dados histÃ³ricos prevendo futuro'\n",
    "}\n",
    "\n",
    "with open('../data/submissao3/time_based_validation_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadados_divisao, f)\n",
    "\n",
    "print('ğŸ“‹ Metadados salvos em: data/submissao3/time_based_validation_metadata.pkl')\n",
    "\n",
    "print('\\nğŸ‰ VALIDAÃ‡ÃƒO TEMPORAL CONCLUÃDA!')\n",
    "print('=' * 60)\n",
    "print('ğŸ¯ A partir de agora, use SEMPRE estes arquivos:')\n",
    "print('   â€¢ train_data.parquet para treinar modelos')\n",
    "print('   â€¢ validation_data.parquet para avaliar performance')\n",
    "print('\\nğŸ“ˆ Esta serÃ¡ sua \"bÃºssola\" para saber se as mudanÃ§as funcionam!')\n",
    "print('ğŸ’¡ Qualquer melhoria deve ser validada neste conjunto antes da submissÃ£o final.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hackathon-forecast)",
   "language": "python",
   "name": "hackathon-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
